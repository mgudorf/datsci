{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso, ElasticNet, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_analysis(clf, X_test, y_test):\n",
    "    y_predict = clf.predict(X_test)\n",
    "    mse_ = mean_squared_error(y_test, y_predict)\n",
    "    evs_ = explained_variance_score(y_test, y_predict)\n",
    "    \n",
    "    print('grid scores', clf.grid_scores_)\n",
    "    print('Number of features selected by RFECV', clf.n_features_)\n",
    "    print('Mean squared error {:0.2f}'.format(mse_))\n",
    "    print('Explained variance score {:0.2f}'.format(evs_))\n",
    "    return None\n",
    "\n",
    "def model_and_evaluate(X, y, clf=LinearRegression(), CVmethod=RFECV, **kwargs):\n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.20)\n",
    "\n",
    "    # Scale all of the data but only using only the training set to fit\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train, y_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize the cross validation method to pass to our CV protocol\n",
    "    model_ = CVmethod(clf, **kwargs)\n",
    "    \n",
    "    # Select and fit model based on cross-validated recursive feature elimination. \n",
    "    model_.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and analyse model with mean-squared error, explained-various and RFECV attributes\n",
    "    classifier_analysis(model_, X_test, y_test)\n",
    "    return model_, (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the regression of the recovered amount of money from charged-off loans, only the the data for charged-off loans\n",
    "is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('regression_loan_data.csv',index_col=False)\n",
    "\n",
    "#Still contains missing values; first, drop features with missing values (dropping samples leaves us with no data).\n",
    "loan_data = loan_data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction is occuring in the present moment. All of the data corresponding to charged-off loans can be used, and it does not have to be treated as a time series, as we are not trying to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Missing     257603\n",
       "Aug-2006        42\n",
       "Aug-2007        39\n",
       "Mar-2006        38\n",
       "May-2006        38\n",
       "             ...  \n",
       "Sep-1984         1\n",
       "Dec-1985         1\n",
       "May-1976         1\n",
       "Jun-1968         1\n",
       "Mar-1984         1\n",
       "Name: sec_app_earliest_cr_line, Length: 451, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.sec_app_earliest_cr_line.value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sec_app_earliest_cr_line     451\n",
       "issue_d                      137\n",
       "last_pymnt_d                 132\n",
       "last_credit_pull_d           114\n",
       "zip_code                     100\n",
       "settlement_date               89\n",
       "debt_settlement_flag_date     83\n",
       "earliest_cr_line              65\n",
       "addr_state                    51\n",
       "sub_grade                     35\n",
       "hardship_end_date             25\n",
       "hardship_start_date           25\n",
       "payment_plan_start_date       24\n",
       "purpose                       14\n",
       "emp_length                    12\n",
       "hardship_reason               10\n",
       "grade                          7\n",
       "home_ownership                 6\n",
       "hardship_loan_status           6\n",
       "verification_status_joint      4\n",
       "settlement_status              4\n",
       "hardship_status                4\n",
       "verification_status            3\n",
       "application_type               2\n",
       "initial_list_status            2\n",
       "hardship_flag                  2\n",
       "hardship_type                  2\n",
       "disbursement_method            2\n",
       "debt_settlement_flag           2\n",
       "term                           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.select_dtypes(include=['object','category']).nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261655, 52)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261655, 52)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.dropna(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to reduce the number of categories so that we can employ one hot encoding and still have a manageable amount of data;\n",
    "know from classification problem how we can deal with dates, at least when there are not missing values; issue_d, earliest_cr_line.\n",
    "When there are missing values; convert the non missing values to numerical and use KBinsDisc.. and then include the Missing\n",
    "values as a one-hot encoded category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign target/training variables\n",
    "y = loan_data.recoveries\n",
    "X = loan_data.drop(columns=['recoveries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=['object','category']).columns\n",
    "cat_features = X.select_dtypes(include=['object','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.loc[:,'zip_code'] = loan_data.zip_code.str.split('xx').str.join(sep='').apply(lambda x : x[:-1]).astype('category')\n",
    "loan_data.loc[:, 'earliest_cr_line'] = pd.to_datetime(loan_data.earliest_cr_line).dt.year.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_transformer = Pipeline(steps=[('scaler', StandardScaler()), ('encoder', KBinsDiscretizer())])\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "col_transformer = ColumnTransformer(transformers=[('num', num_transformer, num_features), \n",
    "                                                  ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories = [np.array(X[col].sort_values().unique().tolist()) for col in X.select_dtypes(include='object').columns]\n",
    "\n",
    "ohenc = OneHotEncoder(categories=unique_categories)\n",
    "cat_X_train_sparse = ohenc.fit_transform(cat_X_train)\n",
    "cat_X_test_sparse = ohenc.transform(cat_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclr = StandardScaler()\n",
    "numerical_X_train_scaled = sclr.fit_transform(numerical_X_train)\n",
    "numerical_X_test_scaled = sclr.transform(numerical_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipeline = Pipeline(steps=[('preprocess', col_transformer), ('classifier', Ridge())])\n",
    "sgd_pipeline = Pipeline(steps=[('preprocess', col_transformer), ('classifier', SGDClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "                    param_grid={'logisticregression__C': [0.1, 10.]},\n",
    "                    cv=2,\n",
    "                    refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid scores [0.01440052 0.02398066 0.22794159 0.22802398 0.25660907 0.29377674\n",
      " 0.29437993 0.30180923 0.32287637 0.32720689 0.34509231 0.34509229\n",
      " 0.34508347 0.34519487 0.34532442 0.34540255 0.34545715 0.34549758\n",
      " 0.34552857 0.34555112 0.3456515  0.34565983 0.34575382 0.34578151\n",
      " 0.34581119 0.34582871 0.34585572 0.34586926 0.34588983 0.34589936\n",
      " 0.34591497 0.34592242 0.34593034 0.34594197 0.34594949 0.34596088\n",
      " 0.34597073 0.34597957 0.34598294 0.34598338 0.34598488 0.34598611\n",
      " 0.34599391 0.34599786 0.34600069 0.34600931 0.34601406 0.34601631\n",
      " 0.34602045 0.34601544 0.34601893 0.34602173 0.34602508 0.34603021\n",
      " 0.34603226 0.34603324 0.34603298 0.34603758 0.34603951 0.34604212\n",
      " 0.34604295 0.34604204 0.34604337 0.34604333 0.34604314 0.34604262\n",
      " 0.34604282 0.34604299 0.34604299 0.34604251 0.34604265 0.34604269\n",
      " 0.34604269 0.34604269]\n",
      "Number of features selected by RFECV 63\n",
      "Mean squared error 341250.27\n",
      "Explained variance score 0.35\n"
     ]
    }
   ],
   "source": [
    "clf1 = LinearRegression()\n",
    "model1, split_data1 = model_and_evaluate(X_timeless, y, clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid scores [0.0146229  0.02429777 0.22938217 0.23508293 0.26522    0.29644831\n",
      " 0.29942201 0.32595813 0.32595805 0.3481662  0.34816557 0.34821974\n",
      " 0.34830391 0.3484388  0.34851153 0.34856195 0.34863916 0.3486853\n",
      " 0.34872824 0.34876667 0.34878449 0.34888069 0.34890857 0.34893048\n",
      " 0.3489524  0.34896748 0.34897992 0.34899571 0.34901677 0.34902638\n",
      " 0.3490469  0.34905682 0.34906698 0.34906836 0.34905595 0.34906613\n",
      " 0.34906439 0.34907778 0.34909091 0.34909601 0.34910428 0.34910763\n",
      " 0.34911481 0.34911958 0.34912317 0.34912468 0.34913002 0.34913738\n",
      " 0.3491367  0.34913125 0.34913488 0.34913976 0.34914159 0.34914875\n",
      " 0.34915397 0.34915567 0.34915734 0.34915834 0.34915943 0.34915843\n",
      " 0.3491597  0.34915892 0.34915944 0.34915833 0.34915896 0.34915977\n",
      " 0.3491599  0.34916031 0.34916064 0.34916112 0.34916107 0.34916117\n",
      " 0.34916117 0.34916117]\n",
      "Number of features selected by RFECV 74\n",
      "Mean squared error 343235.27\n",
      "Explained variance score 0.34\n"
     ]
    }
   ],
   "source": [
    "clf2 = Ridge()\n",
    "model2, split_data2 = model_and_evaluate(X_timeless, y, clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RFECV it filters the features then fits to the estimator using cross-validation to determine number of features.\n",
    "Essentially the function model_and_evaluate is equivalent to a pipeline in the following order: \n",
    "    \n",
    "    1. train_test_split \n",
    "    2. StandardScaler using only training data to fit \n",
    "    3. Scale test data \n",
    "    4. model = RFECV(classifier) fitting with training data\n",
    "    5. Predict with model and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
