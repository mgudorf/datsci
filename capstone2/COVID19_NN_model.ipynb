{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, mean_squared_error, make_scorer\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############### Helper functions in case of debugging/data introspection############\n",
    "\n",
    "def country_slice(data, locations):\n",
    "    if type(locations)==str:\n",
    "        return data[data.location==locations]\n",
    "    else:\n",
    "        return data[data.location.isin(locations)]\n",
    "    \n",
    "def time_slice(data, start, end, indexer='time_index'):\n",
    "    if start < 0 and end < 0:\n",
    "        if start == -1:\n",
    "            start = data.loc[:, indexer].max()\n",
    "        else:\n",
    "            start = data.loc[:, indexer].max()+start\n",
    "        if end == -1:\n",
    "            end = data.loc[:, indexer].max()\n",
    "        else:\n",
    "            end = data.loc[:, indexer].max()+end\n",
    "    return data[(data.loc[:, indexer] >= start) & (data.loc[:, indexer] <= end)]\n",
    "\n",
    "def per_country_plot(data, feature, legend=True):\n",
    "    data.set_index(['time_index', 'location']).loc[:, feature].unstack().plot(legend=legend)\n",
    "    return None\n",
    "\n",
    "def per_time_plot(data, feature, legend=True):\n",
    "    data.set_index(['location','time_index']).loc[:, feature].unstack().plot(legend=legend)\n",
    "    return None\n",
    "\n",
    "def country_groupby(df):\n",
    "    return [df[df.location==country].index for country in df.location.unique()]\n",
    "\n",
    "def country_search(df, country):\n",
    "    return df[df.location==country].index\n",
    "\n",
    "def column_search(df, name, return_style='loc', threshold='contains'):\n",
    "    if threshold=='contains':\n",
    "        func = df.columns.str.contains\n",
    "    else:\n",
    "        func = df.columns.str.match\n",
    "        \n",
    "    if return_style == 'loc':\n",
    "        return df.columns[func(name)]\n",
    "    elif return_style== 'iloc':\n",
    "        return np.where(func(name))[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def concatenate_4d_into_3d(splits, train_test_only=False):\n",
    "    \n",
    "    if train_test_only:\n",
    "        (X_train, y_train, X_test, y_test) = splits\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        concat_splits = (X_train, y_train, X_test, y_test) \n",
    "    else:\n",
    "        (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        X_validate = np.concatenate(X_validate, axis=0)\n",
    "        y_validate = np.concatenate(y_validate, axis=0)\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        concat_splits = (X_train, y_train, X_validate, y_validate, X_test, y_test) \n",
    "    return concat_splits\n",
    "\n",
    "def transpose_for_separable2d(splits, train_test_only=False):\n",
    "    if train_test_only:\n",
    "        (X_train, y_train, X_test, y_test) = splits\n",
    "        X_train = np.transpose(X_train, axes=[0,2,1,3])\n",
    "        X_test = np.transpose(X_test, axes=[0,2,1,3])\n",
    "        transpose_split = (X_train, y_train, X_test, y_test) \n",
    "    else:\n",
    "        (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "        X_train = np.transpose(X_train, axes=[0,2,1,3])\n",
    "        X_validate = np.transpose(X_validate, axes=[0,2,1,3])\n",
    "        X_test = np.transpose(X_test, axes=[0,2,1,3])\n",
    "        transpose_split = (X_train, y_train, X_validate, y_validate, X_test, y_test) \n",
    "    return transpose_split\n",
    "\n",
    "    \n",
    "def true_predict_plot(y_true, y_naive, y_predict, title='', suptitle='', scale=None,s=None):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "    if scale == 'log':\n",
    "        ymax = np.max([np.log(1+y_true).max(), np.log(1+y_predict).max()])\n",
    "        ax1.scatter(np.log(y_true+1), np.log(y_naive+1), s=s,alpha=0.7)\n",
    "        ax1.plot([0, ymax], [0, ymax],color='r')\n",
    "        ax2.scatter(np.log(y_true+1), np.log(y_predict+1), s=s,alpha=0.7)\n",
    "        ax2.plot([0, ymax], [0, ymax],color='r')\n",
    "    else:\n",
    "        ymax = np.max([y_true.max(), y_predict.max()])\n",
    "        ax1.scatter(y_true, y_naive, s=s)\n",
    "        ax1.plot([0, ymax], [0, ymax],color='r')\n",
    "        ax2.scatter(y_true, y_predict, s=s)\n",
    "        ax2.plot([0, ymax], [0, ymax],color='r')\n",
    "    ax1.set_xlabel('True value')\n",
    "    ax1.set_ylabel('Predicted value')\n",
    "    ax1.set_title('Naive model')\n",
    "\n",
    "    ax2.set_xlabel('True value')\n",
    "    ax2.set_ylabel('Predicted value')\n",
    "    ax2.set_title(title)\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def residual_plot(y_test, y_predict, title='', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, y_test-y_predict.ravel(), s=5)\n",
    "    ax.set_ylabel('Residual')\n",
    "    ax.set_xlabel('True value')\n",
    "    ax.grid(True)\n",
    "    return None\n",
    "\n",
    "def residual_diff_plots(y_true, y_naive, y_predict,n_days_into_future, n_countries, scale=None):\n",
    "    \n",
    "    # plot residuals in addition to the residual per country as\n",
    "    # line plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20,5), sharey=True)\n",
    "    (ax1,ax2) = axes.flatten()\n",
    "    xrange = range(len(y_true))\n",
    "    if scale=='log':\n",
    "        residual_plot(np.log(y_true+1),np.log(y_naive+1), ax=ax1)\n",
    "        residual_plot(np.log(y_true+1),np.log(y_predict+1), ax=ax2)\n",
    "    else:\n",
    "        residual_plot(y_true,y_naive, ax=ax1)\n",
    "        residual_plot(y_true,y_predict, ax=ax2)\n",
    "#     fig.suptitle('{}-day-into-future predictions'.format(n_days_into_future))\n",
    "    ax1.set_title('')\n",
    "    ax2.set_title('')\n",
    "    ax1.set_ylabel('Residual')\n",
    "    ax2.set_ylabel('Residual')\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def create_Xy(model_data, target_data, time_index, start_date, frame_size, n_days_into_future, n_countries):\n",
    "    for max_date_in_window in range(start_date, time_index.max() - n_days_into_future + 2):\n",
    "        # Take all model_data with date proxy less than numerical value, leading_window_date_not_included\n",
    "        frame_data = model_data[(time_index <= max_date_in_window-1) & \n",
    "                                (time_index >= max_date_in_window-frame_size)]\n",
    "\n",
    "        reshaped_frame_data = frame_data.values.reshape(n_countries, frame_size, -1)\n",
    "\n",
    "        resized_frame_data = pad_sequences(reshaped_frame_data, maxlen=frame_size, dtype=np.float64)\n",
    "        frame_data_4D = resized_frame_data[np.newaxis, :, :, :]\n",
    "        if max_date_in_window == start_date:\n",
    "            print('Starting with frame ranging time_index values:', max_date_in_window-frame_size, max_date_in_window - 1)\n",
    "            X = frame_data_4D.copy()\n",
    "        else:\n",
    "            X = np.concatenate((X, frame_data_4D),axis=0)\n",
    "    print('Ending with frame ranging time_index values:', max_date_in_window-frame_size, max_date_in_window - 1)\n",
    "    y = target_data.values.reshape(-1, time_index.nunique()).transpose()[-X.shape[0]:,:]\n",
    "    return X, y\n",
    "\n",
    "def split_Xy(X, y, frame_size, n_validation_frames, n_test_frames, train_test_only=False, model_type='cnn'):\n",
    "    \"\"\" Split into training, validation and test data.\n",
    "    \"\"\"\n",
    "    # the indices for the train-validate-test splits for when the predictors are put in a 2-d format.\n",
    "    train_indices = list(range(n_countries*0, n_countries*(len(X)-(n_validation_frames+n_test_frames))))\n",
    "    validate_indices = list(range(n_countries*(len(X)-(n_validation_frames+n_test_frames)), n_countries*(len(X)-n_test_frames)))\n",
    "    test_indices = list(range(n_countries*(len(X)-n_test_frames), n_countries*len(X)))\n",
    "    indices = (train_indices, validate_indices, test_indices)\n",
    "\n",
    "    # Note that the last frame (date_range) that exists in X has already been determined by the choice of the number\n",
    "    # of steps to predict in the future, this is only slicing the frames. \n",
    "    if train_test_only:\n",
    "        X_train= X[:-n_test_frames,:,:,:]\n",
    "        y_train =  y[:-n_test_frames,:]\n",
    "        X_test = X[-n_test_frames:, :, :, :] \n",
    "        y_test = y[-n_test_frames:, :]\n",
    "        splits =  (X_train, y_train, X_test, y_test)\n",
    "    else:\n",
    "        y_train =  y[:-(n_validation_frames+n_test_frames),:]\n",
    "        y_validate = y[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "        X_train= X[:-(n_validation_frames+n_test_frames),:,:,:]\n",
    "        y_train =  y[:-(n_validation_frames+n_test_frames),:]\n",
    "        X_validate = X[-(n_validation_frames+n_test_frames):-n_test_frames, :, :, :]\n",
    "        y_validate = y[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "        X_test = X[-n_test_frames:, :, :, :] \n",
    "        y_test = y[-n_test_frames:, :]\n",
    "        splits =  (X_train, y_train, X_validate, y_validate,\n",
    "                   X_test, y_test)\n",
    "\n",
    "    return splits, indices\n",
    "\n",
    "\n",
    "def flatten_Xy(splits):\n",
    "    (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "    X_train_flat =np.concatenate(X_train.reshape(X_train.shape[0], X_train.shape[1], -1), axis=0)\n",
    "    X_validate_flat =np.concatenate(X_validate.reshape(X_validate.shape[0], X_validate.shape[1], -1), axis=0)\n",
    "    X_test_flat =np.concatenate(X_test.reshape(X_test.shape[0], X_test.shape[1], -1), axis=0)\n",
    "    y_train_flat = y_train.ravel()\n",
    "    y_validate_flat = y_validate.ravel()\n",
    "    y_test_flat = y_test.ravel()\n",
    "    flat_splits = (X_train_flat , y_train_flat , X_validate_flat , y_validate_flat , X_test_flat , y_test_flat )\n",
    "    return flat_splits\n",
    "\n",
    "def model_analysis(y_true, y_naive, y_predict, n_countries, title='',suptitle='',figname=None, scale=None, s=None):\n",
    "    print('There were {} negative predictions'.format(len(y_predict[y_predict<0])))\n",
    "    #     y_predict[y_predict<0]=0\n",
    "    # compute scores \n",
    "    mse_naive = mean_squared_error(y_true.ravel(), y_naive.ravel())\n",
    "    mse_predict = mean_squared_error(y_true.ravel(), y_predict)\n",
    "    r2_naive = explained_variance_score(y_true.ravel(), y_naive.ravel())\n",
    "    r2_predict = explained_variance_score(y_true.ravel(), y_predict)\n",
    "\n",
    "    print('{}-step MSE [Naive, {}] = [{},{}]'.format(\n",
    "    n_days_into_future,title, mse_naive, mse_predict))\n",
    "    print('{}-step R^2 [Naive, {}] = [{},{}]'.format(\n",
    "    n_days_into_future,title, r2_naive, r2_predict))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15,10))\n",
    "    (ax1,ax2,ax3,ax4) = axes.flatten()\n",
    "    if scale == 'log':\n",
    "        ymax = np.max([np.log(1+y_true).max(), np.log(1+y_predict).max()])\n",
    "        ax1.scatter(np.log(y_true+1), np.log(y_naive+1), s=s,alpha=0.7)\n",
    "        ax1.plot([0, ymax], [0, ymax],color='r')\n",
    "        ax2.scatter(np.log(y_true+1), np.log(y_predict+1), s=s,alpha=0.7)\n",
    "        ax2.plot([0, ymax], [0, ymax],color='r')\n",
    "    else:\n",
    "        ymax = np.max([y_true.max(), y_predict.max()])\n",
    "        ax1.scatter(y_true, y_naive, s=s)\n",
    "        ax1.plot([0, ymax], [0, ymax],color='r')\n",
    "        ax2.scatter(y_true, y_predict, s=s)\n",
    "        ax2.plot([0, ymax], [0, ymax],color='r')\n",
    "    \n",
    "    ax1.text(0.0, ymax,'$MSE$ = {}'.format(np.round(mse_naive,3)),fontsize=14)\n",
    "    ax1.text(0.0, 0.9*ymax,'$R^2$ = {}'.format(np.round(r2_naive,3)),fontsize=14)\n",
    "    ax1.set_xlabel('True value')\n",
    "    ax1.set_ylabel('Predicted value')\n",
    "    ax1.set_title('Naive model')\n",
    "             \n",
    "    ax2.text(0.0, ymax,'$MSE$ = {}'.format(np.round(mse_predict,3)),fontsize=14)\n",
    "    ax2.text(0.0, 0.9*ymax,'$R^2$ = {}'.format(np.round(r2_predict,3)),fontsize=14)\n",
    "    ax2.set_xlabel('True value')\n",
    "    ax2.set_ylabel('Predicted value')\n",
    "    ax2.set_title(title)\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    \n",
    "    xrange = range(len(y_true))\n",
    "    if scale=='log':\n",
    "        residual_plot(np.log(y_true+1),np.log(y_naive+1), ax=ax3)\n",
    "        residual_plot(np.log(y_true+1),np.log(y_predict+1), ax=ax4)\n",
    "    else:\n",
    "        residual_plot(y_true,y_naive, ax=ax3)\n",
    "        residual_plot(y_true,y_predict, ax=ax4)\n",
    "    ax3.set_title('')\n",
    "    ax4.set_title('')\n",
    "    ax3.set_ylabel('Residual')\n",
    "    ax4.set_ylabel('Residual')\n",
    "    ax3.grid(True)\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    if figname is not None:\n",
    "        plt.savefig(figname, bbox_inches='tight')\n",
    "        \n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_Xy(splits, feature_range=(0., 1.0), normalization_method='minmax',\n",
    "                        train_test_only=False, feature_indices=None):\n",
    "    \"\"\" Split into training, validation and test data.\n",
    "    Normalize with respect to some absolute max, just choose 2*absolute max of training set. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    min_, max_ = feature_range\n",
    "    (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "    feature_minima = X_train[:,:,:,:].min((0,1,2))[np.newaxis,np.newaxis,np.newaxis,:]\n",
    "    feature_maxima = 2*X_train[:,:,:,:].max((0,1,2))[np.newaxis,np.newaxis,np.newaxis,:]\n",
    "    feature_denominator = feature_maxima-feature_minima\n",
    "    # get the shape of each split's array, so that array arithmetic can be done. \n",
    "    train_tile_shape = np.array(np.array(X_train.shape)/np.array(feature_maxima.shape),int)\n",
    "    validate_tile_shape = np.array(np.array(X_validate.shape)/np.array(feature_maxima.shape),int)\n",
    "    test_tile_shape = np.array(np.array(X_test.shape)/np.array(feature_maxima.shape),int)\n",
    "\n",
    "    # using X - X_min / (X_max-X_min). Form denominator\n",
    "    train_denominator = np.tile(feature_denominator, train_tile_shape)\n",
    "    validate_denominator = np.tile(feature_denominator, validate_tile_shape)\n",
    "    test_denominator = np.tile(feature_denominator, test_tile_shape)\n",
    "    \n",
    "    # and then the minima.\n",
    "    train_minima = np.tile(feature_minima,train_tile_shape)\n",
    "    validate_minima = np.tile(feature_minima,validate_tile_shape)\n",
    "    test_minima = np.tile(feature_minima,test_tile_shape)\n",
    "    \n",
    "    # factor of 1/max_ accounts for absolute maximum that is outside of the data (i.e. potential future values). \n",
    "    X_train_scaled = (max_-min_)*(X_train - train_minima)/train_denominator\n",
    "    X_validate_scaled = (max_-min_)*(X_validate - validate_minima)/validate_denominator\n",
    "    X_test_scaled = (max_-min_)*(X_test - test_minima)/test_denominator\n",
    "\n",
    "    \n",
    "    scaled_splits = (X_train_scaled, y_train, X_validate_scaled, y_validate, X_test_scaled, y_test) \n",
    "    scaling_arrays =  (feature_maxima, feature_minima, feature_denominator)\n",
    "\n",
    "    return scaled_splits, scaling_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned data produced by other notebook. \n",
    "data = pd.read_csv('cnn_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same data as the other models, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('regression_data.csv', index_col=0)\n",
    "tmp =pd.read_csv('regression_data_full.csv', index_col=0)\n",
    "data = pd.concat((data,tmp.loc[:, column_search(tmp,'government_response')]),axis=1)\n",
    "data = data.drop(columns=['date'])\n",
    "data = data.drop(columns=column_search(data,'test'))\n",
    "data = data.drop(columns=column_search(data,'deaths'))\n",
    "data = data.drop(columns=column_search(data,'recovered'))\n",
    "# data = data.drop(columns=column_search(data,'log'))\n",
    "data = data.drop(columns=column_search(data,'std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "<a id='data'></a>\n",
    "[Return to table of contents](#toc)\n",
    "\n",
    "Per the distribution of pandemic starting dates, vast majority of countries have cases by day (time_index) 60. Therefore,\n",
    "truncate the days before this value and truncate the countries which have no cases as of that date.\n",
    "\n",
    "Want to include only time windows in which all countries have one confirmed case. Unfortunately this would reduce the amount of data samples. There are choices to be made which keep the most countries but also the most relevant dates. There are 132 countries in the dataset, 121 of these have  \n",
    "\n",
    "Want the dates where most countries have cases, but the date where *all* countries have dates would dramatically reduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26718, 13), (17229, 13))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data[data.days_since_first_case >= 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not use sub-components of the stringency index; also, the new tests per million feature\n",
    "has differing units between countries and so it will be unreliable. Likewise, the number of new recovered and\n",
    "deaths per million are time delayed quantities and so they are might not be useful for next-day predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data creation is the same as in the notebook ```COVID19_model_prototypes.ipynb```. See that notebook for details. Previously, frame size was set to 28. By setting it to 14, get $14*n_{countries}$ more samples as well as fewer input dimensions such that the number of model parameters will be smaller. This size still captures seasonality as well as the time delayed nature of the pandemic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.time_index>=40]\n",
    "model_data = data.copy().iloc[:, 3:]\n",
    "modeling_features = ['new_cases_per_million', 'government_response_index', 'log_new_cases_per_million']\n",
    "model_data = data.copy().loc[:, modeling_features]\n",
    "new_cases_index = column_search(model_data,'new_cases_per_million', threshold='match', return_style='iloc')[0]\n",
    "n_countries = data.location.nunique()\n",
    "target_data = data.new_cases_per_million\n",
    "time_index = data.time_index\n",
    "\n",
    "frame_size = 28\n",
    "start_date = frame_size + data.time_index.min()\n",
    "\n",
    "n_validation_frames = 7\n",
    "n_test_frames = 1\n",
    "n_days_into_future = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with frame ranging time_index values: 0 27\n",
      "Ending with frame ranging time_index values: 154 181\n"
     ]
    }
   ],
   "source": [
    "X, y = create_Xy(model_data, target_data, time_index, start_date, frame_size, n_days_into_future, n_countries)\n",
    "splits, indices = split_Xy(X, y, frame_size, n_validation_frames, n_test_frames)\n",
    "\n",
    "scaled_splits, scaling_arrays =  normalize_Xy(splits, feature_range=(0,1.0), \n",
    "                                                                  normalization_method='minmax',\n",
    "                                                                  train_test_only=False,\n",
    "                                                                  feature_indices=None)\n",
    "# if need to supply folds for sklearn CV regression functions.\n",
    "(X_nn_train, y_nn_train, X_nn_validate, y_nn_validate, X_nn_test, y_nn_test) = scaled_splits\n",
    "(train_indices, validate_indices, test_indices) = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 183, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_countries = data.location.nunique()\n",
    "n_dates = data.time_index.nunique()\n",
    "n_features = model_data.columns.size\n",
    "n_countries, n_dates, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check that I'm still splitting the data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_scaled_tmp = np.concatenate((X_nn_train,X_nn_validate,X_nn_test), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
    "ax.scatter(range(len(X_scaled_tmp)), X_scaled_tmp[:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=100,color='k', label='original')\n",
    "ax.scatter(range(len(scaled_splits[0])), scaled_splits[0][:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=30, label='train')\n",
    "ax.scatter(range(len(scaled_splits[0]), len(scaled_splits[0])+len(scaled_splits[2])), scaled_splits[2][:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=30, label='validate')\n",
    "ax.scatter(range(len(scaled_splits[0])+len(scaled_splits[2]), len(X)), X_nn_test[:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=30, label='test')\n",
    "plt.legend()\n",
    "plt.ylabel('New cases per million, scaled')\n",
    "plt.xlabel('Time index')\n",
    "plt.savefig('nn_train_test_split.jpg', bbox_inches='tight')\n",
    "_ = plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten and produce the naive baseline quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_splits = flatten_Xy(scaled_splits)\n",
    "(X_nn_train_model,y_nn_train_model,X_nn_validate_model,\n",
    " y_nn_validate_model,X_nn_test_model,y_nn_test_model) = flat_splits\n",
    "X_for_naive_slicing = np.concatenate(X.reshape(X.shape[0], X.shape[1], -1), axis=0)\n",
    "n_features = X.shape[-1]\n",
    "last_day_new_cases_index = np.ravel_multi_index([[frame_size-1],[new_cases_index]],(frame_size, n_features))\n",
    "y_train_naive = X_for_naive_slicing[train_indices, last_day_new_cases_index].ravel()\n",
    "y_validate_naive =  X_for_naive_slicing[validate_indices, last_day_new_cases_index].ravel()\n",
    "y_test_naive =  X_for_naive_slicing[test_indices, last_day_new_cases_index].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the combinations of hyperparameters to search for the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = [200]\n",
    "batch_size_list = [64]\n",
    "first_layer_output_dimension_list = [2,4,6,8,12,16,24,32]\n",
    "parameter_combinations = list(itertools.product(epochs_list, batch_size_list, first_layer_output_dimension_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that redundant, time consuming calculations are not performed every notebook run, create a crude\n",
    "logging system such that the model is only fit with a certain set of parameters if hasn't been done in the past, as\n",
    "indicated by the presence of a score in the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('nn_score_logging.csv'):\n",
    "    score_logging_df = pd.read_csv('nn_score_logging.csv', index_col=0)\n",
    "else:\n",
    "    score_logging_df = pd.DataFrame(np.array(parameter_combinations), \n",
    "                                    columns=['epochs','batch_size','first_layer_output_dimension_list'])\n",
    "    score_logging_df.loc[:, 'mean_squared_error'] = np.nan\n",
    "    score_logging_df.loc[:, 'mean_absolute_error'] = np.nan\n",
    "    score_logging_df.loc[:, 'explained_variance'] = np.nan\n",
    "    score_logging_df.loc[:, 'naive_mean_absolute_error'] = np.nan\n",
    "    score_logging_df.loc[:, 'naive_explained_variance'] = np.nan\n",
    "    score_logging_df.loc[:, 'naive_mean_squared_error'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network model \n",
    "<a id='model'></a>\n",
    "[Return to table of contents](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution will be with respect to time, specifically the time steps within frames of time of predetermined length. The architecture of the CNN itself is two convolutional layers followed by two dense layers, ending with a ReLU activation layer. The key pieces of information to keep in mind when creating the neural network models are that I need to keep the parameter number small to account for the relatively small number of samples, to include only most important time dependent features and to make sure time ordering is respected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_seeds = [0,1,2]\n",
    "one_seeds = [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "for i, hyper_parameters in enumerate(parameter_combinations):\n",
    "    (epochs, batch_size, first_layer_output_dimension) = hyper_parameters\n",
    "    mse_list = []\n",
    "    naive_mse_list = []\n",
    "    explained_variance_list = []\n",
    "    naive_explained_variance_list = []\n",
    "    mae_list = []\n",
    "    naive_mae_list = []\n",
    "    if score_logging_df.isna().loc[i,'mean_squared_error']:\n",
    "        for j in range(len(zero_seeds)):\n",
    "            nn_input = Input(shape=(np.prod(X_nn_train.shape[2:]),))\n",
    "            flat = Flatten()(nn_input)\n",
    "            dense0 = Dense(int(first_layer_output_dimension), \n",
    "                            use_bias=False,\n",
    "                           kernel_initializer=RandomNormal(seed=zero_seeds[j]),\n",
    "                           )(flat)\n",
    "            dense1 = Dense(1, \n",
    "                            activation='relu',\n",
    "                            use_bias=False,\n",
    "                           kernel_initializer=RandomNormal(seed=one_seeds[j]),\n",
    "                           )(dense0)\n",
    "\n",
    "            nn = Model(inputs=nn_input, outputs=dense1)\n",
    "            nn.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "            history = nn.fit(X_nn_train_model, y_nn_train_model, epochs=epochs, validation_data=(X_nn_validate_model, y_nn_validate_model), \n",
    "                      batch_size=batch_size, verbose=0)\n",
    "\n",
    "            y_true = y_nn_validate_model.ravel()\n",
    "            y_predict = nn.predict(X_nn_validate_model).ravel()\n",
    "            y_naive = y_validate_naive.ravel()\n",
    "\n",
    "            # mean squared errors\n",
    "            naive_mse_list.append(mean_squared_error(y_true.ravel(), y_naive.ravel()))\n",
    "            mse_list.append(mean_squared_error(y_true.ravel(), y_predict))\n",
    "            # explained variance\n",
    "            naive_explained_variance_list.append(explained_variance_score(y_true.ravel(), y_naive.ravel()))\n",
    "            explained_variance_list.append(explained_variance_score(y_true.ravel(), y_predict))\n",
    "            # mean absolute error\n",
    "            mae_list.append(mean_absolute_error(y_true.ravel(), y_predict))\n",
    "            naive_mae_list.append(mean_absolute_error(y_true.ravel(), y_naive.ravel()))\n",
    "\n",
    "        score_logging_df.loc[i,'naive_mean_squared_error'] =  np.mean(naive_mse_list)\n",
    "        score_logging_df.loc[i,'mean_squared_error']  = np.mean(mse_list)\n",
    "        score_logging_df.loc[i,'naive_explained_variance']  = np.mean(naive_explained_variance_list)\n",
    "        score_logging_df.loc[i,'explained_variance']  = np.mean(explained_variance_list)\n",
    "        score_logging_df.loc[i,'naive_mean_absolute_error']  =np.mean(naive_mae_list)\n",
    "        score_logging_df.loc[i,'mean_absolute_error']  = np.mean(mae_list)\n",
    "        # every time a new score is calculated, overwrite the original file, to save space but also save progress scoring.\n",
    "        score_logging_df.to_csv('nn_score_logging.csv')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    print('#',end='')\n",
    "    if (i % 50 == 0) & i>0:\n",
    "          print('{} runs completed'.format(str(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the parameters and scores of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_logging_df.loc[score_logging_df.mean_squared_error.idxmin(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this does not beat the naive baseline (the scores are with respect to the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_parameters = score_logging_df.loc[score_logging_df.mean_squared_error.idxmin(),:].iloc[:3]\n",
    "print(best_model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again with a different seed, see if all hope is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_train = np.concatenate((X_nn_train_model, X_nn_validate_model),axis=0)\n",
    "y_final_train = np.concatenate((y_nn_train_model, y_nn_validate_model),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_final_0 = RandomNormal(seed=8)\n",
    "kernel_final_1 = RandomNormal(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs, batch_size, first_layer_output_dimension) = best_model_parameters\n",
    "epochs =  1500\n",
    "nn_input = Input(shape=(np.prod(X_nn_train.shape[2:]),))\n",
    "flat = Flatten()(nn_input)\n",
    "dense0 = Dense(first_layer_output_dimension, \n",
    "                use_bias=False,\n",
    "               kernel_initializer=kernel_final_0,\n",
    "               )(flat)\n",
    "dense1 = Dense(1, \n",
    "                activation='relu',\n",
    "                use_bias=False,\n",
    "              kernel_initializer=kernel_final_1,\n",
    "               )(dense0)\n",
    "\n",
    "\n",
    "best_nn = Model(inputs=nn_input, outputs=dense1)\n",
    "best_nn.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_nn.fit(X_final_train, y_final_train, epochs=int(epochs),\n",
    "                      validation_data=(X_nn_test_model, y_nn_test_model), \n",
    "          batch_size=int(batch_size), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and conclusion\n",
    "<a id='conclusion'></a>\n",
    "[Return to table of contents](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(history.history['loss'], label='loss')\n",
    "_ = plt.plot(history.history['val_loss'], label='val_loss')\n",
    "_ = plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(history.history['loss'][-50:], label='loss')\n",
    "_ = plt.plot(history.history['val_loss'][-50:], label='val_loss')\n",
    "_ = plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions made on the training set (for determining whether or not we overtraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_final_train.ravel()\n",
    "y_naive = np.concatenate((y_train_naive, y_validate_naive),axis=0)\n",
    "y_predict = best_nn.predict(X_final_train).ravel()\n",
    "model_analysis(y_true, y_naive, y_predict, n_countries, title='NN model',\n",
    "               suptitle='Naive baseline vs. predictions of training set',\n",
    "              figname='nn_training_performance.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions made on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_nn_test_model.ravel()\n",
    "y_predict = best_nn.predict(X_nn_test_model).ravel()\n",
    "model_analysis(y_true, y_test_naive, y_predict, n_countries, title='NN model',\n",
    "               suptitle='Naive baseline vs. predictions of testing set',\n",
    "              figname='nn_test_performance.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions made on the hold-out set (final evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, it seems that the neural network model in its current form is unable of producing accurate predictions that beat a simple naive baseline model. In fact, the average performance is much worse than the naive baseline, as indicated by the scoring distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_logging_df.loc[:,column_search(score_logging_df,'squared')].plot.hist(alpha=0.5, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work\n",
    "Make all windows vary in lengths between different batches. \n",
    "https://datascience.stackexchange.com/questions/26366/training-an-rnn-with-examples-of-different-lengths-in-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
