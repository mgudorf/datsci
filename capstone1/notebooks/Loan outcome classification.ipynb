{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, plot_precision_recall_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, Binarizer, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import average_precision_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from joblib import Parallel, delayed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that combines different classification metrics to avoid repeated large blocks of code.\n",
    "# Produces the confusion matrix, classification report (precision, recall, f1-score,..)\n",
    "# ROC-AUC and ROC curve\n",
    "# Precision-recall curve\n",
    "\n",
    "def classifier_analysis(clf, X_test, y_test):\n",
    "    y_predict = clf.predict(X_test_processed)\n",
    "    y_predict_proba= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print('tn, fp, fn, tp', cm.ravel())\n",
    "    _ = ConfusionMatrixDisplay(cm, [0,1]).plot()\n",
    "    \n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "    logit_roc_auc = roc_auc_score(y_test, y_predict_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict_proba)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=(clf.__class__.__name__ + '(area = %0.2f)' % logit_roc_auc))\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    average_precision = average_precision_score(y_test, y_predict_proba)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_predict_proba)\n",
    "    disp = plot_precision_recall_curve(clf, X_test_processed, y_test)\n",
    "    disp.ax_.set_ylim([0.0, 1.0])\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "    plt.show()\n",
    "    \n",
    "    return clf\n",
    "\n",
    "\n",
    "# Convert date-like + 'Missing' valued features to one-hot encoded columns; uses KBins on the years of the date-like, which \n",
    "# bins then one-hot encodes, while also one-hot encoding 'Missing' separately. \n",
    "def encode_dates_and_missing(df):\n",
    "    for i, seriesname in enumerate(df.columns):\n",
    "        series = df[seriesname]\n",
    "        series_missing = pd.get_dummies(series[series=='Missing'])\n",
    "        series_notmissing = series[series!='Missing']\n",
    "        notmiss_index =series_notmissing.index\n",
    "        \n",
    "        kbd = KBinsDiscretizer(n_bins=3, strategy='uniform')\n",
    "        series_dt = pd.to_datetime(series_notmissing).dt.year\n",
    "        encoded_series = kbd.fit_transform(series_dt.values.reshape(-1,1))\n",
    "        encoded_series = pd.DataFrame(kbd.fit_transform(series_dt.values.reshape(-1,1)).toarray(),index=notmiss_index).astype(int)\n",
    "        encoded_series = encoded_series.join(series_missing, how='outer').fillna(value=0)\n",
    "        encoded_series.columns = [seriesname+'_'+str(col) for col in encoded_series.columns]\n",
    "        \n",
    "        if i == 0: \n",
    "            encoded_df = encoded_series\n",
    "        else:\n",
    "            encoded_df = pd.concat((encoded_df,encoded_series),axis=1)\n",
    "            \n",
    "    return encoded_df\n",
    "\n",
    "\n",
    "def model_and_analyze_in_parallel(clf, X_traintest, y_traintest):\n",
    "    # Initialize the cross-validation method\n",
    "    kf = KFold(n_splits=3)\n",
    "    \n",
    "    # Using joblib, run my cross validation function; it scales feature and target data in the correct way \n",
    "    # in combination with cross validation.\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "        results = parallel(delayed(my_cross_validate)(clf, X_traintest, y_traintest, train, test)\n",
    "                              for (train, test) in kf.split(X_traintest, y_traintest))\n",
    "        \n",
    "    # Get the results, then score the models (explained variance score)\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "        scores = parallel(delayed(my_score)(model_, xt, yt) for (model_, xt, yt) in results)\n",
    "    \n",
    "    # Using all of the traintest data; transform both the traintest and holdout data sets.\n",
    "    X_traintest_final, X_holdout_final, cscaler = feature_scaler(col_transformer, X_traintest, X_holdout)\n",
    "    y_traintest_final, y_holdout_final, tscaler = target_scaler(y_traintest.values.ravel(), y_holdout.values.ravel())\n",
    "    best_model = results[np.argmax(scores)][0]\n",
    "    \n",
    "    # Print final scores and plot the y_true vs y_pred\n",
    "    classifier_analysis(best_model, X_holdout_final, y_holdout_final)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_feature_transformer(X, num_features, cat_features, date_features, num_transformer=MinMaxScaler()):\n",
    "\n",
    "    uniq_categories = [list(np.sort(X[col].unique()))+['Missing','Unknown'] for col in cat_features]\n",
    "\n",
    "    cat_transformer = OneHotEncoder(categories=uniq_categories, handle_unknown='ignore')\n",
    "    col_transformer = ColumnTransformer(transformers=[('num', num_transformer, num_features), \n",
    "                                                      ('cat', cat_transformer, cat_features),\n",
    "                                                     ('my_kbd', 'passthrough', date_features)])\n",
    "    \n",
    "    return col_transformer\n",
    "\n",
    "# Dummy function to make notation consistent and uniform\n",
    "def my_target_transformer(y):\n",
    "    return QuantileTransformer()\n",
    "    \n",
    "def scale_features(col_transformer_, X_train, X_test):\n",
    "    _ = col_transformer_.fit(X_train)\n",
    "    X_train = col_transformer_.transform(X_train)\n",
    "    X_test = col_transformer_.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def scale_target(target_transformer_, y_train, y_test):\n",
    "    _ = target_transformer_.fit(y_train.reshape(-1,1))\n",
    "\n",
    "    y_train = target_transformer_.transform(y_train.reshape(-1,1))\n",
    "    y_test = target_transformer_.transform(y_test.reshape(-1,1))    \n",
    "    return y_train.ravel(), y_test.ravel()\n",
    "\n",
    "# This isn't cross validation its just model training. Cross-validation averages over the trained models of a parameter value\n",
    "def my_cross_validate(estimator, col_transformer_, target_transformer_, X_traintest, y_traintest, param_grid):\n",
    "    mean_scores = []\n",
    "    \n",
    "    time_ordered_traintest = \n",
    "    # cv_params needs to make sense for the estimator given\n",
    "    param_grid_list = param_grid_iterable(param_grid)\n",
    "    for params_ in param_grid_list:\n",
    "        with Parallel(n_jobs=-1) as parallel:\n",
    "            fitted_models_and_test_splits = parallel(delayed(fit_model_)(estimator(**params_), col_transformer_, target_transformer_,\n",
    "                                                          X_traintest, y_traintest, train, test)\n",
    "                                  for (train, test) in )\n",
    "            # Get averages (explained variance) score for this model\n",
    "            scores = parallel(delayed(my_score)(model_, xt, yt) for (model_, xt, yt) in fitted_models_and_test_splits) \n",
    "            mean_scores += [np.mean(list(scores))]\n",
    "            \n",
    "    \n",
    "    best_params_ = param_grid_list[np.argmax(np.array(mean_scores))]\n",
    "    return estimator(**best_params_) \n",
    "\n",
    "\n",
    "def fit_model_(estimator, col_transformer_, target_transformer_, X_traintest, y_traintest, train, test):\n",
    "    X_train, X_test = X_traintest.loc[train,:], X_traintest.loc[test,:]\n",
    "    y_train, y_test = y_traintest.loc[train].values.ravel(), y_traintest.loc[test].values.ravel()\n",
    "    \n",
    "    X_train, X_test  = scale_features(col_transformer_, X_train, X_test)\n",
    "    y_train, y_test = scale_target(target_transformer_, y_train, y_test)\n",
    "\n",
    "    _ = estimator.fit(X_train, y_train)    \n",
    "    return (estimator, X_test, y_test)\n",
    "\n",
    "def param_grid_iterable(params):\n",
    "    keys = sorted(params)\n",
    "    combinations = list(itertools.product(*(params[key] if type(params[key]) in [list, dict, np.ndarray] else [params[key]]\n",
    "                                            for key in keys)))\n",
    "    cvsorted = [dict(zip(len(c)*keys, c)) for c in combinations]\n",
    "    return cvsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest and Logistic Regression modeling of loan status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('classification_loan_data.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to take into consideration the time dependence element of this problem. Because we want to predict whether or not\n",
    "to issue a loan, need to take into consideration the time series nature of the issuance date. The main consideration is during the cross-validation process later but reorder the data now as it will later be transformed by one-hot encoding. Specifically, it will be stored in a sparse matrix which is harder to manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will be deprecated after newest data cleaning run. \n",
    "issued_datetime = pd.to_datetime(loan_data.issue_d)\n",
    "\n",
    "loan_data = loan_data.loc[issued_datetime.sort_values().index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a \"hold-out\" set of data that will used for final predictions and analysis after all cross-validation and\n",
    "model learning has been accomplished. The loan issuance dates are aggregated by month, but from the metadata we know that the data is reported *quarterly*. Using this as motivation, the hold-out data will be the most recent quarter. Because the number of loans has grown over time, this one quarter represents nearly $1 / 7$ of all loan data of loans that have either been fully paid or charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data goes from second quarter of 2007 to fourth quarter of 2015; the number of samples are skewed toawrds later dates;\n",
    "# The data is reported quarterly; this should be represented in the cross validation/model selection process.\n",
    "pind = pd.PeriodIndex(issued_datetime, freq='Q-DEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KBins needs numerical variables; use year.quarter (number.decimal). This transformation is not applied to the training data; it's just used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the year to the decimal representing the quarter; Q1 = 0.0 , Q2 = 0.25, Q3 = 0.50, Q4 = 0.75\n",
    "numerical_quarters = pind.year + (pind.quarter - 1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=6\n",
    "kbd = KBinsDiscretizer(n_bins=nb)\n",
    "bin_masks = kbd.fit_transform(numerical_quarters.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93153.,  90943., 115805., 147183.,  64222., 162063.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bin_masks, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn wants iterable containing (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [loan_data.index[np.array(np.sum(bin_masks[:,:i+1],axis=1), dtype=bool)]  for i in range(nb-1)]\n",
    "test_indices = [loan_data.index[np.array(bin_masks[:,i+1], dtype=bool)]  for i in range(nb-1)]\n",
    "train_test_iterable = list(zip(train_indices,test_indices))\n",
    "holdout_train = loan_data.index[np.array(np.sum(bin_masks[:,:-1],axis=1), dtype=bool)] \n",
    "holdout_test = loan_data.index[np.array(bin_masks[:, -1], dtype=bool)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the cross validation folds, now need to create procedure which correctly preprocesses them before testing. Training component of folds are cumulative over time; always want to use as much information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many values for the dates of the earliest credit known credit lines and zip codes; too many at least for one-hot encoding to be practical. Therefore, group zip_code by the first two digits as this retains the geographical information and group the earliest credit_line by using KBinsDiscretizer on the year; it needs a numerical value so the entire date cannot be used without modification. The reason for KBinsDiscretizer is that the distribution is not uniform over time, and it presents an unbiased selection/grouping method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data.drop(columns='zip_code')\n",
    "# loan_data.loc[:,'zip_code'] = loan_data.zip_code.str.split('xx').str.join(sep='').apply(lambda x : x[:-1])#.astype('category')\n",
    "# loan_data.loc[:, 'earliest_cr_line'] = pd.to_datetime(loan_data.earliest_cr_line).dt.year.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dates = encode_dates_and_missing(loan_data.loc[:, 'earliest_cr_line'].to_frame(name='earliest_cr_line'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.concat((loan_data.drop(columns=['earliest_cr_line']), encoded_dates),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = loan_data.loan_status.astype(int)\n",
    "X = loan_data.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=['object','category']).columns\n",
    "cat_features = X.select_dtypes(include=['object','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_categories = [list(np.sort(X[col].unique()))+['Missing','Unknown'] for col in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_transformer = Pipeline(steps=[('scaler', StandardScaler()), ('encoder', KBinsDiscretizer())])\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(categories=uniq_categories,handle_unknown='ignore')\n",
    "col_transformer = ColumnTransformer(transformers=[('num', num_transformer, num_features), \n",
    "                                                  ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special considerations need to be made because the problem is time dependent. The cross validation folds could normally be produced with TimeSeriesSplit(), but the distribution of the continuous numerical variables begs for rescaling. Therein lies the issue; however, as the renormalization using only train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bin categorical data that has too many unique values.\n",
    "2. Convert categorical data to discrete numerical data by means of OneHotEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to reduce capital loss not maximize profits. Therefore, we value prediction of when a loan will be charged off more than fully paid. We can account for this by changing the class weights in the classification process. This model will reject loans that would have been fully paid in order to avoid loans that will become charged off. In other words, the goal is to maximize the number of true positives, where \"positive\" in this case is equivalent to a loan being charged off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to figure out why it's always predicting to accept loans. First check correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pairwise_correlations(df):\n",
    "    # Produce all correlations to the relations between features\n",
    "    correlations_ = df.corr()\n",
    "    # Maximum correlations (excluding auto-correlation)\n",
    "    correlations_df = correlations_.unstack().to_frame(name='data')\n",
    "    # Remove the auto-correlations which are trivial / not useful values.\n",
    "    correlations_no_auto = correlations_df[correlations_df['data']!=1]\n",
    "    # To pick out the maximum pairwise correlations, \n",
    "    maxcvalues = correlations_no_auto[correlations_no_auto['data'] == correlations_no_auto.groupby(level=[0])['data'].transform(max)]\n",
    "    return maxcvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcorr = col_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcorrelations = pd.DataFrame.sparse.from_spmatrix(Xcorr).corr().dropna(axis=1).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcorr = max_pairwise_correlations(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.998970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.998970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.997882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.979726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.337782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_1</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.087310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <th>earliest_cr_line_2</th>\n",
       "      <td>0.074016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_2</th>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.074016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_0</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           data\n",
       "loan_amnt          funded_amnt         0.998970\n",
       "funded_amnt        loan_amnt           0.998970\n",
       "funded_amnt_inv    funded_amnt         0.997882\n",
       "installment        funded_amnt         0.979726\n",
       "annual_inc         loan_amnt           0.337782\n",
       "earliest_cr_line_1 loan_amnt           0.087310\n",
       "int_rate           earliest_cr_line_2  0.074016\n",
       "earliest_cr_line_2 int_rate            0.074016\n",
       "earliest_cr_line_0 funded_amnt_inv     0.003231"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxcorr.sort_values(by='data', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rfc_models_ = []\n",
    "\n",
    "for train_indices, test_indices in train_test_iterable:\n",
    "    X_train, y_train = X.loc[train_indices, :], y.loc[train_indices].values.ravel()\n",
    "    X_test, y_test = X.loc[test_indices, :], y.loc[test_indices].values.ravel()\n",
    "\n",
    "    _ = col_transformer.fit(X_train)\n",
    "    X_train_processed = col_transformer.transform(X_train)\n",
    "    X_test_processed = col_transformer.transform(X_test)\n",
    "    class_weights={0:1, 1:1000000}\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs=-1, n_estimators=100, class_weight=class_weights, random_state=42)\n",
    "#     rfc_selector = RFE(rfc, step=(X_train_processed.shape[1]//10))\n",
    "    rfc.fit(X_train_processed, y_train)\n",
    "    \n",
    "#     rfc_models_ += [rfc_selector]\n",
    "    classifier_analysis(rfc, X_test_processed, y_test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models_ = []\n",
    "\n",
    "for train_indices, test_indices in train_test_iterable:\n",
    "    X_train, y_train = X.loc[train_indices, :], y.loc[train_indices].values.ravel()\n",
    "    X_test, y_test = X.loc[test_indices, :], y.loc[test_indices].values.ravel()\n",
    "\n",
    "    _ = col_transformer.fit(X_train)\n",
    "    X_train_processed = col_transformer.transform(X_train)\n",
    "    X_test_processed = col_transformer.transform(X_test)\n",
    "    class_weights={0:1, 1:1000000}\n",
    "    \n",
    "    lr = LogisticRegression(n_jobs=-1, max_iter=300, class_weight=class_weights)\n",
    "    lr_selector = RFE(lr, step=(X_train_processed.shape[1]//10))\n",
    "    lr_selector.fit(X_train_processed, y_train)\n",
    "    \n",
    "    lr_models_ += [lr_selector]\n",
    "    classifier_analysis(lr_selector, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all training/testing data to help scale the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdoutindicestrain, _ = train_test_iterable[1][0], train_test_iterable[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdoutindicestrain =  holdout_indices[0][0]\n",
    "holdoutindicestest = holdout_indices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_holdout = X.loc[holdoutindicestrain, :]#, y.loc[holdoutindicestrain].values.ravel()\n",
    "X_test_holdout, y_test_holdout = X.loc[holdoutindicestest, :], y.loc[holdoutindicestest].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_holdout.shape, X_test_holdout.shape, y_test_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = col_transformer.fit(X_train_holdout)\n",
    "# Just need to fit the column transformer; aren't really training. \n",
    "# X_train_holdout_processed = col_transformer.transform(X_train_holdout)\n",
    "X_test_holdout_processed = col_transformer.transform(X_test_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model_ = ranfor_models[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't actually use the entire training and testing data to scale/encode because it results in more features than the model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_analysis(best_model_, X_test_holdout_processed, y_test_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one hot encoding can throw an error if there are categories in the test set not in the train set; as the categories are\n",
    "quantities known before hand it should be ok to pass to the encoder; or does this contaminate the test data? The issue is that the lack of a category in the training data prevents accurate prediction as by definition there is no training done on those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it ok to \"look at\" the test data? The issue arises when there are categories that are in the testing set that are not\n",
    "in the training set. If the time-series cross validation folds are not cumulative then this becomes even more of a problem.\n",
    "If kept as a general procedure, that is, relabel any categories unique to the testing set as \"Unknown\", then perhaps it can work. I.e. relabel values in the testing set that are \"unknown\" to the training set; this dummy variable is a flag to the algorithm that these values are \"special\". From Mike; if we know the categories before hand, use that set of unique values and then add two dummy columns: \"Missing\" and \"Unknown/New\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranfor_param_grid={'n_estimators':[5,10,15]}\n",
    "# logreg_param_grid = {'tol':[1e-1, 1e-2, 1e-4]}\n",
    "\n",
    "# ranfor_cv = RandomForestClassifier(class_weight='balanced')\n",
    "# ranfor_model_ = GridSearchCV(ranfor_cv, ranfor_param_grid, cv=TimeSeriesSplit(n_splits=3))\n",
    "# ranfor_model_.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
