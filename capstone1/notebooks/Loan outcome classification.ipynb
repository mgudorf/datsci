{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, plot_precision_recall_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, Binarizer, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.metrics import average_precision_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from joblib import Parallel, delayed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that combines different classification metrics to avoid repeated large blocks of code.\n",
    "# Produces the confusion matrix, classification report (precision, recall, f1-score,..)\n",
    "# ROC-AUC and ROC curve\n",
    "# Precision-recall curve\n",
    "\n",
    "def my_score(clf, X_test, y_test):\n",
    "    '''\n",
    "    Predict using trained scikit-learn estimator and compute the explained variance score  \n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_test : ndarray or DataFrame (n_samples, n_features)\n",
    "             Feature data to test. n_features represents the number of features\n",
    "             present in the data used to train the estimator clf\n",
    "\n",
    "    y_test : ndarray (n_samples, )\n",
    "             Target data to test. \n",
    "\n",
    "\n",
    "    clf : scikit-learn estimator which has been fit to data with same number of columns as X_test\n",
    "\n",
    "    '''\n",
    "    y_predict_proba= clf.predict_proba(X_test)[:,1]\n",
    "    return roc_auc_score(y_test, y_predict_proba)\n",
    "\n",
    "\n",
    "def classifier_analysis(clf, X_test, y_test):\n",
    "    '''\n",
    "    Predict using trained scikit-learn estimator and compute the explained variance score  \n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_test : ndarray or DataFrame (n_samples, n_features)\n",
    "             Feature data to test. n_features represents the number of features\n",
    "             present in the data used to train the estimator clf\n",
    "\n",
    "    y_test : ndarray (n_samples, )\n",
    "             Target data to test. \n",
    "\n",
    "\n",
    "    clf : scikit-learn estimator which has been fit to data with same number of columns as X_test\n",
    "\n",
    "    '''\n",
    "    y_predict = clf.predict(X_test_processed)\n",
    "    y_predict_proba= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print('tn, fp, fn, tp', cm.ravel())\n",
    "    _ = ConfusionMatrixDisplay(cm, [0,1]).plot()\n",
    "    \n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_predict_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict_proba)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=(clf.__class__.__name__ + '(area = %0.2f)' % logit_roc_auc))\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    average_precision = average_precision_score(y_test, y_predict_proba)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_predict_proba)\n",
    "    disp = plot_precision_recall_curve(clf, X_test_processed, y_test)\n",
    "    disp.ax_.set_ylim([0.0, 1.0])\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "# Convert date-like + 'Missing' valued features to one-hot encoded columns; uses KBins on the years of the date-like, which \n",
    "# bins then one-hot encodes, while also one-hot encoding 'Missing' separately. \n",
    "def encode_dates_and_missing(df):\n",
    "    for i, seriesname in enumerate(df.columns):\n",
    "        series = df[seriesname]\n",
    "        series_missing = pd.get_dummies(series[series=='Missing'])\n",
    "        series_notmissing = series[series!='Missing']\n",
    "        notmiss_index =series_notmissing.index\n",
    "        \n",
    "        kbd = KBinsDiscretizer(n_bins=3, strategy='uniform')\n",
    "        series_dt = pd.to_datetime(series_notmissing).dt.year\n",
    "        encoded_series = kbd.fit_transform(series_dt.values.reshape(-1,1))\n",
    "        encoded_series = pd.DataFrame(kbd.fit_transform(series_dt.values.reshape(-1,1)).toarray(),index=notmiss_index).astype(int)\n",
    "        encoded_series = encoded_series.join(series_missing, how='outer').fillna(value=0)\n",
    "        encoded_series.columns = [seriesname+'_'+str(col) for col in encoded_series.columns]\n",
    "        \n",
    "        if i == 0: \n",
    "            encoded_df = encoded_series\n",
    "        else:\n",
    "            encoded_df = pd.concat((encoded_df,encoded_series),axis=1)\n",
    "            \n",
    "    return encoded_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_feature_transformer(X, num_features, cat_features, num_transformer=QuantileTransformer()):\n",
    "\n",
    "    uniq_categories = [list(np.sort(X[col].unique()))+['Missing','Unknown'] for col in cat_features]\n",
    "    cat_transformer = OneHotEncoder(categories=uniq_categories, handle_unknown='ignore')\n",
    "    col_transformer = ColumnTransformer(transformers=[('num', num_transformer, num_features), \n",
    "                                                      ('cat', cat_transformer, cat_features)])\n",
    "    return col_transformer\n",
    "\n",
    "def scale_features(col_transformer_, X_train, X_test):\n",
    "    _ = col_transformer_.fit(X_train)\n",
    "    X_train = col_transformer_.transform(X_train)\n",
    "    X_test = col_transformer_.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def my_cross_validate(estimator, col_transformer_, X_traintest, y_traintest, train_test_iterable, param_grid):\n",
    "    mean_scores = []\n",
    "    # cv_params needs to make sense for the estimator given\n",
    "    param_grid_list = param_grid_iterable(param_grid)\n",
    "    for params_ in param_grid_list:\n",
    "        with Parallel(n_jobs=-2) as parallel:\n",
    "            fitted_models_and_test_splits = parallel(delayed(fit_model_)(estimator(**params_), col_transformer_, target_transformer_,\n",
    "                                                          X_traintest, y_traintest, train, test)\n",
    "                                  for (train, test) in train_test_iterable)\n",
    "            # Get averages (explained variance) score for this model\n",
    "            scores = parallel(delayed(my_score)(model_, xt, yt) for (model_, xt, yt) in fitted_models_and_test_splits) \n",
    "            mean_scores += [np.mean(list(scores))]\n",
    "            \n",
    "    \n",
    "    best_params_ = param_grid_list[np.argmax(np.array(mean_scores))]\n",
    "    return estimator(**best_params_) \n",
    "\n",
    "\n",
    "def fit_model_(estimator, col_transformer_, X_traintest, y_traintest, train, test):\n",
    "    X_train, X_test = X_traintest.loc[train,:], X_traintest.loc[test,:]\n",
    "    y_train, y_test = y_traintest.loc[train].values.ravel(), y_traintest.loc[test].values.ravel()\n",
    "    \n",
    "    X_train, X_test  = scale_features(col_transformer_, X_train, X_test)\n",
    "    \n",
    "    _ = estimator.fit(X_train, y_train)    \n",
    "    return (estimator, X_test, y_test)\n",
    "\n",
    "def param_grid_iterable(params):\n",
    "    keys = sorted(params)\n",
    "    combinations = list(itertools.product(*(params[key] if type(params[key]) in [list, dict, np.ndarray] else [params[key]]\n",
    "                                            for key in keys)))\n",
    "    cvsorted = [dict(zip(len(c)*keys, c)) for c in combinations]\n",
    "    return cvsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest and Logistic Regression modeling of loan status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('classification_loan_data.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to take into consideration the time dependence element of this problem. Because we want to predict whether or not\n",
    "to issue a loan, need to take into consideration the time series nature of the issuance date. The main consideration is during the cross-validation process later but reorder the data now as it will later be transformed by one-hot encoding. Specifically, it will be stored in a sparse matrix which is harder to manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will be deprecated after newest data cleaning run. \n",
    "issued_datetime = pd.to_datetime(loan_data.issue_d)\n",
    "\n",
    "loan_data = loan_data.loc[issued_datetime.sort_values().index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the cross validation folds, now need to create procedure which correctly preprocesses them before testing. Training component of folds are cumulative over time; always want to use as much information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many values for the dates of the earliest credit known credit lines and zip codes; too many at least for one-hot encoding to be practical. Therefore, group zip_code by the first two digits as this retains the geographical information and group the earliest credit_line by using KBinsDiscretizer on the year; it needs a numerical value so the entire date cannot be used without modification. The reason for KBinsDiscretizer is that the distribution is not uniform over time, and it presents an unbiased selection/grouping method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data.drop(columns='zip_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dates = encode_dates_and_missing(loan_data.loc[:, 'earliest_cr_line'].to_frame(name='earliest_cr_line'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.concat((loan_data.drop(columns=['earliest_cr_line']), encoded_dates),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = loan_data.loan_status.astype(int)\n",
    "X = loan_data.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a \"hold-out\" set of data that will used for final predictions and analysis after all cross-validation and\n",
    "model learning has been accomplished. The loan issuance dates are aggregated by month, but from the metadata we know that the data is reported *quarterly*. Using this as motivation, the hold-out data will be the most recent quarter. Because the number of loans has grown over time, this one quarter represents nearly $1 / 7$ of all loan data of loans that have either been fully paid or charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data goes from second quarter of 2007 to fourth quarter of 2015; the number of samples are skewed toawrds later dates;\n",
    "# The data is reported quarterly; this should be represented in the cross validation/model selection process.\n",
    "pind = pd.PeriodIndex(issued_datetime, freq='Q-DEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KBins needs numerical variables; use year.quarter (number.decimal). This transformation is not applied to the training data; it's just used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the year to the decimal representing the quarter; Q1 = 0.0 , Q2 = 0.25, Q3 = 0.50, Q4 = 0.75\n",
    "numerical_quarters = pind.year + (pind.quarter - 1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=6\n",
    "kbd = KBinsDiscretizer(n_bins=nb)\n",
    "bin_masks = kbd.fit_transform(numerical_quarters.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93153.,  90943., 115805., 147183.,  64222., 162063.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bin_masks, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn wants iterable containing (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [loan_data.index[np.array(np.sum(bin_masks[:,:i+1],axis=1), dtype=bool)]  for i in range(nb-1)]\n",
    "test_indices = [loan_data.index[np.array(bin_masks[:,i+1], dtype=bool)]  for i in range(nb-1)]\n",
    "train_test_iterable = list(zip(train_indices,test_indices))\n",
    "traintest = loan_data.index[np.array(np.sum(bin_masks[:,:-1],axis=1), dtype=bool)] \n",
    "holdout = loan_data.index[np.array(bin_masks[:, -1], dtype=bool)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest, X_holdout = X.loc[traintest, :], X.loc[holdout, :]\n",
    "y_traintest, y_holdout = y.loc[traintest].values.ravel(), y.loc[holdout].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special considerations need to be made because the problem is time dependent. The cross validation folds could normally be produced with TimeSeriesSplit(), but the distribution of the continuous numerical variables begs for rescaling. Therein lies the issue; however, as the renormalization using only train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bin categorical data that has too many unique values.\n",
    "2. Convert categorical data to discrete numerical data by means of OneHotEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to reduce capital loss not maximize profits. Therefore, we value prediction of when a loan will be charged off more than fully paid. We can account for this by changing the class weights in the classification process. This model will reject loans that would have been fully paid in order to avoid loans that will become charged off. In other words, the goal is to maximize the number of true positives, where \"positive\" in this case is equivalent to a loan being charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=['object','category']).columns\n",
    "cat_features = X.select_dtypes(include=['object','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_transformer_rfc = my_feature_transformer(X, num_features, cat_features, num_transformer=QuantileTransformer())\n",
    "\n",
    "rfc_param_grid = {'n_estimators':[10,25,100], 'class_weight':['balanced', None]}\n",
    "\n",
    "rfc_model = my_cross_validate(RandomForestClassifier, col_transformer_rfc, X_traintest, y_traintest,\n",
    "                              train_test_iterable, rfc_param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformer_logreg = my_feature_transformer(X, num_features, cat_features, num_transformer=QuantileTransformer())\n",
    "\n",
    "logreg_param_grid = {'max_iter':300, 'C':[0.1, 1, 2], 'class_weight':['balanced', None]}\n",
    "\n",
    "logreg_model = my_cross_validate(LogisticRegression, col_transformer_logreg, X_traintest, y_traintest, \n",
    "                                 train_test_iterable, logreg_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_analysis(rfc_model, X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_analysis(logreg_model, X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to figure out why it's always predicting to accept loans. First check correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pairwise_correlations(df):\n",
    "    # Produce all correlations to the relations between features\n",
    "    correlations_ = df.corr()\n",
    "    # Maximum correlations (excluding auto-correlation)\n",
    "    correlations_df = correlations_.unstack().to_frame(name='data')\n",
    "    # Remove the auto-correlations which are trivial / not useful values.\n",
    "    correlations_no_auto = correlations_df[correlations_df['data']!=1]\n",
    "    # To pick out the maximum pairwise correlations, \n",
    "    maxcvalues = correlations_no_auto[correlations_no_auto['data'] == \n",
    "                                      correlations_no_auto.groupby(level=[0])['data'].transform(max)]\n",
    "    return maxcvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcorr = col_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcorrelations = pd.DataFrame.sparse.from_spmatrix(Xcorr).corr().dropna(axis=1).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcorr = max_pairwise_correlations(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.998970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.998970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.997882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.979726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.337782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_1</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.087310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <th>earliest_cr_line_2</th>\n",
       "      <td>0.074016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_2</th>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.074016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_0</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           data\n",
       "loan_amnt          funded_amnt         0.998970\n",
       "funded_amnt        loan_amnt           0.998970\n",
       "funded_amnt_inv    funded_amnt         0.997882\n",
       "installment        funded_amnt         0.979726\n",
       "annual_inc         loan_amnt           0.337782\n",
       "earliest_cr_line_1 loan_amnt           0.087310\n",
       "int_rate           earliest_cr_line_2  0.074016\n",
       "earliest_cr_line_2 int_rate            0.074016\n",
       "earliest_cr_line_0 funded_amnt_inv     0.003231"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxcorr.sort_values(by='data', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all training/testing data to help scale the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdoutindicestrain, _ = train_test_iterable[1][0], train_test_iterable[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdoutindicestrain =  holdout_indices[0][0]\n",
    "holdoutindicestest = holdout_indices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_holdout = X.loc[holdoutindicestrain, :]#, y.loc[holdoutindicestrain].values.ravel()\n",
    "X_test_holdout, y_test_holdout = X.loc[holdoutindicestest, :], y.loc[holdoutindicestest].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_cross_validate(estimator, col_transformer_, X_traintest, y_traintest, train_test_iterable, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cross_validate(estimator, col_transformer_, X_traintest, y_traintest, train_test_iterable, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_holdout.shape, X_test_holdout.shape, y_test_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = col_transformer.fit(X_train_holdout)\n",
    "# Just need to fit the column transformer; aren't really training. \n",
    "# X_train_holdout_processed = col_transformer.transform(X_train_holdout)\n",
    "X_test_holdout_processed = col_transformer.transform(X_test_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model_ = ranfor_models[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't actually use the entire training and testing data to scale/encode because it results in more features than the model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_analysis(best_model_, X_test_holdout_processed, y_test_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one hot encoding can throw an error if there are categories in the test set not in the train set; as the categories are\n",
    "quantities known before hand it should be ok to pass to the encoder; or does this contaminate the test data? The issue is that the lack of a category in the training data prevents accurate prediction as by definition there is no training done on those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it ok to \"look at\" the test data? The issue arises when there are categories that are in the testing set that are not\n",
    "in the training set. If the time-series cross validation folds are not cumulative then this becomes even more of a problem.\n",
    "If kept as a general procedure, that is, relabel any categories unique to the testing set as \"Unknown\", then perhaps it can work. I.e. relabel values in the testing set that are \"unknown\" to the training set; this dummy variable is a flag to the algorithm that these values are \"special\". From Mike; if we know the categories before hand, use that set of unique values and then add two dummy columns: \"Missing\" and \"Unknown/New\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranfor_param_grid={'n_estimators':[5,10,15]}\n",
    "# logreg_param_grid = {'tol':[1e-1, 1e-2, 1e-4]}\n",
    "\n",
    "# ranfor_cv = RandomForestClassifier(class_weight='balanced')\n",
    "# ranfor_model_ = GridSearchCV(ranfor_cv, ranfor_param_grid, cv=TimeSeriesSplit(n_splits=3))\n",
    "# ranfor_model_.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
