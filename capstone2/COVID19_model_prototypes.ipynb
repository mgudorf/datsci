{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling1D, SeparableConv2D, Activation, concatenate, Conv2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import KLDivergence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prototyping\n",
    "\n",
    "The goal of this notebook is to get a feel for the performance of the two different types of models to be trained.\n",
    "Specifically, comparison will be made between a naive baseline model, a ridge regression model, and a convolutional neural network model. Because this notebook is simply prototyping, a very small subset of the available data will be used; a single \n",
    "feature's time series for a single country, the United States. This single feature is all that will be available to the CNN and Ridge regression models; because eventually the feature data used in the regression is much larger than that used in the CNN training, this might be an unfair comparison.\n",
    "\n",
    "The main issue for using a very small subset of data is that I believe it will affect the CNN more than the regression, because\n",
    "the small number of samples influences how well the specific architecture will perform. Regardless I will press on and continue this testing. \n",
    "\n",
    "Both will use mean squared error as their loss function, unfortunately this means that I have to use RidgeCV, which means I need to provide my own folds in order to respect time ordering.\n",
    "\n",
    "Much like how in regression we want to include multiple days of information for prediction,  it may also be benefitial to convolve multiple frames together for the CNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def country_slice(data, locations):\n",
    "    if type(locations)==str:\n",
    "        return data[data.location==locations]\n",
    "    else:\n",
    "        return data[data.location.isin(locations)]\n",
    "    \n",
    "def time_slice(data, start, end, indexer='time_index'):\n",
    "    if start < 0 and end < 0:\n",
    "        if start == -1:\n",
    "            start = data.loc[:, indexer].max()\n",
    "        else:\n",
    "            start = data.loc[:, indexer].max()+start\n",
    "        if end == -1:\n",
    "            end = data.loc[:, indexer].max()\n",
    "        else:\n",
    "            end = data.loc[:, indexer].max()+end\n",
    "    return data[(data.loc[:, indexer] >= start) & (data.loc[:, indexer] <= end)]\n",
    "\n",
    "def per_country_plot(data, feature, legend=True):\n",
    "    data.set_index(['time_index', 'location']).loc[:, feature].unstack().plot(legend=legend)\n",
    "    return None\n",
    "\n",
    "def per_time_plot(data, feature, legend=True):\n",
    "    data.set_index(['location','time_index']).loc[:, feature].unstack().plot(legend=legend)\n",
    "    return None\n",
    "\n",
    "def country_groupby(df):\n",
    "    return [df[df.location==country].index for country in df.location.unique()]\n",
    "\n",
    "def country_search(df, country):\n",
    "    return df[df.location==country].index\n",
    "\n",
    "def column_search(df, name, return_style='loc', threshold='contains'):\n",
    "    if threshold=='contains':\n",
    "        func = df.columns.str.contains\n",
    "    else:\n",
    "        func = df.columns.str.match\n",
    "        \n",
    "    if return_style == 'loc':\n",
    "        return df.columns[func(name)]\n",
    "    elif return_style== 'iloc':\n",
    "        return np.where(func(name))[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def concatenate_4d_into_3d(splits, train_test_only=False):\n",
    "    \n",
    "    if train_test_only:\n",
    "        (X_train, y_train, X_test, y_test) = splits\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        concat_splits = (X_train, y_train, X_test, y_test) \n",
    "    else:\n",
    "        (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        X_validate = np.concatenate(X_validate, axis=0)\n",
    "        y_validate = np.concatenate(y_validate, axis=0)\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        concat_splits = (X_train, y_train, X_validate, y_validate, X_test, y_test) \n",
    "    return concat_splits\n",
    "\n",
    "def transpose_for_separable2d(splits, train_test_only=False):\n",
    "    if train_test_only:\n",
    "        (X_train, y_train, X_test, y_test) = splits\n",
    "        X_train = np.transpose(X_train, axes=[0,2,1,3])\n",
    "        X_test = np.transpose(X_test, axes=[0,2,1,3])\n",
    "        transpose_split = (X_train, y_train, X_test, y_test) \n",
    "    else:\n",
    "        (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "        X_train = np.transpose(X_train, axes=[0,2,1,3])\n",
    "        X_validate = np.transpose(X_validate, axes=[0,2,1,3])\n",
    "        X_test = np.transpose(X_test, axes=[0,2,1,3])\n",
    "        transpose_split = (X_train, y_train, X_validate, y_validate, X_test, y_test) \n",
    "    return transpose_split\n",
    "\n",
    "    \n",
    "def true_predict_plot(y_true, y_naive, y_predict, title='', scale=None,s=None):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "    if scale == 'log':\n",
    "        ymax = np.max([np.log(1+y_true).max(), np.log(1+y_predict).max()])\n",
    "        ax1.scatter(np.log(y_true+1), np.log(y_naive+1), s=s,alpha=0.7)\n",
    "        ax1.plot([0, ymax], [0, ymax],color='r')\n",
    "        ax2.scatter(np.log(y_true+1), np.log(y_predict+1), s=s,alpha=0.7)\n",
    "        ax2.plot([0, ymax], [0, ymax],color='r')\n",
    "    else:\n",
    "        ymax = np.max([y_true.max(), y_predict.max()])\n",
    "        ax1.scatter(y_true, y_naive, s=s)\n",
    "        ax1.plot([0, ymax], [0, ymax],color='r')\n",
    "        ax2.scatter(y_true, y_predict, s=s)\n",
    "        ax2.plot([0, ymax], [0, ymax],color='r')\n",
    "    ax1.set_xlabel('True value')\n",
    "    ax1.set_ylabel('Predicted value')\n",
    "    ax1.set_title('Naive model')\n",
    "\n",
    "    ax2.set_xlabel('True value')\n",
    "    ax2.set_ylabel('Predicted value')\n",
    "    ax2.set_title(title)\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def residual_plot(y_test, y_predict, title='', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, y_test-y_predict.ravel(), s=5)\n",
    "    ax.set_ylabel('Residual')\n",
    "    ax.set_xlabel('True value')\n",
    "    ax.grid(True)\n",
    "    return None\n",
    "\n",
    "def residual_diff_plots(y_true, y_naive, y_predict,n_days_into_future, n_countries, scale=None):\n",
    "    print(y_true.shape, y_naive.shape, y_predict.shape)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20,5), sharey=True)\n",
    "    (ax1,ax2,ax3,ax4) = axes.flatten()\n",
    "    xrange = range(len(y_true))\n",
    "    if scale=='log':\n",
    "        ax1.plot(xrange, np.log(y_true+1)\n",
    "             -np.log(y_naive+1))\n",
    "        ax2.plot(xrange, np.log(y_true+1)\n",
    "                 -np.log(y_predict+1))\n",
    "        residual_plot(np.log(y_true+1),np.log(y_naive+1), ax=ax3)\n",
    "        residual_plot(np.log(y_true+1),np.log(y_predict+1), ax=ax4)\n",
    "    else:\n",
    "        ax1.plot(xrange, y_true-y_naive)\n",
    "        ax2.plot(xrange, y_true-y_predict)\n",
    "        residual_plot(y_true,y_naive, ax=ax3)\n",
    "        residual_plot(y_true,y_predict, ax=ax4)\n",
    "    fig.suptitle('{}-day-into-future predictions'.format(n_days_into_future))\n",
    "    ax1.set_title('Country-wise differences')\n",
    "    ax2.set_title('Country-wise differences')\n",
    "    ax1.set_ylabel('True - Naive')\n",
    "    ax2.set_ylabel('True - CNN')\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "# Copied from last capstone project. \n",
    "def classifier_analysis(clf, X_test, y_test, plot=True, metric='evs'):\n",
    "    \n",
    "    '''\n",
    "        Predict using trained scikit-learn estimator and compute and plot various metrics:\n",
    "        Prints \n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        X_test : ndarray or DataFrame (n_samples, n_features)\n",
    "                 Feature data to test. n_features represents the number of features\n",
    "                 present in the data used to train the estimator clf\n",
    "                 \n",
    "        y_test : ndarray (n_samples, )\n",
    "                 Target data to test. \n",
    "                \n",
    "        \n",
    "        clf : scikit-learn estimator which has been fit to data with same number of \n",
    "              columns as X_test\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        y_test : ndarray (n_samples, )\n",
    "            \n",
    "            Same as input for convenience\n",
    "        \n",
    "        y_predict : ndarray (n_samples, ) \n",
    "            \n",
    "            Predictions \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    y_predict = clf.predict(X_test)\n",
    "    \n",
    "    # Print the mean squared error and explained variance\n",
    "    if metric == 'evs':\n",
    "        score = explained_variance_score(y_test, y_predict)\n",
    "    elif metric == 'mae':\n",
    "        score = mean_absolute_error(y_test, y_predict)\n",
    "    else:\n",
    "        score = mean_squared_error(y_test, y_predict)\n",
    "\n",
    "#     print('Mean squared error {}'.format(mse_))\n",
    "#     print('Explained variance score {}'.format(evs_))\n",
    "    \n",
    "    if plot:\n",
    "        # Plot true vs. predicted as scatter plot. \n",
    "        ym = np.max(y_test)\n",
    "        fig = plt.figure()\n",
    "        plt.scatter(y_test, y_predict, s=1)\n",
    "        plt.plot([0, ym],[0, ym],color='r')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlabel('True Value')\n",
    "        plt.grid()\n",
    "        plt.xlim([0, 1.1*ym])\n",
    "        plt.ylim([0, 1.1*ym])\n",
    "        _ = plt.show()\n",
    "    \n",
    "    return y_test, y_predict, score\n",
    "\n",
    "def create_Xy(model_data, target_data, time_index, start_date, frame_size, n_days_into_future, n_countries):\n",
    "    for max_date_in_window in range(start_date, time_index.max() - n_days_into_future + 1):\n",
    "        # Take all model_data with date proxy less than numerical value, leading_window_date_not_included\n",
    "        frame_data = model_data[(time_index <= max_date_in_window) & \n",
    "                                (time_index >= max_date_in_window-(frame_size-1))]\n",
    "        #     print(frame_data.shape)\n",
    "        # Reshape the array such that each element along axis=0 is a time series of all feature model_data of a specific country.\n",
    "        reshaped_frame_data = frame_data.values.reshape(n_countries, frame_size, -1)\n",
    "        #     print(reshaped_frame_data.shape)\n",
    "        # Truncate / pad the windows along the \"time\" axis, axis=1. (pad_sequences takes in an iterable of iterables;\n",
    "        # the first axis is always the default iteration axis. \n",
    "        # *********************** WARNING: pad_sequences converts to integers by default *********************\n",
    "        resized_frame_data = pad_sequences(reshaped_frame_data, maxlen=frame_size, dtype=np.float64)\n",
    "        frame_data_4D = resized_frame_data[np.newaxis, :, :, :]\n",
    "        if max_date_in_window == start_date:\n",
    "            X = frame_data_4D.copy()\n",
    "        else:\n",
    "            X = np.concatenate((X, frame_data_4D),axis=0)\n",
    "    y = target_data.values.reshape(-1, time_index.nunique()).transpose()[-X.shape[0]:,:]\n",
    "    return X, y\n",
    "\n",
    "def split_Xy(X, y, frame_size, n_validation_frames, n_test_frames, train_test_only=False):\n",
    "    \"\"\" Split into training, validation and test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Note that the last frame (date_range) that exists in X has already been determined by the choice of the number\n",
    "    # of steps to predict in the future, this is only slicing the frames. \n",
    "    if train_test_only:\n",
    "        X_train= X[:-n_test_frames,:,:,:]\n",
    "        y_train =  y[:-n_test_frames,:]\n",
    "        X_test = X[-n_test_frames:, :, :, :] \n",
    "        y_test = y[-n_test_frames:, :]\n",
    "        splits =  (X_train, y_train, X_test, y_test)\n",
    "    else:\n",
    "        y_train =  y[:-(n_validation_frames+n_test_frames),:]\n",
    "        y_validate = y[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "        X_train= X[:-(n_validation_frames+n_test_frames),:,:,:]\n",
    "        y_train =  y[:-(n_validation_frames+n_test_frames),:]\n",
    "        X_validate = X[-(n_validation_frames+n_test_frames):-n_test_frames, :, :, :]\n",
    "        y_validate = y[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "        X_test = X[-n_test_frames:, :, :, :] \n",
    "        y_test = y[-n_test_frames:, :]\n",
    "        splits =  (X_train, y_train, X_validate, y_validate,\n",
    "                   X_test, y_test)\n",
    "\n",
    "    train_indices = list(range(0, len(X)-(n_validation_frames+n_test_frames)))\n",
    "    validate_indices = list(range(len(X)-(n_validation_frames+n_test_frames), len(X)-n_test_frames))\n",
    "    test_indices = list(range(len(X)-n_test_frames, len(X)))\n",
    "    indices = (train_indices, validate_indices, test_indices)\n",
    "    return splits, indices\n",
    "\n",
    "\n",
    "def normalize_Xy_splits(splits, feature_range=(0., 0.5), normalization_method='minmax',\n",
    "                        train_test_only=False, feature_indices=None):\n",
    "    \"\"\" Split into training, validation and test data.\n",
    "    \"\"\"\n",
    "    min_, max_ = feature_range\n",
    "    (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "    for i in range(1, X_train.shape[0]+1):\n",
    "        # find the minima and maxima of all features for all countries, ranging up to current frame and \n",
    "        # each time step in the frame. \n",
    "        up_to_current_frame_min = X_train[:i,:,:,:].min((0,1,2))\n",
    "        up_to_current_frame_max = X_train[:i,:,:,:].max((0,1,2))\n",
    "        latest_min_array = np.tile(up_to_current_frame_min[np.newaxis, np.newaxis, np.newaxis, :],(1,1,frame_size,1))\n",
    "        latest_max_array = np.tile(up_to_current_frame_max[np.newaxis, np.newaxis, np.newaxis, :],(1,1,frame_size,1))\n",
    "        if i == 1:\n",
    "            frame_min_array = latest_min_array\n",
    "            frame_max_array = latest_max_array\n",
    "        else:\n",
    "            frame_min_array = np.concatenate((frame_min_array, \n",
    "                                                   latest_min_array)\n",
    "                                                  ,axis=0)\n",
    "            frame_max_array = np.concatenate((frame_max_array, \n",
    "                                                   latest_max_array)\n",
    "                                                  ,axis=0)\n",
    "\n",
    "\n",
    "    frame_minmax_denominator = (frame_max_array-frame_min_array)\n",
    "    num_zeros_train = (frame_minmax_denominator==0).sum()\n",
    "\n",
    "    frame_minmax_denominator[np.where(frame_minmax_denominator==0)]=1\n",
    "    X_train_scaled = 0.5*(X_train - frame_min_array) / frame_minmax_denominator\n",
    "    # Use the latest min and max for test scaling.\n",
    "\n",
    "    frame_denom_for_test = latest_max_array - latest_min_array\n",
    "    num_zeros_test = (frame_denom_for_test==0).sum()\n",
    "\n",
    "    frame_denom_for_test[np.where(frame_denom_for_test==0)] = 1\n",
    "\n",
    "    X_validate_scaled = 0.5*(X_validate - latest_min_array) / frame_denom_for_test\n",
    "    X_test_scaled = 0.5*(X_test - latest_min_array) / frame_denom_for_test\n",
    "    scaled_splits = (X_train_scaled, y_train, X_validate_scaled, y_validate, X_test_scaled, y_test) \n",
    "\n",
    "    return scaled_splits \n",
    "\n",
    "def model_analysis(y_true, y_naive, y_predict, title=''):\n",
    "    print('There were {} negative predictions'.format(len(y_predict[y_predict<0])))\n",
    "    #     y_predict[y_predict<0]=0\n",
    "    mse_train_naive = mean_squared_error(y_true.ravel(), y_naive.ravel())\n",
    "    mse_predict = mean_squared_error(y_true.ravel(), y_predict)\n",
    "    r2_train_naive = explained_variance_score(y_true.ravel(), y_naive.ravel())\n",
    "    r2_predict = explained_variance_score(y_true.ravel(), y_predict)\n",
    "\n",
    "    print('{}-step MSE [Naive, {}] = [{},{}]'.format(\n",
    "    n_days_into_future,title, mse_train_naive, mse_predict))\n",
    "    print('{}-step R^2 [Naive, {}] = [{},{}]'.format(\n",
    "    n_days_into_future,title, r2_train_naive, r2_predict))\n",
    "\n",
    "    true_predict_plot(y_true.ravel(), y_naive.ravel(), y_predict, title=title)\n",
    "    residual_diff_plots(y_true.ravel(), y_naive.ravel(), y_predict , n_days_into_future, data.location.nunique())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should have been average/taking min max over countries as well as time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned data produced by other notebook. \n",
    "global_data = pd.read_csv('cnn_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the prototype, see what kind of result we get with just the data on the United States, and only use the new_cases_per_million feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = global_data[global_data.location=='United States'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not enough countries have new_recovered_weighted values.\n",
    "data = data.drop(columns=['date'])\n",
    "data = data.drop(columns=column_search(data, 'log'))\n",
    "# data.loc[:, 'time_index'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3933a22c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.time_index>=40]\n",
    "model_data = data.copy().iloc[:, 1:]\n",
    "model_data =  model_data.apply(lambda x :np.log(x+1))\n",
    "new_cases_index = column_search(model_data,'new_cases_per_million',threshold='match', return_style='iloc')[0]\n",
    "model_data = model_data.iloc[:, new_cases_index].to_frame(); new_cases_index=0\n",
    "n_countries = data.location.nunique()\n",
    "target_data = model_data.new_cases_per_million\n",
    "# model_generator = Conv1D_model\n",
    "time_index = data.time_index\n",
    "\n",
    "frame_size = 28\n",
    "start_date = 2*frame_size#+time_index.min()\n",
    "\n",
    "n_validation_frames = 7\n",
    "n_test_frames = 1\n",
    "n_days_into_future = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_Xy(model_data, target_data, time_index, start_date, frame_size, n_days_into_future, n_countries)\n",
    "splits, indices = split_Xy(X, y, frame_size, n_validation_frames, n_test_frames)\n",
    "(X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "(train_indices, validate_indices, test_indices) = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "ax.scatter(range(len(X)), X[:, 0, -1, new_cases_index], s=40, color='r')\n",
    "ax.scatter(range(len(X_train)), X_train[:,0,-1,new_cases_index], s=20, label='train')\n",
    "ax.scatter(range(len(X_train), len(X_train)+len(X_validate)), X_validate[:,0,-1,new_cases_index], s=20, label='validate')\n",
    "ax.scatter(range(len(X_train)+len(X_validate), len(X)), X_test[:,0,-1,new_cases_index], s=20, label='test')\n",
    "ax.plot(np.log(data.new_cases_per_million.values[start_date:]+1), color='k', alpha=0.2)\n",
    "plt.legend()\n",
    "_ = plt.show()\n",
    "\n",
    "# Rescale to 0.5 to 1 to account for new maximums. How does this even help?        \n",
    "\n",
    "# Rescale to 0.5 to 1 to account for new maximums. How does this even help?        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_splits =  normalize_Xy_splits(splits, feature_range=(0,0.5), normalization_method='minmax', train_test_only=False, feature_indices=None)\n",
    "(X_train_scaled, y_train, X_validate_scaled, y_validate, X_test_scaled, y_test) =scaled_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# ax.scatter(range(len(X)), X[:, 0, -1, new_cases_index], s=40, color='r')\n",
    "ax.scatter(range(len(X_train_scaled)), X_train_scaled[:,0,-1,new_cases_index], s=20, label='train_scaled')\n",
    "ax.scatter(range(len(X_train_scaled), len(X_train_scaled)+len(X_validate_scaled)), X_validate_scaled[:,0,-1,new_cases_index], s=20, label='validate_scaled')\n",
    "ax.scatter(range(len(X_train_scaled)+len(X_validate_scaled), len(X)), X_test_scaled[:,0,-1,new_cases_index], s=20, label='test_scaled')\n",
    "# ax.plot(np.log(data.new_cases_per_million.values[start_date:]+1), color='k', alpha=0.2)\n",
    "plt.legend()\n",
    "_ = plt.show()\n",
    "\n",
    "# Rescale to 0.5 to 1 to account for new maximums. How does this even help?        \n",
    "\n",
    "# Rescale to 0.5 to 1 to account for new maximums. How does this even help?        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time index to X relationship.\n",
    "\n",
    "    Last frame, last day of X is time_index() - n_days_into_future\n",
    "    last frame, first day is time_index() - n_days_into_future - frame_size\n",
    "    first frame, first day is start_date-frame_size\n",
    "    first frame, last day is start_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.56260709, 4.66242915, 4.65150018, 4.82600708, 4.93118075])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(X.reshape(-1, *X.shape[1:]), axis=0)[0,-1,0]\n",
    "time_slice(data.iloc[:,1:], start_date,start_date+frame_size).apply(lambda x: np.log(x+1))\n",
    "np.concatenate(X.reshape(-1, *X.shape[1:]), axis=0)[-1,-5:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.44114423915697"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(X_train.reshape(-1, *X_train.shape[1:]), axis=0).shape\n",
    "np.concatenate(X_train.reshape(-1, *X_train.shape[1:]), axis=0)[-1,-1,0]\n",
    "np.concatenate(X.reshape(-1, *X.shape[1:]), axis=0)[-9,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149    4.441144\n",
       "150    4.514797\n",
       "151    4.646274\n",
       "152    4.368485\n",
       "153    4.562607\n",
       "154    4.662429\n",
       "155    4.651500\n",
       "156    4.826007\n",
       "157    4.931181\n",
       "158    4.862561\n",
       "Name: new_cases_per_million, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-5:]\n",
    "data.new_cases_per_million.apply(lambda x: np.log(x+1))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because only 1 feature, need an extra axis\n",
    "X_train_cnn_model = np.concatenate(X_train.reshape(X_train.shape[0], X_train.shape[1], -1), axis=0)[:,:,np.newaxis]\n",
    "X_test_cnn_model = np.concatenate(X_test.reshape(X_test.shape[0], X_test.shape[1], -1), axis=0)[:,:,np.newaxis]\n",
    "X_validate_cnn_model = np.concatenate(X_validate.reshape(X_validate.shape[0], X_validate.shape[1], -1), axis=0)[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  elif not isinstance(value, collections.Sized):\n"
     ]
    }
   ],
   "source": [
    "# X_train_cnn_model = np.concatenate(\n",
    "#     X_train_scaled.reshape(X_train_scaled.shape[0],\n",
    "#                            X_train_scaled.shape[1],\n",
    "#                            -1), axis=0)[:,:,np.newaxis]\n",
    "# X_test_cnn_model = np.concatenate(\n",
    "#     X_test_scaled.reshape(X_test_scaled.shape[0],\n",
    "#                           X_test_scaled.shape[1],\n",
    "#                           -1), axis=0)[:,:,np.newaxis]\n",
    "# X_validate_cnn_model = np.concatenate(\n",
    "#     X_validate_scaled.reshape(X_validate_scaled.shape[0],\n",
    "#                              X_validate_scaled.shape[1],\n",
    "#                              -1), axis=0)[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "y_validate_cnn_model = y_validate.ravel()\n",
    "y_train_cnn_model = y_train.ravel()\n",
    "y_test_cnn_model = y_test.ravel()\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "kernel = 4\n",
    "N = 8\n",
    "FC = 8\n",
    "\n",
    "f1, f2 = 16, 4\n",
    "k1, k2 = 4, 4\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=int(f1), kernel_size=int(k1),\n",
    "                 padding='valid',\n",
    "                 input_shape=X_train.shape[2:],\n",
    "#                  activation='relu'\n",
    "                )\n",
    "         )\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Activation('relu'))\n",
    "\n",
    "cnn_model.add(Conv1D(filters=int(f2), \n",
    "                 kernel_size=int(k2), \n",
    "                 padding='valid',\n",
    "#                  activation='relu'\n",
    "                )\n",
    "         )\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(cnn_model.output.shape[1], \n",
    "                activation='relu'\n",
    "               )\n",
    "         )\n",
    "cnn_model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "cnn_model.compile(loss='mse', optimizer=Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 25, 16)            80        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 12, 16)            0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 12, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9, 4)              260       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4, 4)              0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 629\n",
      "Trainable params: 629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 28, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate_cnn_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "94/94 [==============================] - 0s 3ms/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 2/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 3/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 4/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 5/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 6/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 7/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 8/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 9/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 10/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 11/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 12/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 13/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 14/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 15/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 16/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 17/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 18/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 19/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 20/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 21/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 22/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 23/1000\n",
      "94/94 [==============================] - 0s 638us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 24/1000\n",
      "94/94 [==============================] - 0s 606us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 25/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 26/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 27/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 28/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 29/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 30/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 31/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 32/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 33/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 34/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 35/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 36/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 37/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 38/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 39/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 40/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 41/1000\n",
      "94/94 [==============================] - 0s 563us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 42/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 43/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 44/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 45/1000\n",
      "94/94 [==============================] - 0s 553us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 46/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 47/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 48/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 49/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 50/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 51/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 52/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 53/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 54/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 55/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 56/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 57/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 58/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 59/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 60/1000\n",
      "94/94 [==============================] - 0s 627us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 61/1000\n",
      "94/94 [==============================] - 0s 595us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 62/1000\n",
      "94/94 [==============================] - 0s 638us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 63/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 64/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 65/1000\n",
      "94/94 [==============================] - 0s 595us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 66/1000\n",
      "94/94 [==============================] - 0s 563us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 67/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 68/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 69/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 70/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 71/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 72/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 73/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 74/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 75/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 76/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 78/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 79/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 80/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 81/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 82/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 83/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 84/1000\n",
      "94/94 [==============================] - ETA: 0s - loss: 18.36 - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 85/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 86/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 87/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 88/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 89/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 90/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 91/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 92/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 93/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 94/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 95/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 96/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 97/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 98/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 99/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 100/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 101/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 102/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 103/1000\n",
      "94/94 [==============================] - 0s 531us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 104/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 105/1000\n",
      "94/94 [==============================] - 0s 563us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 106/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 107/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 108/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 109/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 110/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 111/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 112/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 113/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 114/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 115/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 116/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 117/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 118/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 119/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 120/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 121/1000\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 122/1000\n",
      "94/94 [==============================] - 0s 606us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 123/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 124/1000\n",
      "94/94 [==============================] - 0s 451us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 125/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 126/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 127/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 128/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 129/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 130/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 131/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 132/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 133/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 134/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 135/1000\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 136/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 137/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 138/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 139/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 140/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 141/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 142/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 143/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 144/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 145/1000\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 146/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 147/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 148/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 149/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 150/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 151/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 152/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 154/1000\n",
      "94/94 [==============================] - 0s 400us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 155/1000\n",
      "94/94 [==============================] - 0s 398us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 156/1000\n",
      "94/94 [==============================] - 0s 400us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 157/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 158/1000\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 159/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 160/1000\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 161/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 162/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 163/1000\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 164/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 165/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 166/1000\n",
      "94/94 [==============================] - 0s 531us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 167/1000\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 168/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 169/1000\n",
      "94/94 [==============================] - 0s 574us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 170/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 171/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 172/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 173/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 174/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 175/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 176/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 177/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 178/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 179/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 180/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 181/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 182/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 183/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 184/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 185/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 186/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 187/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 188/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 189/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 190/1000\n",
      "94/94 [==============================] - 0s 388us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 191/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 192/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 193/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 194/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 195/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 196/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 197/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 198/1000\n",
      "94/94 [==============================] - 0s 392us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 199/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 200/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 201/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 202/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 203/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 204/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 205/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 206/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 207/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 208/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 209/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 210/1000\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 211/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 212/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 213/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 214/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 215/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 216/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 217/1000\n",
      "94/94 [==============================] - 0s 585us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 218/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 219/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 220/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 221/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 222/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 223/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 224/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 225/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 226/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 227/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 228/1000\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 230/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 231/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 232/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 233/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 234/1000\n",
      "94/94 [==============================] - 0s 395us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 235/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 236/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 237/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 238/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 239/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 240/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 241/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 242/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 243/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 244/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 245/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 246/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 247/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 248/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 249/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 250/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 251/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 252/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 253/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 254/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 255/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 256/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 257/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 258/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 259/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 260/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 261/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 262/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 263/1000\n",
      "94/94 [==============================] - 0s 403us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 264/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 265/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 266/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 267/1000\n",
      "94/94 [==============================] - 0s 502us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 268/1000\n",
      "94/94 [==============================] - 0s 497us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 269/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 270/1000\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 271/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 272/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 273/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 274/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 275/1000\n",
      "94/94 [==============================] - 0s 553us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 276/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 277/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 278/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 279/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 280/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 281/1000\n",
      "94/94 [==============================] - 0s 383us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 282/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 283/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 284/1000\n",
      "94/94 [==============================] - 0s 563us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 285/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 286/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 287/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 288/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 289/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 290/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 291/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 292/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 293/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 294/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 295/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 296/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 297/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 298/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 299/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 300/1000\n",
      "94/94 [==============================] - 0s 394us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 301/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 302/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 303/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 304/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 306/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 307/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 308/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 309/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 310/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 311/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 312/1000\n",
      "94/94 [==============================] - 0s 531us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 313/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 314/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 315/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 316/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 317/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 318/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 319/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 320/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 321/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 322/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 323/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 324/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 325/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 326/1000\n",
      "94/94 [==============================] - 0s 400us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 327/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 328/1000\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 329/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 330/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 331/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 332/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 333/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 334/1000\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 335/1000\n",
      "94/94 [==============================] - 0s 499us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 336/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 337/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 338/1000\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 339/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 340/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 341/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 342/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 343/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 344/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 345/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 346/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 347/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 348/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 349/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 350/1000\n",
      "94/94 [==============================] - 0s 595us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 351/1000\n",
      "94/94 [==============================] - 0s 564us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 352/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 353/1000\n",
      "94/94 [==============================] - 0s 384us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 354/1000\n",
      "94/94 [==============================] - 0s 403us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 355/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 356/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 357/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 358/1000\n",
      "94/94 [==============================] - 0s 384us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 359/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 360/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 361/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 362/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 363/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 364/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 365/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 366/1000\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 367/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 368/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 369/1000\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 370/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 371/1000\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 372/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 373/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 374/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 375/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 376/1000\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 377/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 378/1000\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 379/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 380/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 382/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 383/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 384/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 385/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 386/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 387/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 388/1000\n",
      "94/94 [==============================] - ETA: 0s - loss: 18.49 - 0s 426us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 389/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 390/1000\n",
      "94/94 [==============================] - 0s 477us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 391/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 392/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 393/1000\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 394/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 395/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 396/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 397/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 398/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 399/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 400/1000\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 401/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 402/1000\n",
      "94/94 [==============================] - 0s 531us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 403/1000\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 404/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 405/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 406/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 407/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 408/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 409/1000\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 410/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 411/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 412/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 413/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 414/1000\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 415/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 416/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 417/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 418/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 419/1000\n",
      "94/94 [==============================] - 0s 396us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 420/1000\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 421/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 422/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 423/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 424/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 425/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 426/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 427/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 428/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 429/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 430/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 431/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 432/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 433/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 434/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 435/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 436/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 437/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 438/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 439/1000\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 440/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 441/1000\n",
      "94/94 [==============================] - 0s 383us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 442/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 443/1000\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 444/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 445/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 446/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 447/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 448/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 449/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 450/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 451/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 452/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 453/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 454/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 455/1000\n",
      "94/94 [==============================] - 0s 394us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 457/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 458/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 459/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 460/1000\n",
      "94/94 [==============================] - 0s 499us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 461/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 462/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 463/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 464/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 465/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 466/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 467/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 468/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 469/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 470/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 471/1000\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 472/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 473/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 474/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 475/1000\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 476/1000\n",
      "94/94 [==============================] - 0s 499us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 477/1000\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 478/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 479/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 480/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 481/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 482/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 483/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 484/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 485/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 486/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 487/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 488/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 489/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 490/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 491/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 492/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 493/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 494/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 495/1000\n",
      "94/94 [==============================] - 0s 396us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 496/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 497/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 498/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 499/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 500/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 501/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 502/1000\n",
      "94/94 [==============================] - 0s 450us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 503/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 504/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 505/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 506/1000\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 507/1000\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 508/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 509/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 510/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 511/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 512/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 513/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 514/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 515/1000\n",
      "94/94 [==============================] - 0s 395us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 516/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 517/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 518/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 519/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 520/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 521/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 522/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 523/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 524/1000\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 525/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 526/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 527/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 528/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 529/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 530/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 531/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 533/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 534/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 535/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 536/1000\n",
      "94/94 [==============================] - 0s 469us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 537/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 538/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 539/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 540/1000\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 541/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 542/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 543/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 544/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 545/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 546/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 547/1000\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 548/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 549/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 550/1000\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 551/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 552/1000\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 553/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 554/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 555/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 556/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 557/1000\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 558/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 559/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 560/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 561/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 562/1000\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 563/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 564/1000\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 565/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 566/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 567/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 568/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 569/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 570/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 571/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 572/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 573/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 574/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 575/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 576/1000\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 577/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 578/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 579/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 580/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 581/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 582/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 583/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 584/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 585/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 586/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 587/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 588/1000\n",
      "94/94 [==============================] - 0s 462us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 589/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 590/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 591/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 592/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 593/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 594/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 595/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 596/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 597/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 598/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 599/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 600/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 601/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 602/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 603/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 604/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 605/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 606/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 607/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 609/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 610/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 611/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 612/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 613/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 614/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 615/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 616/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 617/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 618/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 619/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 620/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 621/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 622/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 623/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 624/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 625/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 626/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 627/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 628/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 629/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 630/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 631/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 632/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 633/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 634/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 635/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 636/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 637/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 638/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 639/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 640/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 641/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 642/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 643/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 644/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 645/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 646/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 647/1000\n",
      "94/94 [==============================] - 0s 563us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 648/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 649/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 650/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 651/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 652/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 653/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 654/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 655/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 656/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 657/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 658/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 659/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 660/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 661/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 662/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 663/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 664/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 665/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 666/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 667/1000\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 668/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 669/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 670/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 671/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 672/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 673/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 674/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 675/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 676/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 677/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 678/1000\n",
      "94/94 [==============================] - 0s 401us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 679/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 680/1000\n",
      "94/94 [==============================] - 0s 421us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 681/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 682/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 683/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 685/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 686/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 687/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 688/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 689/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 690/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 691/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 692/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 693/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 694/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 695/1000\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 696/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 697/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 698/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 699/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 700/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 701/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 702/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 703/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 704/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 705/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 706/1000\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 707/1000\n",
      "94/94 [==============================] - 0s 403us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 708/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 709/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 710/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 711/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 712/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 713/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 714/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 715/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 716/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 717/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 718/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 719/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 720/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 721/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 722/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 723/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 724/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 725/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 726/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 727/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 728/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 729/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 730/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 731/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 732/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 733/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 734/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 735/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 736/1000\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 737/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 738/1000\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 739/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 740/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 741/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 742/1000\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 743/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 744/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 745/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 746/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 747/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 748/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 749/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 750/1000\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 751/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 752/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 753/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 754/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 755/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 756/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 757/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 758/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 759/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 761/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 762/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 763/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 764/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 765/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 766/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 767/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 768/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 769/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 770/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 771/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 772/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 773/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 774/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 775/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 776/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 777/1000\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 778/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 779/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 780/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 781/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 782/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 783/1000\n",
      "94/94 [==============================] - 0s 386us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 784/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 785/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 786/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 787/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 788/1000\n",
      "94/94 [==============================] - 0s 574us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 789/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 790/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 791/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 792/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 793/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 794/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 795/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 796/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 797/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 798/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 799/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 800/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 801/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 802/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 803/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 804/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 805/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 806/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 807/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 808/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 809/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 810/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 811/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 812/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 813/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 814/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 815/1000\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 816/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 817/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 818/1000\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 819/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 820/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 821/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 822/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 823/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 824/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 825/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 826/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 827/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 828/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 829/1000\n",
      "94/94 [==============================] - 0s 520us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 830/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 831/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 832/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 833/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 834/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 835/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 837/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 838/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 839/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 840/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 841/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 842/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 843/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 844/1000\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 845/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 846/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 847/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 848/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 849/1000\n",
      "94/94 [==============================] - 0s 542us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 850/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 851/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 852/1000\n",
      "94/94 [==============================] - 0s 447us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 853/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 854/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 855/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 856/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 857/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 858/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 859/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 860/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 861/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 862/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 863/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 864/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 865/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 866/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 867/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 868/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 869/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 870/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 871/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 872/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 873/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 874/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 875/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 876/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 877/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 878/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 879/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 880/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 881/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 882/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 883/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 884/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 885/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 886/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 887/1000\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 888/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 889/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 890/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 891/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 892/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 893/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 894/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 895/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 896/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 897/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 898/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 899/1000\n",
      "94/94 [==============================] - 0s 531us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 900/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 901/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 902/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 903/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 904/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 905/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 906/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 907/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 908/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 909/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 910/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 911/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 913/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 914/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 915/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 916/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 917/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 918/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 919/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 920/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 921/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 922/1000\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 923/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 924/1000\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 925/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 926/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 927/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 928/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 929/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 930/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 931/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 932/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 933/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 934/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 935/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 936/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 937/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 938/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 939/1000\n",
      "94/94 [==============================] - 0s 397us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 940/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 941/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 942/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 943/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 944/1000\n",
      "94/94 [==============================] - 0s 531us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 945/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 946/1000\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 947/1000\n",
      "94/94 [==============================] - 0s 405us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 948/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 949/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 950/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 951/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 952/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 953/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 954/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 955/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 956/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 957/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 958/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 959/1000\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 960/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 961/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 962/1000\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 963/1000\n",
      "94/94 [==============================] - 0s 553us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 964/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 965/1000\n",
      "94/94 [==============================] - 0s 521us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 966/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 967/1000\n",
      "94/94 [==============================] - 0s 400us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 968/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 969/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 970/1000\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 971/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 972/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 973/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 974/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 975/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 976/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 977/1000\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 978/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 979/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 980/1000\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 981/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 982/1000\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 983/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 984/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 985/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 986/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 987/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 989/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 990/1000\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 991/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 992/1000\n",
      "94/94 [==============================] - 0s 489us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 993/1000\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 994/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 995/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 996/1000\n",
      "94/94 [==============================] - 0s 394us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 997/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 998/1000\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 999/1000\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 17.9386 - val_loss: 21.7815\n",
      "Epoch 1000/1000\n",
      "94/94 [==============================] - 0s 398us/sample - loss: 17.9386 - val_loss: 21.7815\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = cnn_model.fit(X_train_cnn_model, y_train, epochs=epochs, validation_data=(X_validate_cnn_model, y_validate), \n",
    "          batch_size=batch_size, verbose=1)\n",
    "\n",
    "_ = plt.plot(history.history['loss'], label='loss')\n",
    "_ = plt.plot(history.history['val_loss'], label='val_loss')\n",
    "_ = plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.994587209674648"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.64627374, 4.36848536, 4.56260709, 4.66242915, 4.65150018,\n",
       "       4.82600708, 4.93118075])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 28, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate_cnn_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-67b1e797cccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_predict' is not defined"
     ]
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_cnn_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_validate.ravel()\n",
    "y_naive = X[-n_validation_frames-n_test_frames:-n_test_frames, 0, -1, new_cases_index]\n",
    "# y_naive = X_validate_cnn_model[:, -1, new_cases_index]\n",
    "y_predict = cnn_model.predict(X_validate_cnn_model).ravel()\n",
    "model_analysis(y_true, y_naive, y_predict, title='CNN')\n",
    "# y_true = y_validate.ravel()\n",
    "# y_naive = y[-(n_validation_frames+n_test_frames+n_days_into_future):-(n_test_frames+n_days_into_future), :].ravel()\n",
    "# y_predict = model.predict(X_validate).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = y_train.ravel()\n",
    "# y_naive = X[:-n_validation_frames-n_test_frames, 0, -1, new_cases_index]\n",
    "# y_predict = cnn_model.predict(X_train_cnn_model).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('There were {} negative predictions'.format(len(y_predict[y_predict<0])))\n",
    "# y_predict[y_predict<0]=0\n",
    "\n",
    "\n",
    "# mae_train_naive = mean_absolute_error(y_true.ravel(), y_naive.ravel())\n",
    "# mae_predict = mean_absolute_error(y_true.ravel(), y_predict)\n",
    "# r2_train_naive = explained_variance_score(y_true.ravel(), y_naive.ravel())\n",
    "# r2_predict = explained_variance_score(y_true.ravel(), y_predict)\n",
    "\n",
    "# print('{}-step MSE [Naive, CNN] = [{},{}]'.format(\n",
    "# n_days_into_future, mae_train_naive, mae_predict))\n",
    "# print('{}-step R^2 [Naive, CNN] = [{},{}]'.format(\n",
    "# n_days_into_future, r2_train_naive, r2_predict))\n",
    "\n",
    "# true_predict_plot(y_true.ravel(), y_naive.ravel(), y_predict, title='CNN model')\n",
    "# residual_diff_plots(y_true.ravel(), y_naive.ravel(), y_predict , n_days_into_future, data.location.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_validate.ravel()\n",
    "y_naive = X[-n_validation_frames-n_test_frames:-n_test_frames, 0, -1, new_cases_index]\n",
    "y_predict = model.predict(X_validate).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae_naive = mean_squared_error(y_validate, y_naive)\n",
    "# mae_predict = mean_squared_error(y_validate, y_predict)\n",
    "# r2_naive = explained_variance_score(y_validate, y_naive)\n",
    "# r2_predict = explained_variance_score(y_validate, y_predict)\n",
    "\n",
    "# print('{}-step MSE [Naive, CNN] = [{},{}]'.format(\n",
    "# n_days_into_future, mae_naive, mae_predict))\n",
    "# print('{}-step R^2 [Naive, CNN] = [{},{}]'.format(\n",
    "# n_days_into_future, r2_naive, r2_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_predict_plot(y_validate, y_naive, y_predict, title='')\n",
    "# residual_diff_plots(y_validate.ravel(),y_naive, y_predict, n_days_into_future, n_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots of train, validate, test sets, by plotting all values in black first I can ensure that the points\n",
    "are correctly ordered and at the correct values because it makes the rest of the points look like they have black borders.\n",
    "The \"missing\" data point at the end is because it is in the prediction variable y, and not in X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first the following plot looks wrong because y looks like it is 1-day behind but this is only because I am\n",
    "not providing the time values. I.e. the 5th value of y is actually the 6th value of X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[-30:,0,-1,:], label='x')\n",
    "plt.plot(y[-30:], label='y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "ax.scatter(range(len(X)), X[:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=30,color='k')\n",
    "ax.scatter(range(len(X_train)), X_train[:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=10, label='train')\n",
    "ax.scatter(range(len(X_train), len(X_train)+len(X_validate)), X_validate[:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=10, label='validate')\n",
    "ax.scatter(range(len(X_train)+len(X_validate), len(X)), X_test[:,np.where(data.location.unique()=='United States')[0],-1,new_cases_index], s=10, label='test')\n",
    "ax.plot(data[data.location=='United States'].new_cases_per_million.values[frame_size-1:-1], color='k',alpha=0.2)\n",
    "plt.legend()\n",
    "_ = plt.show()\n",
    "# plt.plot(X_validate[:,0,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = pd.read_csv('regression_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single feature regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prune = 2\n",
    "mae_list_naive = []\n",
    "r2_list_naive = []\n",
    "mae_list_predict = []\n",
    "r2_list_predict = []\n",
    "# data = data[data.time_index >= first_day]\n",
    "model_data = data.new_cases_per_million.to_frame().copy()#.apply(lambda x : np.log(x+1))\n",
    "new_cases_index = column_search(model_data,'new_cases_per_million',threshold='match', return_style='iloc')[0]\n",
    "n_countries = data.location.nunique()\n",
    "target_data = data.new_cases_per_million\n",
    "time_index = data.time_index\n",
    "frame_size = 14\n",
    "start_date = frame_size-1 #+ time_index.min()\n",
    "# start_date = 50\n",
    "n_validation_frames = 7\n",
    "n_test_frames = 1\n",
    "n_days_into_future = 1\n",
    "train_or_test = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_Xy(model_data, target_data, time_index, start_date, frame_size, n_days_into_future, n_countries)\n",
    "splits, indices = split_Xy(X, y, frame_size, n_validation_frames, n_test_frames)\n",
    "(X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "(train_indices, validate_indices, test_indices) = indices\n",
    "\n",
    "X_regression = np.concatenate(X.reshape(X.shape[0], X.shape[1], -1), axis=0)[:-1,:]\n",
    "y_regression = y.ravel()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_regression_model = np.concatenate(X_train.reshape(X_train.shape[0], X_train.shape[1], -1), axis=0)\n",
    "# X_test_regression_model = np.concatenate(X_test.reshape(X_test.shape[0], X_test.shape[1], -1), axis=0)\n",
    "# X_validate_regression_model = np.concatenate(X_validate.reshape(X_validate.shape[0], X_validate.shape[1], -1), axis=0)\n",
    "# y_validate_regression_model = y_validate.ravel()\n",
    "# y_train_regression_model = y_train.ravel()\n",
    "# y_test_regression_model = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation (slicing off last row) is because X_regression is both training and validation\n",
    "data to be sliced by the train, validation indices passed to Ridge CV. i.e. the holdout set is being held out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[-1]\n",
    "last_day_new_cases_index = np.ravel_multi_index([[frame_size-1],[new_cases_index]],(frame_size, n_features))\n",
    "X_regression[train_indices, last_day_new_cases_index]-X_train[:, :, -1, new_cases_index].ravel()\n",
    "X[train_indices,0,-1,new_cases_index]-X_train[:, :, -1, new_cases_index].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unscaled train predictions; single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "regression_model = RidgeCV(scoring=scorer, cv=[[train_indices, validate_indices]]) \n",
    "_ = regression_model.fit(X_regression, y_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_train_regression_model\n",
    "y_naive =  X_regression[train_indices, last_day_new_cases_index]\n",
    "_, y_predict, mse = classifier_analysis(regression_model, X_train_regression_model, \n",
    "                                             y_train_regression_model.ravel(), \n",
    "                                             plot=False, metric='mse')\n",
    "\n",
    "print('There were {} negative predictions'.format(len(y_predict[y_predict<0])))\n",
    "y_predict[y_predict<0]=0\n",
    "\n",
    "\n",
    "mae_train_naive = mean_absolute_error(y_true.ravel(), y_naive.ravel())\n",
    "mae_predict = mean_absolute_error(y_true.ravel(), y_predict)\n",
    "r2_train_naive = explained_variance_score(y_true.ravel(), y_naive.ravel())\n",
    "r2_predict = explained_variance_score(y_true.ravel(), y_predict)\n",
    "\n",
    "print('{}-step MSE [Naive, Ridge Regression] = [{},{}]'.format(\n",
    "n_days_into_future, mae_train_naive, mae_predict))\n",
    "print('{}-step R^2 [Naive, Ridge Regression] = [{},{}]'.format(\n",
    "n_days_into_future, r2_train_naive, r2_predict))\n",
    "\n",
    "true_predict_plot(y_true.ravel(), y_naive.ravel(), y_predict,s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unscaled validate predictions; single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_validate_regression_model\n",
    "y_naive =  X_regression[validate_indices, last_day_new_cases_index]\n",
    "_, y_predict, mse = classifier_analysis(regression_model, X_validate_regression_model, \n",
    "                                             y_validate_regression_model.ravel(), \n",
    "                                             plot=False, metric='mse')\n",
    "model_analysis(y_true, y_naive, y_predict, title='CNN')\n",
    "\n",
    "# print('There were {} negative predictions'.format(len(y_predict[y_predict<0])))\n",
    "# y_predict[y_predict<0]=0\n",
    "\n",
    "\n",
    "# mae_train_naive = mean_absolute_error(y_true.ravel(), y_naive.ravel())\n",
    "# mae_predict = mean_absolute_error(y_true.ravel(), y_predict)\n",
    "# r2_train_naive = explained_variance_score(y_true.ravel(), y_naive.ravel())\n",
    "# r2_predict = explained_variance_score(y_true.ravel(), y_predict)\n",
    "\n",
    "# print('{}-step MSE [Naive, Ridge Regression] = [{},{}]'.format(\n",
    "# n_days_into_future, mae_train_naive, mae_predict))\n",
    "# print('{}-step R^2 [Naive, Ridge Regression] = [{},{}]'.format(\n",
    "# n_days_into_future, r2_train_naive, r2_predict))\n",
    "\n",
    "# true_predict_plot(y_true.ravel(), y_naive.ravel(), y_predict)\n",
    "# residual_diff_plots(y_true.ravel(), y_naive.ravel(), y_predict , n_days_into_future, data.location.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, X_train.shape[0]+1):\n",
    "#     # find the minima and maxima of all features for all countries, ranging up to current frame and \n",
    "#     # each time step in the frame. \n",
    "#     up_to_current_frame_min = X_train[:i,:,:,:].min((0,1,2))\n",
    "#     up_to_current_frame_max = X_train[:i,:,:,:].max((0,1,2))\n",
    "#     latest_min_array = np.tile(up_to_current_frame_min[np.newaxis, np.newaxis, np.newaxis, :],(1,1,frame_size,1))\n",
    "#     latest_max_array = np.tile(up_to_current_frame_max[np.newaxis, np.newaxis, np.newaxis, :],(1,1,frame_size,1))\n",
    "#     if i == 1:\n",
    "#         frame_min_array = latest_min_array\n",
    "#         frame_max_array = latest_max_array\n",
    "#     else:\n",
    "\n",
    "#         frame_min_array = np.concatenate((frame_min_array, \n",
    "#                                                latest_min_array)\n",
    "#                                               ,axis=0)\n",
    "#         frame_max_array = np.concatenate((frame_max_array, \n",
    "#                                                latest_max_array)\n",
    "#                                               ,axis=0)\n",
    "        \n",
    "\n",
    "# frame_minmax_denominator = (frame_max_array-frame_min_array)\n",
    "# num_zeros_train = (frame_minmax_denominator==0).sum()\n",
    "\n",
    "# frame_minmax_denominator[np.where(frame_minmax_denominator==0)]=1\n",
    "# X_train = 0.5*(X_train - frame_min_array) / frame_minmax_denominator\n",
    "# # Use the latest min and max for test scaling.\n",
    "\n",
    "# frame_denom_for_test = latest_max_array - latest_min_array\n",
    "# num_zeros_test = (frame_denom_for_test==0).sum()\n",
    "\n",
    "# frame_denom_for_test[np.where(frame_denom_for_test==0)] = 1\n",
    "\n",
    "# X_validate = 0.5*(X_validate - latest_min_array) / frame_denom_for_test\n",
    "# X_test = 0.5*(X_test - latest_min_array) / frame_denom_for_test\n",
    "\n",
    "# # Rescale to 0.5 to 1 to account for new maximums. How does this even help?        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaled single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prune = 2\n",
    "mae_list_naive = []\n",
    "r2_list_naive = []\n",
    "mae_list_predict = []\n",
    "r2_list_predict = []\n",
    "# data = data[data.time_index >= first_day]\n",
    "model_data = data.new_cases_per_million.to_frame().copy()#.apply(lambda x : np.log(x+1))\n",
    "new_cases_index = column_search(model_data,'new_cases_per_million',threshold='match', return_style='iloc')[0]\n",
    "n_countries = data.location.nunique()\n",
    "target_data = data.new_cases_per_million\n",
    "time_index = data.time_index\n",
    "frame_size = 14\n",
    "start_date = frame_size-1 #+ time_index.min()\n",
    "# start_date = 50\n",
    "n_validation_frames = 7\n",
    "n_test_frames = 1\n",
    "n_days_into_future = 1\n",
    "train_or_test = 'train'\n",
    "\n",
    "X, y = create_Xy(model_data, target_data, time_index, start_date, frame_size, n_days_into_future, n_countries)\n",
    "splits, indices = split_Xy(X, y, frame_size, n_validation_frames, n_test_frames)\n",
    "(X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "(train_indices, validate_indices, test_indices) = indices\n",
    "\n",
    "scaled_splits =  normalize_Xy_splits(splits, feature_range=(0,0.5),\n",
    "                                     normalization_method='minmax',\n",
    "                                     train_test_only=False,\n",
    "                                     feature_indices=None)\n",
    "\n",
    "(X_train, y_train, X_validate, y_validate, X_test, y_test) = scaled_splits\n",
    "\n",
    "X_train_regression_model = np.concatenate(X_train.reshape(X_train.shape[0], X_train.shape[1], -1), axis=0)\n",
    "X_test_regression_model = np.concatenate(X_test.reshape(X_test.shape[0], X_test.shape[1], -1), axis=0)\n",
    "X_validate_regression_model = np.concatenate(X_validate.reshape(X_validate.shape[0], X_validate.shape[1], -1), axis=0)\n",
    "y_validate_regression_model = y_validate.ravel()\n",
    "y_train_regression_model = y_train.ravel()\n",
    "y_test_regression_model = y_test.ravel()\n",
    "\n",
    "X_regression = np.concatenate(X.reshape(X.shape[0], X.shape[1], -1), axis=0)[:-1,:]\n",
    "X_regression = np.concatenate((X_train_regression_model, X_validate_regression_model),axis=0)\n",
    "y_regression = y.ravel()[:-1]\n",
    "\n",
    "n_features = X.shape[-1]\n",
    "last_day_new_cases_index = np.ravel_multi_index([[frame_size-1],[new_cases_index]],(frame_size, n_features))\n",
    "# X_regression[train_indices, last_day_new_cases_index]-X_train[:, :, -1, new_cases_index].ravel()\n",
    "# X[train_indices,0,-1,new_cases_index]-X_train[:, :, -1, new_cases_index].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "regression_model = RidgeCV(scoring=scorer, cv=[[train_indices, validate_indices]]) \n",
    "_ = regression_model.fit(X_regression, y_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_validate_regression_model.ravel()\n",
    "y_naive = X[-n_validation_frames-n_test_frames:-n_test_frames, 0, -1, new_cases_index]\n",
    "y_predict = regression_model.predict(X_validate_regression_model).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analysis(y_true, y_naive, y_predict, title='Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"All\" feature prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prune = 2\n",
    "mae_list_naive = []\n",
    "r2_list_naive = []\n",
    "mae_list_predict = []\n",
    "r2_list_predict = []\n",
    "# data = data[data.time_index >= first_day]\n",
    "regression_model_data = data.iloc[:, 1:].copy()#.apply(lambda x : np.log(x+1))\n",
    "new_cases_index = column_search(regression_model_data,'new_cases_per_million',threshold='match', return_style='iloc')[0]\n",
    "n_countries = data.location.nunique()\n",
    "target_data = data.new_cases_per_million\n",
    "time_index = data.time_index\n",
    "frame_size = 14\n",
    "start_date = frame_size-1 #+ time_index.min()\n",
    "# start_date = 50\n",
    "n_validation_frames = 7\n",
    "n_test_frames = 1\n",
    "n_days_into_future = 1\n",
    "train_or_test = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = X_test\n",
    "y_true = y_test\n",
    "y_predict_r = regression_model.predict(X_test)\n",
    "y_predict_c = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for max_date_in_window in range(start_date, time_index.max() - n_days_into_future + 1):\n",
    "#     # Take all model_data with date proxy less than numerical value, leading_window_date_not_included\n",
    "#     frame_data = model_data[(time_index <= max_date_in_window) & \n",
    "#                             (time_index > max_date_in_window-frame_size)]\n",
    "#     #     print(frame_data.shape)\n",
    "#     # Reshape the array such that each element along axis=0 is a time series of all feature model_data of a specific country.\n",
    "#     reshaped_frame_data = frame_data.values.reshape(n_countries, frame_size, -1)\n",
    "#     #     print(reshaped_frame_data.shape)\n",
    "#     # Truncate / pad the windows along the \"time\" axis, axis=1. (pad_sequences takes in an iterable of iterables;\n",
    "#     # the first axis is always the default iteration axis. \n",
    "#     # *********************** WARNING: pad_sequences converts to integers by default *********************\n",
    "#     resized_frame_data = pad_sequences(reshaped_frame_data, maxlen=frame_size, dtype=np.float64)\n",
    "#     frame_data_4D = resized_frame_data[np.newaxis, :, :, :]\n",
    "#     if max_date_in_window == start_date:\n",
    "#         X = frame_data_4D.copy()\n",
    "#     else:\n",
    "#         X = np.concatenate((X, frame_data_4D),axis=0)\n",
    "\n",
    "        \n",
    "# y = target_data.values[-X.shape[0]:].reshape(-1,1)\n",
    "# y_time_index = time_index.values[-X.shape[0]:].reshape(-1,1)\n",
    "# # y = target_data.values.transpose()[-X.shape[0]:,:]\n",
    "# # y_time_index = time_index.values.reshape(-1, time_index.nunique()).transpose()[-X.shape[0]:]\n",
    "\n",
    "# y_train =  y[:-(n_validation_frames+n_test_frames),:]\n",
    "# y_validate = y[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "# X_train= X[:-(n_validation_frames+n_test_frames),:,:,:]\n",
    "# y_train =  y[:-(n_validation_frames+n_test_frames),:]\n",
    "# X_validate = X[-(n_validation_frames+n_test_frames):-n_test_frames, :, :, :]\n",
    "# y_validate = y[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "# X_test = X[-n_test_frames:, :, :, :] \n",
    "# y_test = y[-n_test_frames:, :]\n",
    "# splits =  (X_train, y_train, X_validate, y_validate,\n",
    "#            X_test, y_test)\n",
    "\n",
    "# y_train_time = y_time_index[:-(n_validation_frames+n_test_frames),:]\n",
    "# y_validate_time = y_time_index[-(n_validation_frames+n_test_frames):-n_test_frames, :]\n",
    "# y_test_time = y_time_index[-n_test_frames:, :]\n",
    "\n",
    "# Before normalization, plot the splits \n",
    "\n",
    "#     # Note that the last frame (date_range) that exists in X has already been determined by the choice of the number\n",
    "#     # of steps to predict in the future, this is only slicing the frames. \n",
    "#     if train_test_only:\n",
    "#         (X_train, y_train, X_test, y_test) = splits\n",
    "#     else:\n",
    "#         (X_train, y_train, X_validate, y_validate, X_test, y_test) = splits\n",
    "\n",
    "# #     if normalization_method=='minmax':\n",
    "#         # To encapsulate the time-dependent nature of the problem and ignore the dramatic difference between current\n",
    "#         # and initial behavior, only rescale the validation and testing frames by the most recent frame's values.\n",
    "#         # There is only a single value per feature in this case, meaning that to rescale, the values need to\n",
    "#         # be repeated for each validation, test frame for each country for each timestep.\n",
    "#     X_min = X_train.min(axis=(2))\n",
    "#     X_max = X_train.max(axis=(2))\n",
    "\n",
    "\n",
    "#     X_train_scaled = minmax(X_train, X_min[:, :, np.newaxis, :],\n",
    "#                     X_max[:, :, np.newaxis, :])\n",
    "#     X_test_scaled = minmax(X_test, X_min[-1][np.newaxis, :, np.newaxis, :], \n",
    "#                            X_max[-1][np.newaxis, :, np.newaxis, :])\n",
    "#     if train_test_only:\n",
    "#     # Normalize the training data by each frame's specific mean and std deviation. \n",
    "#         splits = (X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "#     else:\n",
    "#         X_validate_scaled = minmax(X_validate, X_min[-1,:][np.newaxis, :, np.newaxis, :], \n",
    "#                                    X_max[-1,:][np.newaxis, :, np.newaxis, :])\n",
    "#         splits = (X_train_scaled, y_train, X_validate_scaled, y_validate, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
