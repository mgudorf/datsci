{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, plot_precision_recall_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, Binarizer, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import average_precision_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that combines different classification metrics to avoid repeated large blocks of code.\n",
    "# Produces the confusion matrix, classification report (precision, recall, f1-score,..)\n",
    "# ROC-AUC and ROC curve\n",
    "# Precision-recall curve\n",
    "\n",
    "def classifier_analysis(clf, X_test, y_test):\n",
    "    y_predict = clf.predict(X_test_processed)\n",
    "    y_predict_proba= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print('tn, fp, fn, tp', cm.ravel())\n",
    "    _ = ConfusionMatrixDisplay(cm, [0,1]).plot()\n",
    "    \n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "    logit_roc_auc = roc_auc_score(y_test, y_predict_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict_proba)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=(clf.__class__.__name__ + '(area = %0.2f)' % logit_roc_auc))\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    average_precision = average_precision_score(y_test, y_predict_proba)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_predict_proba)\n",
    "    disp = plot_precision_recall_curve(clf, X_test_processed, y_test)\n",
    "    disp.ax_.set_ylim([0.0, 1.0])\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "    plt.show()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest and Logistic Regression modeling of loan status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('classification_loan_data.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                     1368\n",
       "funded_amnt                   1368\n",
       "funded_amnt_inv               8821\n",
       "int_rate                       521\n",
       "installment                  59517\n",
       "annual_inc                   40081\n",
       "term                             2\n",
       "grade                            7\n",
       "sub_grade                       35\n",
       "emp_length                      12\n",
       "home_ownership                   6\n",
       "verification_status              3\n",
       "issue_d                        103\n",
       "purpose                         14\n",
       "zip_code                       918\n",
       "addr_state                      51\n",
       "earliest_cr_line               691\n",
       "initial_list_status              2\n",
       "application_type                 2\n",
       "verification_status_joint        2\n",
       "loan_status                      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to take into consideration the time dependence element of this problem. Because we want to predict whether or not\n",
    "to issue a loan, need to take into consideration the time series nature of the issuance date. The main consideration is during the cross-validation process later but reorder the data now as it will later be transformed by one-hot encoding. Specifically, it will be stored in a sparse matrix which is harder to manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will be deprecated after newest data cleaning run. \n",
    "issued_datetime = pd.to_datetime(loan_data.issue_d)\n",
    "\n",
    "loan_data = loan_data.loc[issued_datetime.sort_values().index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a \"hold-out\" set of data that will used for final predictions and analysis after all cross-validation and\n",
    "model learning has been accomplished. The loan issuance dates are aggregated by month, but from the metadata we know that the data is reported *quarterly*. Using this as motivation, the hold-out data will be the most recent quarter. Because the number of loans has grown over time, this one quarter represents nearly $1 / 7$ of all loan data of loans that have either been fully paid or charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data goes from second quarter of 2007 to fourth quarter of 2015; the number of samples are skewed toawrds later dates;\n",
    "# The data is reported quarterly; this should be represented in the cross validation/model selection process.\n",
    "pind = pd.PeriodIndex(issued_datetime, freq='Q-DEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KBins needs numerical variables; use year.quarter (number.decimal). This transformation is not applied to the training data; it's just used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the year to the decimal representing the quarter; Q1 = 0.0 , Q2 = 0.25, Q3 = 0.50, Q4 = 0.75\n",
    "numerical_quarters = pind.year + (pind.quarter - 1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=6\n",
    "kbd = KBinsDiscretizer(n_bins=nb)\n",
    "bin_masks = kbd.fit_transform(numerical_quarters.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93153.,  90943., 115805., 147183.,  64222., 162063.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bin_masks, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn wants iterable containing (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [loan_data.index[np.array(np.sum(bin_masks[:,:i+1],axis=1), dtype=bool)]  for i in range(nb-1)]\n",
    "test_indices = [loan_data.index[np.array(bin_masks[:,i+1], dtype=bool)]  for i in range(nb-1)]\n",
    "train_test_iterable = list(zip(train_indices,test_indices))\n",
    "holdout_train = loan_data.index[np.array(np.sum(bin_masks[:,:-1],axis=1), dtype=bool)] \n",
    "holdout_test = loan_data.index[np.array(bin_masks[:, -1], dtype=bool)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the cross validation folds, now need to create procedure which correctly preprocesses them before testing. Training component of folds are cumulative over time; always want to use as much information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many values for the dates of the earliest credit known credit lines and zip codes; too many at least for one-hot encoding to be practical. Therefore, group zip_code by the first two digits as this retains the geographical information and group the earliest credit_line by using KBinsDiscretizer on the year; it needs a numerical value so the entire date cannot be used without modification. The reason for KBinsDiscretizer is that the distribution is not uniform over time, and it presents an unbiased selection/grouping method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.loc[:,'zip_code'] = loan_data.zip_code.str.split('xx').str.join(sep='').apply(lambda x : x[:-1])#.astype('category')\n",
    "loan_data.loc[:, 'earliest_cr_line'] = pd.to_datetime(loan_data.earliest_cr_line).dt.year.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 673369 entries, 0 to 673368\n",
      "Data columns (total 21 columns):\n",
      "loan_amnt                    673369 non-null int64\n",
      "funded_amnt                  673369 non-null int64\n",
      "funded_amnt_inv              673369 non-null float64\n",
      "int_rate                     673369 non-null float64\n",
      "installment                  673369 non-null float64\n",
      "annual_inc                   673369 non-null float64\n",
      "term                         673369 non-null object\n",
      "grade                        673369 non-null object\n",
      "sub_grade                    673369 non-null object\n",
      "emp_length                   673369 non-null object\n",
      "home_ownership               673369 non-null object\n",
      "verification_status          673369 non-null object\n",
      "issue_d                      673369 non-null object\n",
      "purpose                      673369 non-null object\n",
      "zip_code                     673369 non-null object\n",
      "addr_state                   673369 non-null object\n",
      "earliest_cr_line             673369 non-null object\n",
      "initial_list_status          673369 non-null object\n",
      "application_type             673369 non-null object\n",
      "verification_status_joint    673369 non-null object\n",
      "loan_status                  673369 non-null int64\n",
      "dtypes: float64(4), int64(3), object(14)\n",
      "memory usage: 113.0+ MB\n"
     ]
    }
   ],
   "source": [
    "loan_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = loan_data.select_dtypes(exclude=['object'])\n",
    "cat_data = loan_data.select_dtypes(include=['object'])\n",
    "loan_data = pd.concat((num_data,cat_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = loan_data.loan_status.astype(int)\n",
    "X = loan_data.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "47\n",
      "14327\n",
      "673369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cbd329f4c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, int(y.shape[0] + 1)):\n",
    "    if int(y.shape[0]) % i == 0:\n",
    "        print(i)\n",
    "plt.imshow(y.values.reshape(-1,47), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=['object','category']).columns\n",
    "cat_features = X.select_dtypes(include=['object','category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_categories = [list(np.sort(X[col].unique()))+['Missing','Unknown'] for col in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_transformer = Pipeline(steps=[('scaler', StandardScaler()), ('encoder', KBinsDiscretizer())])\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(categories=uniq_categories,handle_unknown='ignore')\n",
    "col_transformer = ColumnTransformer(transformers=[('num', num_transformer, num_features), \n",
    "                                                  ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special considerations need to be made because the problem is time dependent. The cross validation folds could normally be produced with TimeSeriesSplit(), but the distribution of the continuous numerical variables begs for rescaling. Therein lies the issue; however, as the renormalization using only train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bin categorical data that has too many unique values.\n",
    "2. Convert categorical data to discrete numerical data by means of OneHotEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to reduce capital loss not maximize profits. Therefore, we value prediction of when a loan will be charged off more than fully paid. We can account for this by changing the class weights in the classification process. This model will reject loans that would have been fully paid in order to avoid loans that will become charged off. In other words, the goal is to maximize the number of true positives, where \"positive\" in this case is equivalent to a loan being charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfc_models_ = []\n",
    "\n",
    "for train_indices, test_indices in train_test_iterable:\n",
    "    X_train, y_train = X.loc[train_indices, :], y.loc[train_indices].values.ravel()\n",
    "    X_test, y_test = X.loc[test_indices, :], y.loc[test_indices].values.ravel()\n",
    "\n",
    "    _ = col_transformer.fit(X_train)\n",
    "    X_train_processed = col_transformer.transform(X_train)\n",
    "    X_test_processed = col_transformer.transform(X_test)\n",
    "    class_weights={0:1, 1:1000000}\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs=-1, n_estimators=100, class_weight=class_weights, random_state=42)\n",
    "    rfc_selector = RFE(rfc, step=(X_train_processed.shape[1]//10))\n",
    "    rfc_selector.fit(X_train_processed, y_train)\n",
    "    \n",
    "    rfc_models_ += [rfc_selector]\n",
    "    classifier_analysis(rfc_selector, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models_ = []\n",
    "\n",
    "for train_indices, test_indices in train_test_iterable:\n",
    "    X_train, y_train = X.loc[train_indices, :], y.loc[train_indices].values.ravel()\n",
    "    X_test, y_test = X.loc[test_indices, :], y.loc[test_indices].values.ravel()\n",
    "\n",
    "    _ = col_transformer.fit(X_train)\n",
    "    X_train_processed = col_transformer.transform(X_train)\n",
    "    X_test_processed = col_transformer.transform(X_test)\n",
    "    class_weights={0:1, 1:1000000}\n",
    "    \n",
    "    lr = LogisticRegression(n_jobs=-1, max_iter=300, class_weight=class_weights)\n",
    "    lr_selector = RFE(lr, step=(X_train_processed.shape[1]//10))\n",
    "    lr_selector.fit(X_train_processed, y_train)\n",
    "    \n",
    "    lr_models_ += [lr_selector]\n",
    "    classifier_analysis(lr_selector, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all training/testing data to help scale the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdoutindicestrain, _ = train_test_iterable[1][0], train_test_iterable[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdoutindicestrain =  holdout_indices[0][0]\n",
    "holdoutindicestest = holdout_indices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_holdout = X.loc[holdoutindicestrain, :]#, y.loc[holdoutindicestrain].values.ravel()\n",
    "X_test_holdout, y_test_holdout = X.loc[holdoutindicestest, :], y.loc[holdoutindicestest].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_holdout.shape, X_test_holdout.shape, y_test_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = col_transformer.fit(X_train_holdout)\n",
    "# Just need to fit the column transformer; aren't really training. \n",
    "# X_train_holdout_processed = col_transformer.transform(X_train_holdout)\n",
    "X_test_holdout_processed = col_transformer.transform(X_test_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model_ = ranfor_models[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't actually use the entire training and testing data to scale/encode because it results in more features than the model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_analysis(best_model_, X_test_holdout_processed, y_test_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one hot encoding can throw an error if there are categories in the test set not in the train set; as the categories are\n",
    "quantities known before hand it should be ok to pass to the encoder; or does this contaminate the test data? The issue is that the lack of a category in the training data prevents accurate prediction as by definition there is no training done on those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it ok to \"look at\" the test data? The issue arises when there are categories that are in the testing set that are not\n",
    "in the training set. If the time-series cross validation folds are not cumulative then this becomes even more of a problem.\n",
    "If kept as a general procedure, that is, relabel any categories unique to the testing set as \"Unknown\", then perhaps it can work. I.e. relabel values in the testing set that are \"unknown\" to the training set; this dummy variable is a flag to the algorithm that these values are \"special\". From Mike; if we know the categories before hand, use that set of unique values and then add two dummy columns: \"Missing\" and \"Unknown/New\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranfor_param_grid={'n_estimators':[5,10,15]}\n",
    "# logreg_param_grid = {'tol':[1e-1, 1e-2, 1e-4]}\n",
    "\n",
    "# ranfor_cv = RandomForestClassifier(class_weight='balanced')\n",
    "# ranfor_model_ = GridSearchCV(ranfor_cv, ranfor_param_grid, cv=TimeSeriesSplit(n_splits=3))\n",
    "# ranfor_model_.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
