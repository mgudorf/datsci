{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D,AveragePooling1D, SeparableConv2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def country_groupby(df):\n",
    "    return [df[df.location==country].index for country in df.location.unique()]\n",
    "\n",
    "def country_search(df, country):\n",
    "    return df[df.location==country].index\n",
    "\n",
    "def column_search(df, name, return_style='loc', threshold='contains'):\n",
    "    if threshold=='contains':\n",
    "        func = df.columns.str.contains\n",
    "    else:\n",
    "        func = df.columns.str.match\n",
    "        \n",
    "    if return_style == 'loc':\n",
    "        return df.columns[func(name)]\n",
    "    elif return_style== 'iloc':\n",
    "        return np.where(func(name))[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cnn_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First course of action is to decide on the format of the inputs. For now, focus on 1-D convolution only.\n",
    "Need to decide on the dimension of the inputs. The typical format is (batch size, time steps, n_features). \n",
    "Two quick ideas :\n",
    "\n",
    "I think the simplest is to just find all windows of length $n$ for all countries such that the input dimension would be\n",
    "input_dim = (n_countries * n_windows, window_size, n_features) \n",
    "\n",
    "The other idea I had would be to do (n_windows, n_countries, window_size, n_features), and then the output would be the future values for each country.\n",
    "\n",
    "Just do the first for now. Also, just do a one-step model for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to predict n_cases_weighted (weighted by the percentage of the population that the country consists of. Might be a dumb idea.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='date')\n",
    "data.loc[:, 'date_proxy'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17935</th>\n",
       "      <td>0.272393</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.359064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17936</th>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.359064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17937</th>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.359064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17938</th>\n",
       "      <td>0.359064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17940 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4    5    6    7    8    9    10  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "17935  0.272393  0.307474  0.307474  0.359064  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "17936  0.307474  0.307474  0.359064       NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "17937  0.307474  0.359064       NaN       NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "17938  0.359064       NaN       NaN       NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "17939       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "        11   12   13   14  \n",
       "0      0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  \n",
       "17935  NaN  NaN  NaN  NaN  \n",
       "17936  NaN  NaN  NaN  NaN  \n",
       "17937  NaN  NaN  NaN  NaN  \n",
       "17938  NaN  NaN  NaN  NaN  \n",
       "17939  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[17940 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 15):\n",
    "    if i == 1:\n",
    "        target_data =  data.groupby('location').shift(-i).n_cases_weighted.copy()\n",
    "    else:\n",
    "        target_data = pd.concat((target_data,  data.groupby('location').shift(-i).n_cases_weighted),axis=1)\n",
    "\n",
    "target_data.columns = [i for i in range(1, 15)]\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_countries = data.location.nunique()\n",
    "n_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how I will be concatenating, slicing, padding, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 138, 32, 152)\n"
     ]
    }
   ],
   "source": [
    "model_data = data.iloc[:, 1:]\n",
    "max_date_in_window = 32\n",
    "window_size = 32\n",
    "\n",
    "# Take all model_data with date proxy less than numerical value, leading_window_date_not_included\n",
    "windowed_data = model_data[model_data.date_proxy <= max_date_in_window]\n",
    "#     print(windowed_data.shape)\n",
    "\n",
    "# Reshape the array such that each element along axis=0 is a time series of all feature model_data of a specific country.\n",
    "reshaped_windowed_data = windowed_data.values.reshape(n_countries, max_date_in_window, -1)\n",
    "#     print(reshaped_windowed_data.shape)\n",
    "\n",
    "# Truncate / pad the windows along the \"time\" axis, axis=1. (pad_sequences takes in an iterable of iterables;\n",
    "# the first axis is always the default iteration axis. \n",
    "resized_window_data = pad_sequences(reshaped_windowed_data, maxlen=window_size)\n",
    "#     print(resized_window_data.shape)\n",
    "\n",
    "# \n",
    "window_data_4d = resized_window_data[np.newaxis, :, :, :]\n",
    "if max_date_in_window == window_size:\n",
    "    X = window_data_4d.copy()\n",
    "else:\n",
    "    X = np.concatenate((X, window_data_4d),axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "n_windows, n_countries, n_time_steps, n_features = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By iterating over possible leading window dates (window right edge, not inclusive),\n",
    "a 4-d tensor with dimensions given by the following is created:\n",
    "    \n",
    "```(n_windows, n_countries, n_time_steps, n_features)```\n",
    "\n",
    "Even if I don't use the input of this form, it makes it much easier to slice into train, validate and test, by slicing along\n",
    "the ```n_windows``` axis. \n",
    "\n",
    "Note that if I also only wanted to include data from after the first case, that is possible by slicing data.time_index >= 1 \n",
    "\n",
    "Putting this all together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c9429ad308>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.n_cases_weighted.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 138, 32, 152)\n",
      "(66, 138)\n"
     ]
    }
   ],
   "source": [
    "model_data = data.iloc[:, 1:]\n",
    "start_date = 64\n",
    "window_size = 32\n",
    "n_days_into_future = 1\n",
    "# can't include the max date because need at least 1 day in future to predict. +1 because of how range doesn't include endpoint\n",
    "for max_date_in_window in range(start_date, model_data.date_proxy.max() - n_days_into_future + 1):\n",
    " \n",
    "    # Take all model_data with date proxy less than numerical value, leading_window_date_not_included\n",
    "    windowed_data = model_data[model_data.date_proxy <= max_date_in_window]\n",
    "    #     print(windowed_data.shape)\n",
    "    # Reshape the array such that each element along axis=0 is a time series of all feature model_data of a specific country.\n",
    "    reshaped_windowed_data = windowed_data.values.reshape(n_countries, max_date_in_window, -1)\n",
    "    #     print(reshaped_windowed_data.shape)\n",
    "    # Truncate / pad the windows along the \"time\" axis, axis=1. (pad_sequences takes in an iterable of iterables;\n",
    "    # the first axis is always the default iteration axis. \n",
    "    resized_window_data = pad_sequences(reshaped_windowed_data, maxlen=window_size)\n",
    "    \n",
    "    window_data_4d = resized_window_data[np.newaxis, :, :, :]\n",
    "\n",
    "    #     print(resized_window_data.shape)\n",
    "    #\n",
    "    future_index = model_data[model_data.date_proxy == max_date_in_window].index\n",
    "    n_step_predictions = target_data.loc[future_index, n_days_into_future]\n",
    "    if max_date_in_window == start_date:\n",
    "        X = window_data_4d.copy()\n",
    "        y = n_step_predictions.values.reshape(1,-1)\n",
    "    else:\n",
    "        X = np.concatenate((X, window_data_4d),axis=0)\n",
    "        y = np.concatenate((y, n_step_predictions.values.reshape(1,-1)),axis=0)\n",
    "print(X.shape)\n",
    "n_windows, n_countries, n_time_steps, n_features = X.shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method of slicing target values\n",
    "#     future_index = model_data[model_data.date_proxy == leading_window_date_included + n_days_into_future].index\n",
    "#     n_step_predictions = model_data.loc[future_index, 'n_cases_weighted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, splitting X intro train, validate, test, is as easy as slicing the first axis. Depending on how the CNN is set up, this\n",
    "axis can later be flattened by simply applying ```np.concatenate(X_train, axis=0)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the target data ```y```. To be as general as possible, I note that I should first shift the time series and combine them to store all of the data, and THEN manipulate it, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that ```X``` is of the shape ```(n_windows, n_countries, n_time_steps, n_features)```, the target data ```y``` should\n",
    "be of shape ```(n_windows, n_countries)``` and the values for each slice of the first axis is then of shape ```(n_countries,)```, with the values equaling the ```model_data.n_cases_weighted``` value for ```date_proxy == window_right_edge_inclusive + n```, where n is the prediction step size. \n",
    "\n",
    "Because we need future values with which to measure error, the maximum that the leading window edge can be is always \n",
    "\n",
    "```model_data.date_proxy.max() - n```\n",
    "\n",
    "In other words, because the maximum date value is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.date_proxy.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to predict (and measure error) for 7 days in the future, the last window would have leading edge \n",
    "```model_data.date_proxy == 123```. \n",
    "\n",
    "For now, just test the waters with a 1-day prediction.\n",
    "To do so, first split the X and y data into train, validate, test.\n",
    "For the first attempt at a model, use Conv1D only, have to flatten the data with concatenations.\n",
    "Before this, however, I want to rescale the data. Now, because each different element in the first axis is a different time range, the correct action is to (if normalizing) take the mean with respect to axis=1 and axis=2 ```n_countries``` and  ```n_time_steps```. This leaves a total number of averages of shape ```(n_windows, n_features)```, i.e. the mean and standard deviations for each feature for each date range. This ensures that no data snooping has occurred. To actually subtract and divide by these values, need to reform the same shape array (or at least that seems to be the easiest method to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.concatenate(X[:-7,:,:,:],axis=0), np.concatenate(y[:-7,:],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalization approach I'm using doesn't utilize all values in the history to normalize; only values in the specific windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmean = np.tile(X[:-7,:,:,:].std(axis=(1,2))[:, np.newaxis, np.newaxis, :], (1, n_countries, n_time_steps, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to check, the slice [0, :, :, 0] should only contain one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.233093    4416\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Xmean[0,:,:,0].ravel()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X_means = np.tile(X.mean(axis=(1,2))[:, np.newaxis, np.newaxis, :], (1, n_countries, n_time_steps, 1))\n",
    "    X_stds = np.tile(X.std(axis=(1,2))[:, np.newaxis, np.newaxis, :], (1, n_countries, n_time_steps, 1))\n",
    "    return (X - X_means) / X_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:-7,:,:,:], y[:-7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_means = np.tile(X_train.mean(axis=(1,2))[:, np.newaxis, np.newaxis, :], (1, n_countries, n_time_steps, 1))\n",
    "X_training_stds = np.tile(X_train.std(axis=(1,2))[:, np.newaxis, np.newaxis, :], (1, n_countries, n_time_steps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train - X_training_means) / X_training_stds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=(1,2))[-1,:][np.newaxis, np.newaxis, np.newaxis, :]\n",
    "X_std = X_train.std(axis=(1,2))[-1,:][np.newaxis, np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate, y_validate = X[-7:-4,:,:,:], y[-7:-4,:]\n",
    "X_test, y_test = X[-4:,:,:,:], y[-4:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = np.concatenate(((X_validate - np.tile(X_mean, (X_validate.shape[0],X_validate.shape[1],X_validate.shape[2],1)))\n",
    "                / np.tile(X_std, (X_validate.shape[0],X_validate.shape[1],X_validate.shape[2],1))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate(((X_test - np.tile(X_mean, (X_test.shape[0],X_test.shape[1],X_test.shape[2],1))) \n",
    "            / np.tile(X_std, (X_test.shape[0],X_test.shape[1],X_test.shape[2],1))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_validate, y_test = np.concatenate(y_train, axis=0),np.concatenate(y_validate, axis=0),np.concatenate(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_validate, y_validate = np.concatenate(normalize(X[-7:-4,:,:,:]), axis=0), np.concatenate(y[-7:-4,:],axis=0)\n",
    "# X_test, y_test = np.concatenate(normalize(X[-4:,:,:,:]), axis=0), np.concatenate(y[-4:,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = np.concatenate(normalize(X[:-7,:,:,:]), axis=0), np.concatenate(y[:-7,:],axis=0)\n",
    "# X_validate, y_validate = np.concatenate(normalize(X[-7:-4,:,:,:]), axis=0), np.concatenate(y[-7:-4,:],axis=0)\n",
    "# X_test, y_test = np.concatenate(normalize(X[-4:,:,:,:]), axis=0), np.concatenate(y[-4:,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  elif not isinstance(value, collections.Sized):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8142 samples, validate on 414 samples\n",
      "Epoch 1/10\n",
      "8142/8142 [==============================] - 1s 125us/sample - loss: 582.6169 - val_loss: 34617250.1546\n",
      "Epoch 2/10\n",
      "8142/8142 [==============================] - 1s 107us/sample - loss: 581.6158 - val_loss: 65273568.7343\n",
      "Epoch 3/10\n",
      "8142/8142 [==============================] - 1s 109us/sample - loss: 580.3932 - val_loss: 115856711.8068\n",
      "Epoch 4/10\n",
      "8142/8142 [==============================] - 1s 109us/sample - loss: 578.2898 - val_loss: 166047052.1353\n",
      "Epoch 5/10\n",
      "8142/8142 [==============================] - 1s 110us/sample - loss: 576.4662 - val_loss: 205057879.7681\n",
      "Epoch 6/10\n",
      "8142/8142 [==============================] - 1s 108us/sample - loss: 573.1527 - val_loss: 247018436.4831\n",
      "Epoch 7/10\n",
      "8142/8142 [==============================] - 1s 108us/sample - loss: 570.4393 - val_loss: 203795531.6715\n",
      "Epoch 8/10\n",
      "8142/8142 [==============================] - 1s 108us/sample - loss: 567.4760 - val_loss: 184871249.8551\n",
      "Epoch 9/10\n",
      "8142/8142 [==============================] - 1s 107us/sample - loss: 564.5514 - val_loss: 129981349.5266\n",
      "Epoch 10/10\n",
      "8142/8142 [==============================] - 1s 107us/sample - loss: 561.0640 - val_loss: 128716362.8213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114438263.88405797"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 25, 256\n",
    "#     n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv1D(filters=8, kernel_size=16, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_validate, y_validate), batch_size=256)\n",
    "# evaluate model\n",
    "model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ymin, ymax = np.min([y_test.min(), y_predict.min()]), np.max([y_test.max(), y_predict.max()])\n",
    "plt.scatter(y_test, y_predict)\n",
    "plt.plot([0,ymax], [0,ymax])\n",
    "plt.ylabel('Predicted value')\n",
    "plt.xlabel('True value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:-7,:,:,:], y[:-7,:]\n",
    "X_validate, y_validate = X[-7:-4,:,:,:], y[-7:-4,:]\n",
    "X_test, y_test = X[-4:,:,:,:], y[-4:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size = 0, 10, 256\n",
    "#     n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "model = Sequential()\n",
    "model.add(SeparableConv2D(filters=128, kernel_size=3, data_format='channels_first', activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "model.fit(trainX, trainy, epochs=epochs, validation_data=(X_validate, y_validate), batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 10, 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
