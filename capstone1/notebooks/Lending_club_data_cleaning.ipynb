{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.impute import SimpleImputer\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"text\", usetex=True)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from re import search\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unbalanced_columns(df, proportion=1):\n",
    "    #Determine the number of samples with the most frequent value; if it equals the number of samples, then drop this column.\n",
    "    columns = df.columns.values\n",
    "    columns_to_drop = columns[[df[col].value_counts().max() >= proportion*len(df) for col in columns]].tolist()\n",
    "    columns_to_drop += columns[[df[col].isna().sum() >= proportion*len(df) for col in columns]].tolist()\n",
    "    print('Dropping', len(columns_to_drop), 'column(s) from DataFrame.')\n",
    "    return df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capital loss prevention : data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this project is to create two predictive models that combine to form a multi-stage recommendation system\n",
    "for the preservation and or recovery of capital. The first model is a classification model that predicts whether or not a loan\n",
    "will be \"Charged-off\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three stages of data cleaning\n",
    "\n",
    "    1. Ensure the integrity of the data for use in exploratory data analysis (EDA)\n",
    "    2. Subset and process the data relevant for the loan-outcome classification problem\n",
    "    3. Subset and process the data relevant for the recovery-amount regression problem\n",
    "    \n",
    "This notebook is focused on cleaning and selecting subsets of the data for different purposes. Any preprocessing\n",
    "required for application of ML algorithms is left for separate notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data cleaning for use in exploratory data analysis (EDA)\n",
    "\n",
    "This doesn't require much as we simply want to ensure the integrity of the data; the data comes in '.csv' format\n",
    "so let us see if it can be imported into a Pandas DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loan_data = pd.read_csv('../data/loan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows for features (columns) to have non-uniform data types, represented by the general category 'object' dtype.\n",
    "Still, we want the dtypes to be uniform to ensure that any manipulations or transformations later on do not cause errors.\n",
    "\n",
    "An example of a problem that could arise: imagine a feature includes strings and lists of strings. Attempting to apply\n",
    "a string based operation such as Python's \"split()\" method would return an error, as lists do not have the aforementioned attribute. \n",
    "\n",
    "Need to deal with mixed dtype columns to make the data consistent and  but first let's see if any of these columns survive the initial processing to remove\n",
    "columns with majority of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the column names from DTypeWarning. Need to clean by converting to one data type. \n",
    "mixed_dtype_column_names = loan_data.columns[[0,19,49,59,118,129,130,131,134,135,136,139,145,146,147]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try to ascertain the cause of this mixed dtype error, let's look at some of the values in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>sec_app_earliest_cr_line</th>\n",
       "      <th>hardship_type</th>\n",
       "      <th>hardship_reason</th>\n",
       "      <th>hardship_status</th>\n",
       "      <th>hardship_start_date</th>\n",
       "      <th>hardship_end_date</th>\n",
       "      <th>payment_plan_start_date</th>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2260691</th>\n",
       "      <td>89996426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260692</th>\n",
       "      <td>90006534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260693</th>\n",
       "      <td>89955820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260694</th>\n",
       "      <td>89885898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260695</th>\n",
       "      <td>88977788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260696</th>\n",
       "      <td>88985880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260697</th>\n",
       "      <td>88224441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Mar-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260698</th>\n",
       "      <td>88215728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260699</th>\n",
       "      <td>Total amount funded in policy code 1: 1465324575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260700</th>\n",
       "      <td>Total amount funded in policy code 2: 521953170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       id desc next_pymnt_d  \\\n",
       "2260691                                          89996426  NaN          NaN   \n",
       "2260692                                          90006534  NaN          NaN   \n",
       "2260693                                          89955820  NaN     Apr-2019   \n",
       "2260694                                          89885898  NaN     Apr-2019   \n",
       "2260695                                          88977788  NaN     Apr-2019   \n",
       "2260696                                          88985880  NaN     Apr-2019   \n",
       "2260697                                          88224441  NaN          NaN   \n",
       "2260698                                          88215728  NaN     Apr-2019   \n",
       "2260699  Total amount funded in policy code 1: 1465324575  NaN          NaN   \n",
       "2260700   Total amount funded in policy code 2: 521953170  NaN          NaN   \n",
       "\n",
       "        verification_status_joint sec_app_earliest_cr_line hardship_type  \\\n",
       "2260691                       NaN                      NaN           NaN   \n",
       "2260692                       NaN                      NaN           NaN   \n",
       "2260693                       NaN                      NaN           NaN   \n",
       "2260694                       NaN                      NaN           NaN   \n",
       "2260695                       NaN                      NaN           NaN   \n",
       "2260696                       NaN                      NaN           NaN   \n",
       "2260697                       NaN                      NaN           NaN   \n",
       "2260698                       NaN                      NaN           NaN   \n",
       "2260699                       NaN                      NaN           NaN   \n",
       "2260700                       NaN                      NaN           NaN   \n",
       "\n",
       "        hardship_reason hardship_status hardship_start_date hardship_end_date  \\\n",
       "2260691             NaN             NaN                 NaN               NaN   \n",
       "2260692             NaN             NaN                 NaN               NaN   \n",
       "2260693             NaN             NaN                 NaN               NaN   \n",
       "2260694             NaN             NaN                 NaN               NaN   \n",
       "2260695             NaN             NaN                 NaN               NaN   \n",
       "2260696             NaN             NaN                 NaN               NaN   \n",
       "2260697             NaN             NaN                 NaN               NaN   \n",
       "2260698             NaN             NaN                 NaN               NaN   \n",
       "2260699             NaN             NaN                 NaN               NaN   \n",
       "2260700             NaN             NaN                 NaN               NaN   \n",
       "\n",
       "        payment_plan_start_date hardship_loan_status  \\\n",
       "2260691                     NaN                  NaN   \n",
       "2260692                     NaN                  NaN   \n",
       "2260693                     NaN                  NaN   \n",
       "2260694                     NaN                  NaN   \n",
       "2260695                     NaN                  NaN   \n",
       "2260696                     NaN                  NaN   \n",
       "2260697                     NaN                  NaN   \n",
       "2260698                     NaN                  NaN   \n",
       "2260699                     NaN                  NaN   \n",
       "2260700                     NaN                  NaN   \n",
       "\n",
       "        debt_settlement_flag_date settlement_status settlement_date  \n",
       "2260691                       NaN               NaN             NaN  \n",
       "2260692                       NaN               NaN             NaN  \n",
       "2260693                       NaN               NaN             NaN  \n",
       "2260694                       NaN               NaN             NaN  \n",
       "2260695                       NaN               NaN             NaN  \n",
       "2260696                       NaN               NaN             NaN  \n",
       "2260697                  Mar-2019            ACTIVE        Mar-2019  \n",
       "2260698                       NaN               NaN             NaN  \n",
       "2260699                       NaN               NaN             NaN  \n",
       "2260700                       NaN               NaN             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.loc[:, mixed_dtype_column_names].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the mixed dtypes are likely due to a mixture of NumPy's NaN value with strings. \n",
    "Because the features are in essence categorical, the NaN values can be replaced with a new category, 'Missing';\n",
    "this applies to all object dtype columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to eventually reorder the data by date and it doesn't affect any calculations so it's done now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "issued_datetime = pd.to_datetime(loan_data.issue_d)\n",
    "idiosyncratic_columns = ['emp_title', 'desc', 'title','member_id','id','url']\n",
    "loan_data_time_ordered = loan_data.loc[issued_datetime.sort_values().index,:].drop(columns=idiosyncratic_columns)\n",
    "loan_data_time_ordered = loan_data_time_ordered.drop(loan_data_time_ordered.index[loan_data_time_ordered.term.isna()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = loan_data_time_ordered.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the guess for the reason for mixed dtypes was right,\n",
    "check and see that all of these columns with NaN being replaced can undergo a string\n",
    "concatenation operation; I believe this ensure that all elements are strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_status</th>\n",
       "      <th>hardship_start_date</th>\n",
       "      <th>hardship_end_date</th>\n",
       "      <th>payment_plan_start_date</th>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1654413</th>\n",
       "      <td>36 months</td>\n",
       "      <td>A</td>\n",
       "      <td>A5</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>Does not meet the credit policy. Status:Fully ...</td>\n",
       "      <td>n</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654392</th>\n",
       "      <td>36 months</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>Does not meet the credit policy. Status:Fully ...</td>\n",
       "      <td>n</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654393</th>\n",
       "      <td>36 months</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>2 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>Does not meet the credit policy. Status:Fully ...</td>\n",
       "      <td>n</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654394</th>\n",
       "      <td>36 months</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>Does not meet the credit policy. Status:Fully ...</td>\n",
       "      <td>n</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654395</th>\n",
       "      <td>36 months</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>Does not meet the credit policy. Status:Fully ...</td>\n",
       "      <td>n</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               term grade sub_grade emp_length home_ownership  \\\n",
       "1654413   36 months     A        A5   < 1 year           NONE   \n",
       "1654392   36 months     C        C2   < 1 year           RENT   \n",
       "1654393   36 months     B        B4    2 years       MORTGAGE   \n",
       "1654394   36 months     B        B2   < 1 year           RENT   \n",
       "1654395   36 months     C        C4   < 1 year           RENT   \n",
       "\n",
       "        verification_status   issue_d  \\\n",
       "1654413        Not Verified  Jun-2007   \n",
       "1654392        Not Verified  Jun-2007   \n",
       "1654393        Not Verified  Jun-2007   \n",
       "1654394        Not Verified  Jun-2007   \n",
       "1654395        Not Verified  Jun-2007   \n",
       "\n",
       "                                               loan_status pymnt_plan  \\\n",
       "1654413  Does not meet the credit policy. Status:Fully ...          n   \n",
       "1654392  Does not meet the credit policy. Status:Fully ...          n   \n",
       "1654393  Does not meet the credit policy. Status:Fully ...          n   \n",
       "1654394  Does not meet the credit policy. Status:Fully ...          n   \n",
       "1654395  Does not meet the credit policy. Status:Fully ...          n   \n",
       "\n",
       "                    purpose  ... hardship_status hardship_start_date  \\\n",
       "1654413               other  ...             NaN                 NaN   \n",
       "1654392  debt_consolidation  ...             NaN                 NaN   \n",
       "1654393  debt_consolidation  ...             NaN                 NaN   \n",
       "1654394               other  ...             NaN                 NaN   \n",
       "1654395               other  ...             NaN                 NaN   \n",
       "\n",
       "        hardship_end_date payment_plan_start_date hardship_loan_status  \\\n",
       "1654413               NaN                     NaN                  NaN   \n",
       "1654392               NaN                     NaN                  NaN   \n",
       "1654393               NaN                     NaN                  NaN   \n",
       "1654394               NaN                     NaN                  NaN   \n",
       "1654395               NaN                     NaN                  NaN   \n",
       "\n",
       "        disbursement_method debt_settlement_flag debt_settlement_flag_date  \\\n",
       "1654413                Cash                    N                       NaN   \n",
       "1654392                Cash                    N                       NaN   \n",
       "1654393                Cash                    N                       NaN   \n",
       "1654394                Cash                    N                       NaN   \n",
       "1654395                Cash                    N                       NaN   \n",
       "\n",
       "        settlement_status settlement_date  \n",
       "1654413               NaN             NaN  \n",
       "1654392               NaN             NaN  \n",
       "1654393               NaN             NaN  \n",
       "1654394               NaN             NaN  \n",
       "1654395               NaN             NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data.apply(lambda x : x+'').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new category for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = categorical_data.fillna(value='Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we investigate any required manipulations of the numerical data.\n",
    "There were not any importation warnings in regards to the numerical columns; but because the categorical variables were missing values it is likely that the numerical data is also missing values. First let's see how many values are indeed missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = loan_data_time_ordered.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_processing = pd.concat((numerical_data, categorical_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 75675882 missing values in all features\n",
      "This represents 22.17% of the toital data set.\n"
     ]
    }
   ],
   "source": [
    "# Summation of all missing values\n",
    "number_of_missing_values = loan_data_processing.isna().sum().sum()\n",
    "print('There are {} missing values in all features'.format(number_of_missing_values))\n",
    "print('This represents {0:.2f}% of the toital data set.'.format(100*number_of_missing_values/loan_data.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 features missing 50% of their values\n"
     ]
    }
   ],
   "source": [
    "missing_value_percentages = 100 * loan_data_processing.isna().sum() / len(loan_data_processing)\n",
    "print('There are {} features missing 50% of their values'.format(\n",
    "    len(missing_value_percentages[missing_value_percentages > 50.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting question, how are these missing variables distributed? Is it uniform across all features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the percentage of values that are missing per feature as a monotonically decreasing sequence\n",
    "percentnan = numerical_data.isna().sum().sort_values(ascending=False) / len(numerical_data)\n",
    "plt.plot(100*percentnan.values, marker='.',linestyle='none')\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Missing values (percent)')\n",
    "plt.savefig('missing_value_distribution.jpg',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There cannot be any missing values in the final data set used for the machine learning portion of this\n",
    "project. There are two different ways of handling this, but a hybrid method is needed in order to keep as\n",
    "many samples as possible. Namely, the samples with missing values cannot be dropped because that would in fact\n",
    "remove all of the samples. If the features with missing values are dropped then again a majority of the data\n",
    "will be removed. Therefore, I deemed it the best to first drop the features with a vast majority of missing values\n",
    "and then drop the samples that still had missing values afterwards. This avoids dropping features with few missing values.\n",
    "There would be an argument to make that perhaps this is representative of sampling bias but because the sample is so large this is almost surely not the case unless there is something systematic at play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcolthensamp = loan_data_processing.drop(columns=missing_value_percentages[missing_value_percentages>30.0].index)\n",
    "dropcolthensamp = dropcolthensamp.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of features are missing values; this is a problem for some of scikit-learn's machine learning algorithms we\n",
    "want to use; therefore, we need to figure out how to deal with them. We can not simply drop all rows (samples) which have missing values as this would leave us with exactly 0 samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A similar situation is the columns which only have a single value; note that Pandas does not consider missing values as a \"value\" so a distinction needs to be made between literally every sample having the same value features containing a single value and missing values.\n",
    "\n",
    "The distinction between these two types is motivated by the concept of sampling bias. When we train our models with columns which follow the same pattern as 'policy_code', the model will only train on a single value and as such won't be good models for new test data with different values. In other words, the training domain doesn't encapsulate the testing domain and as such the model will have trouble with such predictions.\n",
    "\n",
    "First, determine and drop the features which are dominated by a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 15 column(s) from DataFrame.\n"
     ]
    }
   ],
   "source": [
    "loan_data_processed = drop_unbalanced_columns(dropcolthensamp, proportion=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also certain data whose purpose is to merely contribute noise to the data set. These features have a large number of personalized responses; creating categorical data with a large number of categories. This information could be\n",
    "encoded into a sparse matrix, or tools from natural language processing (NLP) could be applied, but we reject these choices as\n",
    "they do not seem very efficient or useful at the moment.\n",
    "\n",
    "Another reason to do this is because later in the cross validation stage of the modeling process, we would like to only have variables where we know their categories a priori so that they can be encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_processing.to_csv('loan_data_eda.csv', index=False)\n",
    "loan_data_processed.to_csv('loan_data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data cleaning and preprocessing for loan outcome classification problem.\n",
    "\n",
    "The current formulation of this problem is to predict whether or not a loan will be charged off by the time it matures. Therefore, we separate out the data for the loans that have already matured by comparing the most recent date in the dataset\n",
    "to the maturity date. The maturity date is equal to the date the loan was issued added to the length of the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to convert the loan status into a binary variable; label the loans which have been charged off as positive\n",
    "outcome and otherwise as negative. This begs the question; should the data be separated into loans that have past their\n",
    "maturity date? The outcome of a current loan is a nonsensical quantity. Because the answer is not known let's account for both cases. Save the index when subsetting the data so other dataframes can be sliced equivalently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Term' from string to integer years; strings are either ' 36 Months' or ' 60 Months' (note the leading whitespace)\n",
    "terms_num = loan_data_processed.term.str.split(' ').apply(lambda x: int(x[1])//12)\n",
    "\n",
    "issued_date = pd.to_datetime(loan_data_processed.issue_d)\n",
    "\n",
    "# Select the indices for 3 and 5 year loans\n",
    "year3index = terms_num[terms_num.values==3].index\n",
    "year5index = terms_num[terms_num.values==5].index\n",
    "\n",
    "# Maturity Date = Term + Issued date \n",
    "maturity_date_3yr = issued_date.loc[year3index] + pd.DateOffset(years=3)\n",
    "maturity_date_5yr = issued_date.loc[year5index] + pd.DateOffset(years=5)\n",
    "\n",
    "# The matured loans are those whose maturity date is less than the most recent date, December 1st, 2018.\n",
    "matured_loan_data_3yr = loan_data_processed.loc[maturity_date_3yr[maturity_date_3yr < pd.to_datetime('2018-12-02')].index, :]\n",
    "matured_loan_data_5yr = loan_data_processed.loc[maturity_date_5yr[maturity_date_5yr < pd.to_datetime('2018-12-02')].index, :]\n",
    "\n",
    "classification_data_3yr = matured_loan_data_3yr[matured_loan_data_3yr.loan_status.isin(['Charged Off','Fully Paid'])]\n",
    "classification_data_5yr = matured_loan_data_5yr[matured_loan_data_5yr.loan_status.isin(['Charged Off','Fully Paid'])]\n",
    "\n",
    "classification_data = pd.concat((classification_data_3yr, classification_data_5yr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can safely overwrite/transform values to binary that we want for logistic regression because we have made a copy specifically\n",
    "for the classification problem. I'm going to keep the term data as separate entities in case it is necessary to investigate them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_loan_status_3yr = classification_data_3yr.loan_status.map({'Fully Paid': 0, 'Charged Off': 1, 0:0, 1:1})\n",
    "classification_data_3yr = classification_data_3yr.assign(loan_status=binary_loan_status_3yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_loan_status_5yr = classification_data_5yr.loan_status.map({'Fully Paid': 0, 'Charged Off': 1, 0:0, 1:1})\n",
    "classification_data_5yr = classification_data_5yr.assign(loan_status=binary_loan_status_5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_loan_status = classification_data.loan_status.map({'Fully Paid': 0, 'Charged Off': 1, 0:0, 1:1})\n",
    "classification_data = classification_data.assign(loan_status=binary_loan_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because a subset of the data was taken; ensure that there are no features with a single value again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 8 column(s) from DataFrame.\n"
     ]
    }
   ],
   "source": [
    "classification_data_3yr = drop_unbalanced_columns(classification_data_3yr, proportion=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 9 column(s) from DataFrame.\n"
     ]
    }
   ],
   "source": [
    "classification_data_5yr = drop_unbalanced_columns(classification_data_5yr, proportion=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 7 column(s) from DataFrame.\n"
     ]
    }
   ],
   "source": [
    "classification_data = drop_unbalanced_columns(classification_data, proportion=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are trying to predict whether or not to issue a loan, only data that is available at the time of\n",
    "that decision can be used in the creation of the predictive model. This will exclude variables which aggregate data\n",
    "from the past X months from the present date. The metadata or explanation of the variables typically indicates when the quantity involves time, so we take advantage of this by keeping anything that doesn't include terms like \"current\" or \"past X months\", etc. \n",
    "\n",
    "The list of variables included in the modeling process:\n",
    "    \n",
    "    1. Loan amount\n",
    "    2. Interest rate\n",
    "    3. Installment\n",
    "    4. Annual income\n",
    "    5. Term\n",
    "    6. Sub-grade\n",
    "    7. Length of time at current employer\n",
    "    8. Home ownership status\n",
    "    9. Verification status\n",
    "    10. Issuance date\n",
    "    11. Purpose\n",
    "    12. Zip code\n",
    "    13. State of residence\n",
    "    14. Earliest date of recorded credit line\n",
    "    15. Initial listing status\n",
    "    16. Low end of FICO score\n",
    "    \n",
    "And of course, the target variable; the outcome of the loan. Only the lower range is included because \n",
    "the upper range is identically correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fico_range_high    1.000000\n",
       "fico_range_low     1.000000\n",
       "bc_open_to_buy     0.514867\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_processed.corrwith(loan_data_processed.fico_range_high).sort_values(ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_independent =  ['loan_amnt', 'int_rate', 'installment',\n",
    "                        'annual_inc', 'grade', 'sub_grade', 'emp_length', 'home_ownership',\n",
    "                        'issue_d', 'purpose', 'zip_code', 'addr_state',\n",
    "                        'earliest_cr_line', 'initial_list_status', \n",
    "                        'loan_status','verification_status','fico_range_low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the time independent features and export to new .csv files. Commented out to not save by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classification_data_3yr_ind = classification_data_3yr[time_independent]\n",
    "classification_data_5yr_ind = classification_data_5yr[time_independent]\n",
    "classification_data_ind = classification_data[time_independent]\n",
    "# classification_data_3yr_ind.dropna(axis=0).to_csv('classification_loan_data_3yr_ind.csv',index=False)\n",
    "# classification_data_5yr_ind.dropna(axis=0).to_csv('classification_loan_data_5yr_ind.csv', index=False)\n",
    "classification_data_ind.dropna(axis=0).to_csv('classification_loan_data_ind.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data cleaning and preprocessing in capital recovery regression problem.\n",
    "\n",
    "The current formulation of this problem is to form a model which predicts the amount of money that can be recovered from charged off loans; this only requires slicing of the DataFrame such that charged off loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off_loans = loan_data_processed[loan_data_processed.loan_status=='Charged Off']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because a subset of the data was taken; ensure that there are no features with a single value again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 5 column(s) from DataFrame.\n"
     ]
    }
   ],
   "source": [
    "charged_off_loans = drop_unbalanced_columns(charged_off_loans, proportion=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_off_loans.to_csv('regression_loan_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
