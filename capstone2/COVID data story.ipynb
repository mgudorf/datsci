{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from matplotlib.patches import Rectangle\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "This notebook uses a variety of different COVID-19 related datasets to explore the behavior\n",
    "of the multiple time series'. This notebook also creates new features that attempt to encapsulate the\n",
    "time dependent (and time delayed) nature of the problem; these will be used during the model creation\n",
    "project which makes time dependent forecasting models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "## [Function definitions](#generalfunctions)\n",
    "\n",
    "## [Data](#imports)\n",
    "\n",
    "## [Exploratory Data Analysis](#EDA)\n",
    "\n",
    "## [Feature production](#newfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions <a id='generalfunctions'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rolling_values(df, features, roll_widths):\n",
    "    new_feature_df_list = []\n",
    "    for window in roll_widths:\n",
    "        # order the dataframe so date is index, backfill in the first roll_width values \n",
    "        rollmean = pd.DataFrame(df.groupby(by='location').rolling(window).mean().fillna(value=0.))\n",
    "#         rollstd = pd.DataFrame(df.groupby(by='location').rolling(window).std().fillna(value=0.))    \n",
    "#         new_features = pd.concat((rollmean, rollstd), axis=1)\n",
    "        new_features = rollmean\n",
    "        new_cols = features +'_rolling_mean_' + str(window)\n",
    "#         rsind = features +'_rolling_std_' + str(window)\n",
    "#         new_cols = rmind.append(rsind)\n",
    "        new_features.columns = new_cols\n",
    "        new_feature_df_list.append(new_features)\n",
    "    return new_feature_df_list\n",
    "\n",
    "def tsplot(data, roll_width, **kw):\n",
    "    rollmean = datatmp.rolling(roll_width).mean().fillna(method='backfill').values.ravel()\n",
    "    rollstd  = datatmp.rolling(roll_width).std().fillna(method='backfill').values.ravel()\n",
    "    cis = (rollmean - rollstd, rollmean + rollstd)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.fill_between(range(len(datatmp)), cis[0], cis[1], alpha=0.5)\n",
    "    ax.plot(range(len(datatmp)), rollmean, color='k', **kw)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>active</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>new_deaths_per_million</th>\n",
       "      <th>total_tests_per_thousand</th>\n",
       "      <th>new_tests_per_thousand</th>\n",
       "      <th>tests_units</th>\n",
       "      <th>c1_school_closing</th>\n",
       "      <th>...</th>\n",
       "      <th>penalty_missing_flag</th>\n",
       "      <th>per100k_missing_flag</th>\n",
       "      <th>testsPer100k_missing_flag</th>\n",
       "      <th>n_cases_missing_flag</th>\n",
       "      <th>new_tests_average_missing_flag</th>\n",
       "      <th>n_deaths_missing_flag</th>\n",
       "      <th>n_recovered_missing_flag</th>\n",
       "      <th>n_tests_missing_flag</th>\n",
       "      <th>days_since_missing_flag</th>\n",
       "      <th>time_index_missing_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>2020-02-24 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2020-03-04 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.052</td>\n",
       "      <td>units unclear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2020-02-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-04-03 00:00:00</td>\n",
       "      <td>901.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.292</td>\n",
       "      <td>4.523</td>\n",
       "      <td>15.227</td>\n",
       "      <td>1.178</td>\n",
       "      <td>units unclear</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-04-19 00:00:00</td>\n",
       "      <td>52598.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>51.251</td>\n",
       "      <td>2.196</td>\n",
       "      <td>20.940</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         location                 date   active  new_deaths  \\\n",
       "8497   Mauritania  2020-02-24 00:00:00      0.0         0.0   \n",
       "734       Austria  2020-03-04 00:00:00      0.0         0.0   \n",
       "13307     Tunisia  2020-02-10 00:00:00      0.0         0.0   \n",
       "4784      Estonia  2020-04-03 00:00:00    901.0         6.0   \n",
       "5470      Germany  2020-04-19 00:00:00  52598.0       184.0   \n",
       "\n",
       "       total_deaths_per_million  new_deaths_per_million  \\\n",
       "8497                      0.000                   0.000   \n",
       "734                       0.000                   0.000   \n",
       "13307                     0.000                   0.000   \n",
       "4784                      8.292                   4.523   \n",
       "5470                     51.251                   2.196   \n",
       "\n",
       "       total_tests_per_thousand  new_tests_per_thousand    tests_units  \\\n",
       "8497                      0.000                   0.000        Missing   \n",
       "734                       0.357                   0.052  units unclear   \n",
       "13307                     0.000                   0.000        Missing   \n",
       "4784                     15.227                   1.178  units unclear   \n",
       "5470                     20.940                   0.000        Missing   \n",
       "\n",
       "       c1_school_closing  ...  penalty_missing_flag  per100k_missing_flag  \\\n",
       "8497                 0.0  ...                  True                  True   \n",
       "734                  0.0  ...                 False                 False   \n",
       "13307                0.0  ...                  True                  True   \n",
       "4784                 3.0  ...                 False                 False   \n",
       "5470                 3.0  ...                 False                 False   \n",
       "\n",
       "       testsPer100k_missing_flag  n_cases_missing_flag  \\\n",
       "8497                        True                 False   \n",
       "734                        False                 False   \n",
       "13307                       True                 False   \n",
       "4784                       False                 False   \n",
       "5470                       False                 False   \n",
       "\n",
       "       new_tests_average_missing_flag  n_deaths_missing_flag  \\\n",
       "8497                             True                  False   \n",
       "734                             False                  False   \n",
       "13307                            True                  False   \n",
       "4784                            False                  False   \n",
       "5470                            False                  False   \n",
       "\n",
       "       n_recovered_missing_flag  n_tests_missing_flag  \\\n",
       "8497                      False                  True   \n",
       "734                       False                 False   \n",
       "13307                     False                  True   \n",
       "4784                      False                 False   \n",
       "5470                      False                 False   \n",
       "\n",
       "       days_since_missing_flag  time_index_missing_flag  \n",
       "8497                     False                    False  \n",
       "734                      False                    False  \n",
       "13307                    False                    False  \n",
       "4784                     False                    False  \n",
       "5470                     False                    False  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', index_col=0)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # key words account for multilevel indices\n",
    "# data = pd.read_csv('data.csv', index_col=[0,1], header=[0,1])\n",
    "# data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature production <a id='newfeatures'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function ```append_rolling_values``` is not working. Need to compute rolling averages for each\n",
    "countries time series' individually but want to store them in the multi index DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before interpolation and backfilling, I used to prune countries which did not have cases prior\n",
    "to responses (i.e. \"early responders\" were not included)\n",
    "To make my life easier, I'm only taking data which had cases before all government mandates so the rates before and after are well defined. We can think of these as being \"late responders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_columns = data.columns[data.columns.str.contains('flag')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['active', 'active_missing_flag', 'c1_flag', 'c1_flag_missing_flag',\n",
       "       'c1_school_closing', 'c1_school_closing_missing_flag', 'c2_flag',\n",
       "       'c2_flag_missing_flag', 'c2_workplace_closing',\n",
       "       'c2_workplace_closing_missing_flag', 'c3_cancel_public_events',\n",
       "       'c3_cancel_public_events_missing_flag', 'c3_flag',\n",
       "       'c3_flag_missing_flag', 'c4_flag', 'c4_flag_missing_flag',\n",
       "       'c4_restrictions_on_gatherings',\n",
       "       'c4_restrictions_on_gatherings_missing_flag',\n",
       "       'c5_close_public_transport', 'c5_close_public_transport_missing_flag',\n",
       "       'c5_flag', 'c5_flag_missing_flag', 'c6_flag', 'c6_flag_missing_flag',\n",
       "       'c6_stay_at_home_requirements',\n",
       "       'c6_stay_at_home_requirements_missing_flag', 'c7_flag',\n",
       "       'c7_flag_missing_flag', 'c7_restrictions_on_internal_movement',\n",
       "       'c7_restrictions_on_internal_movement_missing_flag',\n",
       "       'c8_international_travel_controls',\n",
       "       'c8_international_travel_controls_missing_flag',\n",
       "       'days_since_missing_flag', 'e1_flag', 'e1_flag_missing_flag',\n",
       "       'e1_income_support', 'e1_income_support_missing_flag',\n",
       "       'e2_debt_contract_relief', 'e2_debt_contract_relief_missing_flag',\n",
       "       'e3_fiscal_measures', 'e3_fiscal_measures_missing_flag',\n",
       "       'e4_international_support', 'e4_international_support_missing_flag',\n",
       "       'h1_flag', 'h1_flag_missing_flag', 'h1_public_information_campaigns',\n",
       "       'h1_public_information_campaigns_missing_flag', 'h2_testing_policy',\n",
       "       'h2_testing_policy_missing_flag', 'h3_contact_tracing',\n",
       "       'h3_contact_tracing_missing_flag',\n",
       "       'h4_emergency_investment_in_healthcare',\n",
       "       'h4_emergency_investment_in_healthcare_missing_flag',\n",
       "       'h5_investment_in_vaccines', 'h5_investment_in_vaccines_missing_flag',\n",
       "       'legacy_stringency_index', 'legacy_stringency_index_for_display',\n",
       "       'legacy_stringency_index_for_display_missing_flag',\n",
       "       'legacy_stringency_index_missing_flag', 'n_cases',\n",
       "       'n_cases_missing_flag', 'n_deaths', 'n_deaths_missing_flag',\n",
       "       'n_recovered', 'n_recovered_missing_flag', 'n_tests',\n",
       "       'n_tests_missing_flag', 'new_deaths', 'new_deaths_missing_flag',\n",
       "       'new_deaths_per_million', 'new_deaths_per_million_missing_flag',\n",
       "       'new_tests_average', 'new_tests_average_missing_flag',\n",
       "       'new_tests_per_thousand', 'new_tests_per_thousand_missing_flag',\n",
       "       'penalty', 'penalty_missing_flag', 'per100k', 'per100k_missing_flag',\n",
       "       'stringency_index', 'stringency_index_for_display',\n",
       "       'stringency_index_for_display_missing_flag',\n",
       "       'stringency_index_missing_flag', 'testsPer100k',\n",
       "       'testsPer100k_missing_flag', 'tests_units_missing_flag',\n",
       "       'time_index_missing_flag', 'total_deaths_per_million',\n",
       "       'total_deaths_per_million_missing_flag', 'total_tests_per_thousand',\n",
       "       'total_tests_per_thousand_missing_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = data.iloc[:,2:].columns.difference(flag_columns.tolist() + ['tests_units', 'time_index', 'days_since','population'])\n",
    "features = data.columns.difference(['date','location','tests_units', 'time_index', 'days_since','population'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_groupby = features.tolist() + ['location']\n",
    "roll_widths = [2, 3, 5, 7, 14]\n",
    "datatmp = data.loc[:, features_groupby]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_df_list = append_rolling_values(datatmp, features, roll_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_features = pd.concat((data, pd.concat(new_feature_df_list, axis=1).reset_index(drop=True)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_features.to_csv('modeling_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>active</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>new_deaths_per_million</th>\n",
       "      <th>total_tests_per_thousand</th>\n",
       "      <th>new_tests_per_thousand</th>\n",
       "      <th>tests_units</th>\n",
       "      <th>c1_school_closing</th>\n",
       "      <th>...</th>\n",
       "      <th>stringency_index_for_display_missing_flag_rolling_mean_14</th>\n",
       "      <th>stringency_index_missing_flag_rolling_mean_14</th>\n",
       "      <th>testsPer100k_rolling_mean_14</th>\n",
       "      <th>testsPer100k_missing_flag_rolling_mean_14</th>\n",
       "      <th>tests_units_missing_flag_rolling_mean_14</th>\n",
       "      <th>time_index_missing_flag_rolling_mean_14</th>\n",
       "      <th>total_deaths_per_million_rolling_mean_14</th>\n",
       "      <th>total_deaths_per_million_missing_flag_rolling_mean_14</th>\n",
       "      <th>total_tests_per_thousand_rolling_mean_14</th>\n",
       "      <th>total_tests_per_thousand_missing_flag_rolling_mean_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2019-12-31 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-04 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-08 00:00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>55.507143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-09 00:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>57.057143</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-10 00:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>58.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-11 00:00:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>59.842857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>61.235714</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15008 rows × 551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          location                 date  active  new_deaths  \\\n",
       "0      Afghanistan  2019-12-31 00:00:00     0.0         0.0   \n",
       "1      Afghanistan  2020-01-01 00:00:00     0.0         0.0   \n",
       "2      Afghanistan  2020-01-02 00:00:00     0.0         0.0   \n",
       "3      Afghanistan  2020-01-03 00:00:00     0.0         0.0   \n",
       "4      Afghanistan  2020-01-04 00:00:00     0.0         0.0   \n",
       "...            ...                  ...     ...         ...   \n",
       "15003     Zimbabwe  2020-05-08 00:00:00    25.0         0.0   \n",
       "15004     Zimbabwe  2020-05-09 00:00:00    21.0         0.0   \n",
       "15005     Zimbabwe  2020-05-10 00:00:00    22.0         0.0   \n",
       "15006     Zimbabwe  2020-05-11 00:00:00    23.0         0.0   \n",
       "15007     Zimbabwe  2020-05-12 00:00:00    23.0         0.0   \n",
       "\n",
       "       total_deaths_per_million  new_deaths_per_million  \\\n",
       "0                         0.000                     0.0   \n",
       "1                         0.000                     0.0   \n",
       "2                         0.000                     0.0   \n",
       "3                         0.000                     0.0   \n",
       "4                         0.000                     0.0   \n",
       "...                         ...                     ...   \n",
       "15003                     0.202                     0.0   \n",
       "15004                     0.202                     0.0   \n",
       "15005                     0.202                     0.0   \n",
       "15006                     0.202                     0.0   \n",
       "15007                     0.202                     0.0   \n",
       "\n",
       "       total_tests_per_thousand  new_tests_per_thousand tests_units  \\\n",
       "0                           0.0                     0.0     Missing   \n",
       "1                           0.0                     0.0     Missing   \n",
       "2                           0.0                     0.0     Missing   \n",
       "3                           0.0                     0.0     Missing   \n",
       "4                           0.0                     0.0     Missing   \n",
       "...                         ...                     ...         ...   \n",
       "15003                       0.0                     0.0     Missing   \n",
       "15004                       0.0                     0.0     Missing   \n",
       "15005                       0.0                     0.0     Missing   \n",
       "15006                       0.0                     0.0     Missing   \n",
       "15007                       0.0                     0.0     Missing   \n",
       "\n",
       "       c1_school_closing  ...  \\\n",
       "0                    0.0  ...   \n",
       "1                    0.0  ...   \n",
       "2                    0.0  ...   \n",
       "3                    0.0  ...   \n",
       "4                    0.0  ...   \n",
       "...                  ...  ...   \n",
       "15003                3.0  ...   \n",
       "15004                3.0  ...   \n",
       "15005                3.0  ...   \n",
       "15006                3.0  ...   \n",
       "15007                3.0  ...   \n",
       "\n",
       "       stringency_index_for_display_missing_flag_rolling_mean_14  \\\n",
       "0                                               0.000000           \n",
       "1                                               0.000000           \n",
       "2                                               0.000000           \n",
       "3                                               0.000000           \n",
       "4                                               0.000000           \n",
       "...                                                  ...           \n",
       "15003                                           0.000000           \n",
       "15004                                           0.000000           \n",
       "15005                                           0.000000           \n",
       "15006                                           0.071429           \n",
       "15007                                           0.142857           \n",
       "\n",
       "       stringency_index_missing_flag_rolling_mean_14  \\\n",
       "0                                           0.000000   \n",
       "1                                           0.000000   \n",
       "2                                           0.000000   \n",
       "3                                           0.000000   \n",
       "4                                           0.000000   \n",
       "...                                              ...   \n",
       "15003                                       0.285714   \n",
       "15004                                       0.357143   \n",
       "15005                                       0.428571   \n",
       "15006                                       0.500000   \n",
       "15007                                       0.571429   \n",
       "\n",
       "       testsPer100k_rolling_mean_14  \\\n",
       "0                          0.000000   \n",
       "1                          0.000000   \n",
       "2                          0.000000   \n",
       "3                          0.000000   \n",
       "4                          0.000000   \n",
       "...                             ...   \n",
       "15003                     55.507143   \n",
       "15004                     57.057143   \n",
       "15005                     58.450000   \n",
       "15006                     59.842857   \n",
       "15007                     61.235714   \n",
       "\n",
       "       testsPer100k_missing_flag_rolling_mean_14  \\\n",
       "0                                       0.000000   \n",
       "1                                       0.000000   \n",
       "2                                       0.000000   \n",
       "3                                       0.000000   \n",
       "4                                       0.000000   \n",
       "...                                          ...   \n",
       "15003                                   0.357143   \n",
       "15004                                   0.428571   \n",
       "15005                                   0.500000   \n",
       "15006                                   0.571429   \n",
       "15007                                   0.642857   \n",
       "\n",
       "       tests_units_missing_flag_rolling_mean_14  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "...                                         ...   \n",
       "15003                                       0.0   \n",
       "15004                                       0.0   \n",
       "15005                                       0.0   \n",
       "15006                                       0.0   \n",
       "15007                                       0.0   \n",
       "\n",
       "       time_index_missing_flag_rolling_mean_14  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "...                                        ...   \n",
       "15003                                      0.0   \n",
       "15004                                      0.0   \n",
       "15005                                      0.0   \n",
       "15006                                      0.0   \n",
       "15007                                      0.0   \n",
       "\n",
       "       total_deaths_per_million_rolling_mean_14  \\\n",
       "0                                         0.000   \n",
       "1                                         0.000   \n",
       "2                                         0.000   \n",
       "3                                         0.000   \n",
       "4                                         0.000   \n",
       "...                                         ...   \n",
       "15003                                     0.202   \n",
       "15004                                     0.202   \n",
       "15005                                     0.202   \n",
       "15006                                     0.202   \n",
       "15007                                     0.202   \n",
       "\n",
       "       total_deaths_per_million_missing_flag_rolling_mean_14  \\\n",
       "0                                                    0.0       \n",
       "1                                                    0.0       \n",
       "2                                                    0.0       \n",
       "3                                                    0.0       \n",
       "4                                                    0.0       \n",
       "...                                                  ...       \n",
       "15003                                                1.0       \n",
       "15004                                                1.0       \n",
       "15005                                                1.0       \n",
       "15006                                                1.0       \n",
       "15007                                                1.0       \n",
       "\n",
       "       total_tests_per_thousand_rolling_mean_14  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "...                                         ...   \n",
       "15003                                       0.0   \n",
       "15004                                       0.0   \n",
       "15005                                       0.0   \n",
       "15006                                       0.0   \n",
       "15007                                       0.0   \n",
       "\n",
       "       total_tests_per_thousand_missing_flag_rolling_mean_14  \n",
       "0                                                    0.0      \n",
       "1                                                    0.0      \n",
       "2                                                    0.0      \n",
       "3                                                    0.0      \n",
       "4                                                    0.0      \n",
       "...                                                  ...      \n",
       "15003                                                1.0      \n",
       "15004                                                1.0      \n",
       "15005                                                1.0      \n",
       "15006                                                1.0      \n",
       "15007                                                1.0      \n",
       "\n",
       "[15008 rows x 551 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis<a id='EDA'></a>\n",
    "Ideas for the inclusion or creation of new columns.\n",
    "\n",
    "Moving averages\n",
    "fourier\n",
    "signal\n",
    "flags for lots of different things\n",
    "\n",
    "hardest hit countries\n",
    "\n",
    "days since\n",
    "\n",
    "extrapolated, actual, interpolated\n",
    "\n",
    "which dataset it came from\n",
    "\n",
    "humans view, interpret and forecast things in a way which are not available to robots. \n",
    "data driven, time dependent manner of modeling. Really trying to encapsulate the time dependence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_rolling_values(data, features, roll_widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA COVID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_response_dates = start_end_df.min(axis=1).sort_index()\n",
    "first_response_dates.head(10)\n",
    "\n",
    "first_case_dates = test_multiindex_df.reset_index(level=1).groupby(level=0).Date.min().sort_index()\n",
    "first_case_dates.head(10)\n",
    "\n",
    "dates_with_test_data = test_multiindex_df.tests_cumulative.dropna()\n",
    "dates_with_test_data.head()\n",
    "\n",
    "min_testing_dates = test_multiindex_df.tests_cumulative.dropna().reset_index(level=1).groupby(level=0).Date.min()\n",
    "\n",
    "first_testing_dates = test_multiindex_df.tests_cumulative.dropna().reset_index(level=1).groupby(level=0).Date.min()\n",
    "last_testing_dates = test_multiindex_df.tests_cumulative.dropna().reset_index(level=1).groupby(level=0).Date.max()\n",
    "\n",
    "first_testing_dates.reset_index()\n",
    "\n",
    "# convert entire dataframe to index so it can be used to slice testing data, dataframe\n",
    "first_tmp =  first_testing_dates.reset_index().set_index(['Country','Date'])\n",
    "last_tmp =  last_testing_dates.reset_index().set_index(['Country','Date'])\n",
    "first_tmp.head()\n",
    "\n",
    "test_min = test_multiindex_df.loc[first_tmp.index, :]\n",
    "test_max = test_multiindex_df.loc[last_tmp.index, :]\n",
    "\n",
    "# reset index so we can subtract datetime variables.\n",
    "test_max_reset = test_max.reset_index(level=1)\n",
    "test_min_reset = test_min.reset_index(level=1)\n",
    "time_differential = (test_max_reset.Date - test_min_reset.Date).dt.days\n",
    "testing_rates = np.log(test_max_reset.tests_cumulative / test_min_reset.tests_cumulative)# / time_intervals\n",
    "\n",
    "\n",
    "test_final_test_initial_time_intervals = (test_max_reset.Date - test_min_reset.Date).dt.days\n",
    "\n",
    "case_response_differential = (first_case_dates-first_response_dates).dt.days\n",
    "\n",
    "late_response = case_response_differential < 0\n",
    "late_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_to_inspect = ['Michigan', 'Georgia', 'New York', 'Texas']\n",
    "\n",
    "dead=us_deaths[us_deaths['Province_State'].isin(states_to_inspect)].groupby(by='Province_State').sum()\n",
    "confirmed=us_cases[us_cases['Province_State'].isin(states_to_inspect)].groupby(by='Province_State').sum()\n",
    "confirmed.head()\n",
    "\n",
    "\n",
    "since_first_case_normalized_u = u.replace(to_replace=[0,0.], value=np.nan)\n",
    "since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:].values\n",
    "since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:] / since_first_case_normalized_u.loc[(states_to_inspect,'Dead'), :].iloc[:,6:]\n",
    "since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:].apply(np.log10).transpose().plot()\n",
    "time_series_df = since_first_case_normalized_u#.iloc[:, 6:]\n",
    "death_rate_df = since_first_case_normalized_u.loc[(states_to_inspect,'Dead'), :].iloc[:,6:].copy()\n",
    "death_rate_normalized = 100 * since_first_case_normalized_u.loc[(states_to_inspect,'Dead'), :].iloc[:,6:].values / since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:].values\n",
    "death_rate_df.loc[:, :] = death_rate_normalized\n",
    "\n",
    "\n",
    "since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:].values\n",
    "\n",
    "since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:] / since_first_case_normalized_u.loc[(states_to_inspect,'Dead'), :].iloc[:,6:]\n",
    "\n",
    "since_first_case_normalized_u.loc[(states_to_inspect,'Confirmed'), :].iloc[:,6:].apply(np.log10).transpose().plot()\n",
    "\n",
    "time_series_df = since_first_case_normalized_u#.iloc[:, 6:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_case_dates.astype('category').cat.codes.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(new_feature_df_list,ignore_index=False).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10), dpi=200)\n",
    "death_rate_df.transpose().plot().legend(bbox_to_anchor=(1, 1))\n",
    "_ = plt.xlabel('Date')\n",
    "_ = plt.ylabel('Death Rate (%)')\n",
    "plt.grid(True, axis='both')\n",
    "plt.title('Death rate by state')\n",
    "plt.savefig('death_rate_NY_MI_GA.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax,ax2) = plt.subplots(1, 2, sharey=True,  figsize=(20,5), dpi=200)\n",
    "confirmed.loc[:, '2/21/20':].transpose().plot(ax=ax).legend(bbox_to_anchor=(0.2, 1))\n",
    "dead.loc[:, '2/21/20':].transpose().plot(ax=ax2).legend(bbox_to_anchor=(0.2, 1))\n",
    "ax.set_yscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax.set_title('Number of confirmed cases vs. time')\n",
    "ax2.set_title('Number of diseased vs. time')\n",
    "ax.grid(True, axis='both')\n",
    "ax2.grid(True, axis='both')\n",
    "plt.savefig('cases_vs_dead_comparison_GA_NY_MI.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_counties(state_df, state_name):\n",
    "    state = state_df[(state_df.Province_State==state_name)]\n",
    "    state = state.drop(columns=['UID','iso2','iso3','code3','FIPS','Country_Region','Lat','Long_','Combined_Key','Province_State'])\n",
    "    top5_counties = state.groupby(by='Admin2').sum().sum(axis=1).sort_values(ascending=False)[:5].index.tolist()\n",
    "    state_info = state[state.Admin2.isin(top5_counties)].set_index('Admin2').transpose()\n",
    "    state_info.columns.name = 'County'\n",
    "    return state_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global COVID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_recovered_dates_only = global_recovered.set_index('Country/Region').loc[:, '1/22/20':].groupby(level=0).sum()\n",
    "global_confirmed_dates_only = global_confirmed.set_index('Country/Region').loc[:, '1/22/20':].groupby(level=0).sum()\n",
    "global_dead_dates_only = global_dead.set_index('Country/Region').loc[:, '1/22/20':].groupby(level=0).sum()\n",
    "\n",
    "global_dead['type']='Dead'\n",
    "global_confirmed['type']='Confirmed'\n",
    "global_recovered['type']='Recovered'\n",
    "\n",
    "dead=global_dead[global_dead['Country/Region'].isin(['Germany', 'Italy', 'US'])].set_index('Country/Region').loc[:,'1/22/20':]#.iloc[:, 4:].transpose().columns\n",
    "confirmed=global_confirmed[global_confirmed['Country/Region'].isin(['Germany', 'Italy', 'US'])].set_index('Country/Region').loc[:,'1/22/20':]#.iloc[:, 4:].transpose().columns\n",
    "\n",
    "global_dead = global_dead.sort_index(axis=1)\n",
    "global_confirmed = global_confirmed.sort_index(axis=1)\n",
    "global_recovered = global_recovered.sort_index(axis=1)\n",
    "\n",
    "skr = global_confirmed.groupby('Country/Region').sum().iloc[143, :].loc['1/22/20':'4/28/20']\n",
    "skr.head()\n",
    "\n",
    "top10 = global_confirmed.groupby('Country/Region').sum().loc[:, '1/22/20':'4/28/20'].sort_values(by='4/28/20').iloc[-10:, :]\n",
    "skr = global_confirmed.groupby('Country/Region').sum().loc['Korea, South', '1/22/20':'4/28/20']\n",
    "\n",
    "top10_and_south_korea = pd.concat((top10, skr.to_frame(name='South Korea').transpose()),axis=0).sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for i, country_time_series in enumerate(top10_and_south_korea.replace(to_replace=[0,0.], value=np.nan).values):\n",
    "    nan_count = np.sum(np.isnan(country_time_series))\n",
    "    days_since_first = np.roll(country_time_series, -nan_count)\n",
    "    plt.plot(days_since_first, label=top10_and_south_korea.index[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "global_dead_dates_only\n",
    "\n",
    "dsum = global_dead_dates_only.sum()\n",
    "csum = global_confirmed_dates_only.sum()\n",
    "drsum = 100*dsum/csum\n",
    "drsum.plot()\n",
    "_ = plt.xlabel('Date')\n",
    "_ = plt.ylabel('Death Rate (%)')\n",
    "_ = plt.title('Average global death rate vs. time')\n",
    "plt.grid(True, axis='both')\n",
    "plt.savefig('death_rate_global.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_case_dates = case_df.reset_index().set_index(['Country','date']).total_cases.replace(\n",
    "                           to_replace=0,value=np.nan).dropna().reset_index(level=1).groupby(level=0).date.min()\n",
    "\n",
    "first_response_dates = response_df.min(axis=1)\n",
    "tmp = response_df.copy()\n",
    "dt = pd.DataFrame(np.tile(first_case_dates.values.reshape(-1,1),(1, response_df.shape[1])))\n",
    "diff_df = tmp - np.tile(first_case_dates.values.reshape(-1,1),(1, response_df.shape[1]))\n",
    "num_miss=diff_df.where(diff_df > pd.Timedelta(days=0)).isna().sum(1).sort_values(ascending=False)\n",
    "countries_with_cases_before_responses = num_miss.where(num_miss==0).dropna().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using the endpoints of each interval is not going to work as well, because if the endpoints represent outliers then they\n",
    "will not capture the overall trend. Therefore, I will do the following: average the two intervals before and after the quarantine measure (average the cases/((1M people)(100k tests)) and then compare the averages with the value at the quarantine date. I believe this is fair because it's being applied equally to both intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "country_list = []\n",
    "slice_list = []\n",
    "\n",
    "for j, (country, country_df) in enumerate(all_responses.groupby(level=0)):\n",
    "    active_dates = country_df.replace(to_replace=0., value=np.nan)\n",
    "    country_list += [country]\n",
    "    before_list = []\n",
    "    after_list = []\n",
    "    for i, single_response in enumerate(active_dates.columns):\n",
    "        effective_range = active_dates[single_response].dropna(axis=0)\n",
    "        before = effective_range.reset_index().Date.min()\n",
    "#         after = effective_range.reset_index().Date.max()\n",
    "        slice_list += [before]   \n",
    "        \n",
    "enacted_ended_df = pd.DataFrame(np.array(slice_list).reshape(len(country_list), -1), index=country_list, columns=all_responses.columns)\n",
    "\n",
    "all_responses = response_df.iloc[:, [0, 1, 2, 3, 5, 6]]\n",
    "country_list = []\n",
    "minmax_list = []\n",
    "for j, (country, country_df) in enumerate(all_responses.groupby(level=0)):\n",
    "    active_dates = country_df.replace(to_replace=0., value=np.nan)\n",
    "    country_list += [country]\n",
    "    for i, single_response in enumerate(active_dates.columns):\n",
    "        effective_range = active_dates[single_response].dropna(axis=0)\n",
    "        before = effective_range.reset_index().Date.min()\n",
    "        after = effective_range.reset_index().Date.max()\n",
    "        minmax_list += [before, after]   \n",
    "\n",
    "start_end_columns = np.array([[x+'_start', x+'_end'] for x in all_responses.columns.tolist()]).ravel()\n",
    "start_end_df = pd.DataFrame(np.array(minmax_list).reshape(len(country_list), -1), index=country_list, columns=start_end_columns)\n",
    "start_end_filtered_df = start_end_df.drop(columns=['Close_public_transport_start','Close_public_transport_end']).dropna(axis=0)\n",
    "filtered_countries = start_end_filtered_df.index\n",
    "enacted_ended_filtered_df = enacted_ended_df.drop(columns=['Close_public_transport']).loc[filtered_countries, :]\n",
    "start_end_filtered_df = start_end_df.drop(columns=['Close_public_transport_start','Close_public_transport_end']).dropna(axis=0)\n",
    "filtered_countries = start_end_filtered_df.index\n",
    "enacted_ended_filtered_df = enacted_ended_df.drop(columns=['Close_public_transport']).loc[filtered_countries, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = case_multiindex_df.join(test_multiindex_df, lsuffix='_x', rsuffix='_y').sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that total cases is a cumulative variable, replace zeros with np.nan and then backwards interpolate\n",
    "Growth rate calculations require values greater than zero, so remove all dates where there are zero confirmed cases, per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the time series, fill in with missing values with nan. \n",
    "data = data.reindex(pd.MultiIndex.from_product([data.index.levels[0], \n",
    "                    data.index.get_level_values(1).unique().sort_values()], names=['Country', 'Date']), fill_value=np.nan)\n",
    "\n",
    "# Don't use zeros this messes things up.\n",
    "data.loc[:, 'total_cases'] = data.loc[:, 'total_cases'].replace(to_replace=[0,0.], value=np.nan)\n",
    "# instantiate with copy so that we can iterate over DataFrame groupby\n",
    "data.loc[:, 'total_cases_interpolated'] = data.loc[:, 'total_cases'].copy()\n",
    "data.loc[:, 'tests_cumulative_interpolated'] = data.loc[:, 'tests_cumulative'].copy()\n",
    "\n",
    "for country, country_df in data.groupby(level=0):\n",
    "    data.loc[country, 'total_cases_interpolated'] = country_df.loc[:, 'total_cases'].interpolate(limit_direction='backward').values\n",
    "    data.loc[country, 'tests_cumulative_interpolated'] = country_df.loc[:, 'tests_cumulative'].interpolate(limit_direction='backward').values\n",
    "    data.loc[country, 'population'] = country_df.loc[:, 'population'].fillna(method='backfill')\n",
    "\n",
    "data.loc[:, 'cases_per_1M_people_per_100k_tests'] = (data.total_cases_interpolated / ((data.population/1000000.) * (data.tests_cumulative_interpolated))).values\n",
    "data.loc[:, 'cases_per_1M_people'] = (data.total_cases_interpolated / ((data.population/1000000.))).values\n",
    "\n",
    "\n",
    "data.loc[:, 'cumulative_normalized_case_test_ratio'] = (data.total_cases_interpolated / ((data.population/1000000.) * (data.tests_cumulative_interpolated))).cumsum().apply(np.log)\n",
    "\n",
    "before_minus_after = response_multiindex_df.applymap(multiindex_response_date_to_average_rates).replace(to_replace=0., value=np.nan).sort_index()\n",
    "\n",
    "before_minus_after_residual_values =  before_minus_after.values - np.tile(before_minus_after.mean(1).values.reshape(-1,1), (1, 5))\n",
    "before_minus_after_residual_df = pd.DataFrame(before_minus_after_residual_values.reshape(-1, 5), columns=before_minus_after.columns, index=before_minus_after.index)\n",
    "before_minus_after_residual_df.head()\n",
    "\n",
    "data.loc[:, 'cumulative_normalized_case_test_ratio'] = (data.total_cases_interpolated / data.tests_cumulative_interpolated).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
