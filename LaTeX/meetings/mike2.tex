\subsection{Mike Badescu(2) Wednesday, September 11th 2019}

Second mentor meeting. Haven't done much other than
acquire stock market dataset.

Stock market data set
Idea of ticker name vs. trading popularity.
Trends in dirty data? (multiple data sets, dirty is hard).
Watched video and read
Fuzzy matching, how do you account for the most
common errors. Tools that already deal with this.
Not the code logic but the business logic that matters.
Would need to validate against something. Outside of
the automated process which is not aware of the context
the problem. Cleaning is not the difficult part but
understanding the context. Standard tricks, computing
averages and mode and edit distance between values.
Edit distribution between values of ``Mike''
Stock ideas for ticker names, project for hedgefunds
there is some sort of alphabet effect.

Human nature there are focal points, because of these
focal points there are extra criteria. There are human psychology
layers on top of the data. Full month vs arbitrary thirty.
Granger causality. Can figure out Granger causality
need A to happen before B. Granger causality is a time
delay effect. In order to frame the problem. Try to
predict the probability of a recession. A blog
that Mike Badescu.

The godfather of Time series, Hamilton something something. Freight shipping, bond yields.
Bond yields as a function of curvature.
Treat it as a machine learning problem as opposed to a time
series problem. Don't contaminate the timeline. Can use crazy
things to predict. Employment is a lagging indicator.
Definition of recession plays a part as well.
Try to play with this if you're trying to predict something.
Get people to talk about this, in vogue right now.

Seems like what he's saying is to have a very
precisely defined goal.
If you pay attention to certain variables as opposed
to others. A lot of machine learning is about automation.
Whenever there is a pattern in terms of what the humans are
doing, automate it. If you do not know too much
The most difficult part in fact is feature engineering;
new ways of looking at the data. If you have $x,y$
transform to polar coordinates. Teasing out nonlinear
effects. ``Knowing'' that something exists is equivalent
to transforming the
auto-ML is automatic machine learning. Put some standard
transformations on it and run it through some algorithms to
see what is the best algorithm. (Does this include the parameters
of the algorithm?). Don't mind extra columns, minimize the error
using
Simple regularization technique does wonders; optimization
by adding in penalties
Can't guide you, find someone with PhD. in Computer Science.
Time dependent auto-ML.
Constantly scraping data; sales everyday. Cannot use previously
trained model to
What you do is use a moving window (moving average) and retrain
everyday.
There is no free lunch; What happens when data changes, or trends
change?
For image recognition you go deep learning and not
try anything else. Image recognition and speech recognition
pick up on redundancies, but perhaps there is. AI is fancy
a fancy term for if statements.
Neural networks started in the 1960s and many people were disappointed.
The risk of business is that you cannot guarantee the result.
If you believe that time is tight then contact student support
about freezing.

Setup a narrative and write down some research questions.
What exactly are we looking for?
Don't go for unsupervised learning. For clustering.
Should point to columns
of the data, can combine data to create new metrics.
Try to predict something. Back testing; should I predict
something that I can actually see if it works? Window
a year and then try to predict a month ahead, like weather prediction.
Be careful with this because pattern you think you observe is because
you used past data to predict the future. People find some patterns
and then  implement algorithms

Stock market is harder because it's a feedback loop.
Learn the mechanics in the first project. Does not have to be versus
time. Have to be careful not to contaminate.

Cross validation; have a dataset, want to measure the error; do the training
on part of the data set (wasting). Split data set into five parts, cross
validation by training on four parts and predict on the fifth. Finding
five complementary sets. Cross validation.

If you partition with respect to time then this is not straightforward
because the predictions always have to be in the future. 