{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import requests\n",
    "from matplotlib.patches import Rectangle\n",
    "from datetime import datetime\n",
    "# sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "This notebook cleans and wrangles numerous data sets, making them uniform\n",
    "so that they can be used in a data-driven model for COVID-19 prediction.\n",
    "\n",
    "The key cleaning measures are those which find the most viable set of countries and date ranges\n",
    "such that the maximal amount of data can be used. In other words, different datasets can have data\n",
    "on a different set of countries; to avoid introducing large quantities of missing values\n",
    "the intersection of these countries is taken. For the date ranges, depending on the quantity,\n",
    "extrapolation/interpolation is used to ensure that each time series is defined to be non-zero\n",
    "on all dates. This process is kept track of by encoding the dates which have interpolated values.\n",
    "There are two measures to do so. Essentially its one hot encoding for the categories ['extrapolated', 'interpolated', 'actual']. The other measure is to track the \"days since infection\" where 0 represents the first day with a recorded\n",
    "case of COVID within that country. I leave the more complex feature creation to the exploratory data analysis portion\n",
    "of this project.\n",
    "\n",
    "Some of the data is currently not used but may be incorporated later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents<a id='toc'></a>\n",
    "\n",
    "## [Data wrangling function definitions](#generalfunctions)\n",
    "\n",
    "# Data <a id='data'></a>\n",
    "\n",
    "<!-- ## [The COVID tracking project testing data.](#source1)\n",
    "[https://covidtracking.com/api](https://covidtracking.com/api)\n",
    "            -->\n",
    "## [JHU CSSE case data.](#csse)\n",
    "[https://systems.jhu.edu/research/public-health/ncov/](https://systems.jhu.edu/research/public-health/ncov/)\n",
    "[https://github.com/CSSEGISandData/COVID-19](https://github.com/CSSEGISandData/COVID-19)\n",
    "\n",
    "This data is split between a collection of .csv files of two different formats; first, the daily reports (global) are\n",
    "separated by day, each residing in their own .csv. Additionally, the daily report files have three different formats that need to be taken into account when compiling the data. The daily report data itself contains values on the number of confirmed cases, deceased, active cases, recovered cases.\n",
    "\n",
    "For the other format, .csv files with 'timeseries' in their filename, the data contains values for confirmed, deceased, recovered and are split between global numbers (contains United States as a whole) and numbers for the united states (statewide).\n",
    "           \n",
    "## [IHME hospital data](#ihme)\n",
    "[http://www.healthdata.org/covid/data-downloads](http://www.healthdata.org/covid/data-downloads)\n",
    "\n",
    "The IHME hospital data is one of the more unique datasets I've discovered with \n",
    "           \n",
    "## [OWID case and test data](#owid)\n",
    "[https://github.com/owid/covid-19-data](https://github.com/owid/covid-19-data)\n",
    "[https://ourworldindata.org/covid-testing](https://ourworldindata.org/covid-testing)\n",
    "\n",
    "The OWID dataset contains information regarding case and test numbers; it overlaps with the JHU CSSE \n",
    "and Testing Tracker datasets but I am going to attempt to use it in conjunction with those two because\n",
    "of how there is unreliable reporting. In other words to get the bigger picture I'm looking to stitch together\n",
    "multiple datasets.\n",
    "           \n",
    "## [OxCGRT government response data](#oxcgrt)\n",
    "[https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv](https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv)\n",
    "[https://covidtracker.bsg.ox.ac.uk/about-api](https://covidtracker.bsg.ox.ac.uk/about-api)\n",
    "\n",
    "The OxCGRT dataset contains information regarding different government responses in regards to social\n",
    "distancing measures. It measures the type of social distancing measure, whether or not they are recommended\n",
    "or mandated, whether they are targeted or broad (I think geographically). \n",
    "           \n",
    "## [Testing tracker data](#testtrack)\n",
    "[https://www.statista.com/statistics/1109066/coronavirus-testing-in-europe-by-country/](https://www.statista.com/statistics/1109066/coronavirus-testing-in-europe-by-country/)\n",
    "[https://finddx.shinyapps.io/FIND_Cov_19_Tracker/](https://finddx.shinyapps.io/FIND_Cov_19_Tracker/)\n",
    "\n",
    "This dataset contains a time series of testing information: e.g. new (daily) tests, cumulative tests, etc. \n",
    "\n",
    "## [Delphi-epidata (currently not used)**](#delphi) which contains \n",
    "       Facebook surveys, google surveys, doctor visits, google health trends, quidel test data\n",
    "[https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html)\n",
    "\n",
    "I have not dove into this dataset too thoroughly but it contains information from facebook and google\n",
    "surveys regarding COVID as well as doctor visits; the doctor visit data attempts to make distinctions between\n",
    "those sick with the annual influenza and those with COVID.\n",
    "\n",
    "\n",
    "# [Data regularization: making things uniform](#uniformity)\n",
    "\n",
    "### [Intersection of countries](#country)\n",
    "  \n",
    "### [Time series date ranges](#time)\n",
    "\n",
    "### [Missing Values](#missingval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling function declaration <a id='generalfunctions'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- Helper Functions for cleaning ----------------------#\n",
    "\n",
    "\n",
    "def column_or_index_string_reformat(df, columns=True, index=False, dt_formats=('%m/%d/%y', '%Y-%m-%d')):\n",
    "    \"\"\" Reformat column and index names. \n",
    "    \n",
    "    Parameters :\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "    columns : bool\n",
    "    index : bool\n",
    "    \n",
    "    Notes :\n",
    "    -----\n",
    "    Change headers of columns; this needs to be updated to account for their formatting changes. \n",
    "    This function converts strings with CamelCase, underscore and space separators to lowercase words uniformly\n",
    "    separated with underscores. I.e. (hopefully!) following the correct python identifier syntax so that each column\n",
    "    can be reference as an attribute if desired. \n",
    "\n",
    "    For more on valid Python identifiers, see:\n",
    "    https://docs.python.org/3/reference/lexical_analysis.html#identifiers\n",
    "    \"\"\"\n",
    "    if columns:\n",
    "        reformatted_column_names = []\n",
    "        for c in df.columns:\n",
    "            # handle labels which can be cast to datetime objects\n",
    "            try:\n",
    "                reformatted_column_names.append(datetime.strftime(\n",
    "                    datetime.strptime(c, dt_formats[0]), format=dt_formats[1]))\n",
    "            except ValueError:\n",
    "                reformatted_column_names.append('_'.join(re.sub('([A-Z][a-z]+)', r' \\1', \n",
    "                                                         re.sub('([A-Z]+)|_|\\/', r' \\1', c)\n",
    "                                                                .lower()).split()))\n",
    "        df.columns = reformatted_column_names        \n",
    "        \n",
    "    if index:\n",
    "        # only use only multi index dataframes where level=0 is country and level=1 is date. \n",
    "        \n",
    "        \n",
    "        reformatted_country_names = []\n",
    "        for c in df.index.get_level_values(0):\n",
    "            reformatted_country_names.append(' '.join(re.sub('([A-Z][a-z]+)', r' \\1', \n",
    "                                                        re.sub('([A-Z]+)|_|\\/', r' \\1', c).lower())\n",
    "                                                        .split()).title())\n",
    "        \n",
    "        reformatted_dates = pd.to_datetime(df.index.get_level_values(1)).normalize()\n",
    "        restored_columns = df.index.names\n",
    "        df = df.reset_index()\n",
    "        df.loc[:, restored_columns[0]] = reformatted_country_names\n",
    "        df.loc[:, restored_columns[1]] = reformatted_dates\n",
    "        df = df.set_index(restored_columns).sort_index()\n",
    "        \n",
    "#     if index:\n",
    "#         # only use only multi index dataframes where level=0 is country and level=1 is date. \n",
    "#         reformatted_index_names = []\n",
    "#         for c in df.index.get_level_values(0):\n",
    "#             # handle labels which can be cast to datetime objects\n",
    "#             try:\n",
    "#                 reformatted_index_names.append(datetime.strftime(\n",
    "#                     datetime.strptime(c, dt_formats[0]), format=dt_formats[1]))\n",
    "#             except ValueError:\n",
    "#                 reformatted_index_names.append(' '.join(re.sub('([A-Z][a-z]+)', r' \\1', \n",
    "#                                                         re.sub('([A-Z]+)|_|\\/', r' \\1', c).lower())\n",
    "#                                                         .split()).title())\n",
    "#         restored_column = df.index.names[0]\n",
    "#         df = df.reset_index(level=0)\n",
    "#         df.loc[:, restored_column] = reformatted_index_names\n",
    "#         df = df.set_index([restored_column, df.index]).sort_index()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def csse_daily_reports_reformat():\n",
    "    \"\"\" Import and concatenate all JHU CSSE daily report data from local machine. \n",
    "    \"\"\"\n",
    "    csv_different_formats_list = []\n",
    "    \n",
    "    # the actual format difference is being covered up by pd.concat which fills with Nans\n",
    "    for x in glob.glob('CSSEGIS_git_case_data/csse_covid_19_data/csse_covid_19_daily_reports/*'):\n",
    "        if os.path.isdir(x):\n",
    "            df_list = []\n",
    "            for days in glob.glob(x+'/*'):\n",
    "                df = pd.read_csv(days)\n",
    "                df_list.append(df)\n",
    "            csv_different_formats_list.append(column_or_index_string_reformat(pd.concat(df_list, axis=0).reset_index(drop=True)))\n",
    "    \n",
    "    # concatenate the data\n",
    "    daily_reports_df = pd.concat(csv_different_formats_list).reset_index(drop=True)\n",
    "    # convert the date-like variable to datetime\n",
    "    daily_reports_df.loc[:, 'last_update'] = pd.to_datetime(daily_reports_df.last_update).dt.normalize()\n",
    "    # In the reporting there are duplicate values. Also, I'm aggregating by country because the other datasets\n",
    "    # are not nearly as detailed. Probably should flag this somehow. \n",
    "    daily_reports_df = daily_reports_df.drop_duplicates().groupby(['country_region','last_update']).sum()\n",
    "    # Reformat the location names and datetime index. Look at documentation above for details. \n",
    "    daily_reports_df = column_or_index_string_reformat(daily_reports_df, index=True, columns=True)\n",
    "    # name the indices and columns for later concatenation\n",
    "    daily_reports_df.index.names = ['location','date']\n",
    "    daily_reports_df.columns.names = ['csse_global_daily_reports']\n",
    "    return daily_reports_df\n",
    "    \n",
    "def csse_timeseries_reformat():\n",
    "    \"\"\" Import and concatenate all JHU CSSE time series data from local machine. \n",
    "    \"\"\"\n",
    "    global_df_list = []\n",
    "\n",
    "    for x in glob.glob('CSSEGIS_git_case_data/csse_covid_19_data/csse_covid_19_time_series/*_global.csv'):\n",
    "        global_tmp = column_or_index_string_reformat(pd.read_csv(x))\n",
    "        # only include the actual time series info; this removes latitude and \n",
    "        # longitude as well as other useless data.\n",
    "        global_specific_indice_list = [1] + list(range(4, global_tmp.shape[1]))\n",
    "        global_tmp = global_tmp.iloc[:,global_specific_indice_list].groupby(by='country_region').sum()\n",
    "        # keep the name of the data; i.e. 'confirmed', 'deaths', etc.\n",
    "        time_series_name = '_'.join(x.split('.')[0].split('_')[-2:][::-1])\n",
    "        global_df_list.append(global_tmp.stack().to_frame(name=time_series_name))    \n",
    "    \n",
    "    # concatenate the data and name it to abide by my convention. \n",
    "    global_time_series_df = pd.concat(global_df_list, axis=1)#.reset_index(drop=True)\n",
    "    global_time_series_df.index.names = ['location','date']\n",
    "    global_time_series_df.columns.names = ['csse_global_timeseries']\n",
    "    global_time_series_df = column_or_index_string_reformat(global_time_series_df, index=True, columns=False)\n",
    "\n",
    "    # Repeat the steps above but for United States statewide data. \n",
    "    usa_df_list = []\n",
    "    for y in glob.glob('CSSEGIS_git_case_data/csse_covid_19_data/csse_covid_19_time_series/*_US.csv'):\n",
    "        usa_tmp = column_or_index_string_reformat(pd.read_csv(y))\n",
    "        try:\n",
    "            usa_tmp = usa_tmp.drop(columns='population')\n",
    "        except: \n",
    "            pass\n",
    "        usa_specific_indice_list = [6] + list(range(10, usa_tmp.shape[1]))\n",
    "        usa_tmp = usa_tmp.iloc[:,usa_specific_indice_list].groupby(\n",
    "            by='province_state').sum()\n",
    "        time_series_name = '_'.join(y.split('.')[0].split('_')[-2:][::-1])\n",
    "        usa_tmp.index.name = 'state'\n",
    "        usa_df_list.append(usa_tmp.stack().to_frame(name=time_series_name))    \n",
    "    \n",
    "    usa_time_series_df = pd.concat(usa_df_list,axis=1)#.reset_index(drop=True)\n",
    "    usa_time_series_df.index.names = ['location','date']\n",
    "    usa_time_series_df.columns.names = ['csse_us_timeseries']\n",
    "    usa_time_series_df = column_or_index_string_reformat(usa_time_series_df, index=True, columns=False)\n",
    "    \n",
    "    return global_time_series_df, usa_time_series_df\n",
    "\n",
    "\n",
    "def regularize_country_names(df):\n",
    "    \"\"\" Reformat column and index names. only works with with pandas MultiIndex for level=0.\n",
    "    \n",
    "    Parameters :\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "\n",
    "    Notes :\n",
    "    -----\n",
    "    Different datasets have different naming conventions (for countries that go by multiple names and abbreviations).\n",
    "    This function imposes a convention on a selection of these country names.  \n",
    "    \"\"\"\n",
    "    # these lists are one-to-one. countries compared via manual inspection, unfortunately. \n",
    "    mismatch_labels_bad = ['Lao People\\'s Democratic Republic', 'Mainland China',\n",
    "                           'Occupied Palestinian Territory','Republic of Korea', 'Korea, South', \n",
    "                           'Gambia, The ', 'UK', \n",
    "                           'USA', 'Iran (Islamic Republic of)',\n",
    "                           'Bahamas, The', 'Russian Federation', 'Czech Republic', 'Republic Of Ireland',\n",
    "                          'Hong Kong Sar', 'Macao Sar', 'Uk','Us',\n",
    "                           'Congo ( Kinshasa)','Congo ( Brazzaville)',\n",
    "                           'Cote D\\' Ivoire', 'Viet Nam','Guinea- Bissau','Guinea','Usa']\n",
    "\n",
    "    mismatch_labels_good = ['Laos','China',\n",
    "                            'Palestine', 'South Korea', 'South Korea', \n",
    "                            'The Gambia', 'United Kingdom', \n",
    "                            'United States','Iran',\n",
    "                            'The Bahamas','Russia','Czechia','Ireland',\n",
    "                            'Hong Kong','Macao','United Kingdom', 'United States',\n",
    "                            'Democratic Republic Of The Congo','Republic Of The Congo',\n",
    "                            'Ivory Coast','Vietnam', 'Guinea Bissau','Guinea Bissau','United States']\n",
    "    \n",
    "    df = df.reset_index(level=0)\n",
    "    df.loc[:,'location'] = df.loc[:,'location'].replace(to_replace=mismatch_labels_bad, value=mismatch_labels_good)\n",
    "    df = df.set_index(['location', df.index])\n",
    "    return df\n",
    "\n",
    "#----------------- Helper Functions for regularization ----------------------#\n",
    "def intersect_country_index(df, country_intersection):\n",
    "    df_tmp = df.copy().reset_index(level=0)\n",
    "    df_tmp = df_tmp[df_tmp.location.isin(country_intersection)]\n",
    "    df_tmp = df_tmp.set_index(['location', df_tmp.index])\n",
    "    return df_tmp \n",
    "\n",
    "def resample_dates(df, dates):\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    return df.reindex(pd.MultiIndex.from_product([df.index.levels[0], dates], names=['location', 'date']), fill_value=np.nan)\n",
    "\n",
    "def make_multilevel_columns(df):\n",
    "    df.columns = pd.MultiIndex.from_product([[df.columns.name], df.columns], names=['dataset', 'features'])\n",
    "    return df\n",
    "\n",
    "#----------------- Manipulation flagging ----------------------#\n",
    "\n",
    "def flag_nan_differences(df, df_altered, suffix):\n",
    "    # Use bitwise XOR to flag the values which have been changed from NaN to something else.\n",
    "    # values which get mapped true -> false are those that are changed. \n",
    "    flag_df = df.isna() ^ df_altered.isna()\n",
    "    z1 = tuple(flag_df.columns.get_level_values(0).tolist())\n",
    "    z2 = tuple((flag_df.columns.get_level_values(1) + suffix).tolist())\n",
    "    flag_df.columns = pd.MultiIndex.from_tuples(list(zip(z1,z2)),names=['dataset', 'features'])\n",
    "    return flag_df\n",
    "\n",
    "\n",
    "#----------------- Currently Unused ----------------------#\n",
    "\n",
    "def pull_delphi_data(data_source=['fb-survey', 'google-survey', 'ght', 'quidel', 'quidelneg', 'doctor-visits'], \n",
    "                     daterange=pd.date_range(start=\"20200101\",\n",
    "                                             end=''.join(str(datetime.now().date()).split('-'))).strftime('%Y%m%d'),\n",
    "                     **kwargs):\n",
    "    \"\"\" Pull data from https://cmu-delphi.github.io/delphi-epidata/api/\n",
    "        https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for data in data_source:\n",
    "        signal_dict = {'fb-survey':'smoothed_cli',\n",
    "                       'google-survey':'smoothed_cli',\n",
    "                       'ght':'smoothed_search',\n",
    "                       'quidel':'smoothed_tests_per_device',\n",
    "                       'quidelneg':'smoothed_pct_negative',\n",
    "                       'doctor-visits':'smoothed_cli'}\n",
    "        \n",
    "        signal = signal_dict[data]\n",
    "        if data=='quidelneg':\n",
    "            #change the proxy for the quidel signal\n",
    "            data = 'quidel'\n",
    "        for days in daterange:\n",
    "            resp = requests.get('https://delphi.cmu.edu/epidata/api.php?source=covidcast&data_source=doctor-visits&signal=smoothed_cli&time_type=day&geo_type=county&geo_value=*&time_values='+days)\n",
    "            day_data = resp.json().get('epidata', None)\n",
    "            if day_data is None:\n",
    "                pass\n",
    "            else:\n",
    "                var_number += pd.json_normalize(day_data).size\n",
    "                print(pd.json_normalize(day_data).shape)    \n",
    "                \n",
    "                \n",
    "# date_range_2020 = pd.date_range(start=\"20200101\",end=''.join(str(datetime.now().date()).split('-'))).strftime('%Y%m%d')\n",
    "# var_number = 0 \n",
    "# for days in date_range_2020:\n",
    "# #     days='20200302'\n",
    "#     resp = requests.get('https://delphi.cmu.edu/epidata/api.php?source=covidcast&data_source=doctor-visits&signal=smoothed_cli&time_type=day&geo_type=county&geo_value=*&time_values='+days)\n",
    "#     day_data = resp.json().get('epidata', None)\n",
    "#     if day_data is None:\n",
    "#         pass\n",
    "#     else:\n",
    "#         var_number += pd.json_normalize(day_data).size\n",
    "#         print(pd.json_normalize(day_data).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reformatting\n",
    "\n",
    "The following sections take the corresponding data set and reformat them such that the data\n",
    "is stored in a pandas DataFrame with a multiindex; level=0 -> 'location' (country or region) and\n",
    "level=1 -> date. Due to the nature of the data this is done separately for country-wide and united states-wide locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU CSSE case data\n",
    "<a id='csse'></a>\n",
    "[Return to table of contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks / to-do for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### United States COVID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csse_global_daily_reports_df = csse_daily_reports_reformat().loc[:, ['confirmed','active','deaths','recovered']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csse_global_timeseries_df, csse_us_timeseries_df = csse_timeseries_reformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csse_global_timeseries</th>\n",
       "      <th>global_confirmed</th>\n",
       "      <th>global_deaths</th>\n",
       "      <th>global_recovered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Somalia</th>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunisia</th>\n",
       "      <th>2020-04-12</th>\n",
       "      <td>707</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azerbaijan</th>\n",
       "      <th>2020-04-11</th>\n",
       "      <td>1058</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qatar</th>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "csse_global_timeseries  global_confirmed  global_deaths  global_recovered\n",
       "location   date                                                          \n",
       "Somalia    2020-01-25                  0              0                 0\n",
       "Tunisia    2020-04-12                707             31                43\n",
       "Bangladesh 2020-02-10                  0              0                 0\n",
       "Azerbaijan 2020-04-11               1058             11               200\n",
       "Qatar      2020-01-24                  0              0                 0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csse_global_timeseries_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently unused\n",
    "#pd.read_csv('./CSSEGIS_git_case_data/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHME hospital data\n",
    "<a id='ihme'></a>\n",
    "[Return to table of contents](#toc)\n",
    "\n",
    "[JHU CSSE](#csse) \n",
    "<font color='red'>\n",
    "### Has all USA states but only 32 countries which overlap with other data; stash this dataset for now. \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_df = column_or_index_string_reformat(pd.read_csv(\n",
    "    './IHME_hospital_data/2020_04_12.02/Hospitalization_all_locs.csv').rename(columns={'location_name':'location'}))\n",
    "ihme_df.loc[:, 'date'] = pd.to_datetime(ihme_df.loc[:,'date']).dt.normalize()\n",
    "ihme_df = ihme_df.set_index(['location', 'date']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>allbed_mean</th>\n",
       "      <th>allbed_lower</th>\n",
       "      <th>allbed_upper</th>\n",
       "      <th>icubed_mean</th>\n",
       "      <th>icubed_lower</th>\n",
       "      <th>icubed_upper</th>\n",
       "      <th>inv_ven_mean</th>\n",
       "      <th>inv_ven_lower</th>\n",
       "      <th>inv_ven_upper</th>\n",
       "      <th>...</th>\n",
       "      <th>new_icu_upper</th>\n",
       "      <th>totdea_mean</th>\n",
       "      <th>totdea_lower</th>\n",
       "      <th>totdea_upper</th>\n",
       "      <th>bedover_mean</th>\n",
       "      <th>bedover_lower</th>\n",
       "      <th>bedover_upper</th>\n",
       "      <th>icuover_mean</th>\n",
       "      <th>icuover_lower</th>\n",
       "      <th>icuover_upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>2020-05-24</th>\n",
       "      <td>143</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.101</td>\n",
       "      <td>191.0</td>\n",
       "      <td>780.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>31</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>2020-05-24</th>\n",
       "      <td>143</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.354</td>\n",
       "      <td>32.0</td>\n",
       "      <td>151.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liguria</th>\n",
       "      <th>2020-05-24</th>\n",
       "      <td>143</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>773.412</td>\n",
       "      <td>761.0</td>\n",
       "      <td>796.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>24</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          v1  allbed_mean  allbed_lower  allbed_upper  \\\n",
       "location     date                                                       \n",
       "Wisconsin    2020-05-24  143      0.00080           0.0           0.0   \n",
       "South Dakota 2020-02-02   31      0.00000           0.0           0.0   \n",
       "Bulgaria     2020-05-24  143      0.00065           0.0           0.0   \n",
       "Liguria      2020-05-24  143      0.00000           0.0           0.0   \n",
       "Oregon       2020-01-26   24      0.00000           0.0           0.0   \n",
       "\n",
       "                         icubed_mean  icubed_lower  icubed_upper  \\\n",
       "location     date                                                  \n",
       "Wisconsin    2020-05-24          0.0           0.0           0.0   \n",
       "South Dakota 2020-02-02          0.0           0.0           0.0   \n",
       "Bulgaria     2020-05-24          0.0           0.0           0.0   \n",
       "Liguria      2020-05-24          0.0           0.0           0.0   \n",
       "Oregon       2020-01-26          0.0           0.0           0.0   \n",
       "\n",
       "                         inv_ven_mean  inv_ven_lower  inv_ven_upper  ...  \\\n",
       "location     date                                                    ...   \n",
       "Wisconsin    2020-05-24           0.0            0.0            0.0  ...   \n",
       "South Dakota 2020-02-02           0.0            0.0            0.0  ...   \n",
       "Bulgaria     2020-05-24           0.0            0.0            0.0  ...   \n",
       "Liguria      2020-05-24           0.0            0.0            0.0  ...   \n",
       "Oregon       2020-01-26           0.0            0.0            0.0  ...   \n",
       "\n",
       "                         new_icu_upper  totdea_mean  totdea_lower  \\\n",
       "location     date                                                   \n",
       "Wisconsin    2020-05-24            0.0      338.101         191.0   \n",
       "South Dakota 2020-02-02            0.0        0.000           0.0   \n",
       "Bulgaria     2020-05-24            0.0       66.354          32.0   \n",
       "Liguria      2020-05-24            0.0      773.412         761.0   \n",
       "Oregon       2020-01-26            0.0        0.000           0.0   \n",
       "\n",
       "                         totdea_upper  bedover_mean  bedover_lower  \\\n",
       "location     date                                                    \n",
       "Wisconsin    2020-05-24       780.275           0.0            0.0   \n",
       "South Dakota 2020-02-02         0.000           0.0            0.0   \n",
       "Bulgaria     2020-05-24       151.025           0.0            0.0   \n",
       "Liguria      2020-05-24       796.000           0.0            0.0   \n",
       "Oregon       2020-01-26         0.000           0.0            0.0   \n",
       "\n",
       "                         bedover_upper  icuover_mean  icuover_lower  \\\n",
       "location     date                                                     \n",
       "Wisconsin    2020-05-24            0.0           0.0            0.0   \n",
       "South Dakota 2020-02-02            0.0           0.0            0.0   \n",
       "Bulgaria     2020-05-24            0.0           0.0            0.0   \n",
       "Liguria      2020-05-24            0.0           0.0            0.0   \n",
       "Oregon       2020-01-26            0.0           0.0            0.0   \n",
       "\n",
       "                         icuover_upper  \n",
       "location     date                       \n",
       "Wisconsin    2020-05-24            0.0  \n",
       "South Dakota 2020-02-02            0.0  \n",
       "Bulgaria     2020-05-24            0.0  \n",
       "Liguria      2020-05-24            0.0  \n",
       "Oregon       2020-01-26            0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihme_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OWID case and test data\n",
    "<a id='source5'></a>\n",
    "[Return to table of contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "owid_df = column_or_index_string_reformat(pd.read_csv('./OWID_git_and_manual_case_and_test_data/owid-covid-data.csv'))\n",
    "owid_df.loc[:, 'date'] = pd.to_datetime(owid_df.loc[:, 'date']).dt.normalize()\n",
    "owid_df = owid_df.set_index(['location','date']).sort_index()\n",
    "owid_df = regularize_country_names(owid_df)\n",
    "owid_df.columns.names = ['owid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owid</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>total_cases_per_million</th>\n",
       "      <th>new_cases_per_million</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>new_deaths_per_million</th>\n",
       "      <th>total_tests</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>total_tests_per_thousand</th>\n",
       "      <th>new_tests_per_thousand</th>\n",
       "      <th>tests_units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <th>2020-04-04</th>\n",
       "      <td>IRQ</td>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>19.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.343</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>2020-04-10</th>\n",
       "      <td>ATG</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>194.020</td>\n",
       "      <td>40.846</td>\n",
       "      <td>20.423</td>\n",
       "      <td>20.423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benin</th>\n",
       "      <th>2020-03-18</th>\n",
       "      <td>BEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timor</th>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>TLS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guernsey</th>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>GGY</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "owid                           iso_code  total_cases  new_cases  total_deaths  \\\n",
       "location            date                                                        \n",
       "Iraq                2020-04-04      IRQ          772          0            54   \n",
       "Antigua and Barbuda 2020-04-10      ATG           19          4             2   \n",
       "Benin               2020-03-18      BEN            1          0             0   \n",
       "Timor               2020-04-02      TLS            1          0             0   \n",
       "Guernsey            2020-03-26      GGY           30          7             0   \n",
       "\n",
       "owid                            new_deaths  total_cases_per_million  \\\n",
       "location            date                                              \n",
       "Iraq                2020-04-04           0                   19.193   \n",
       "Antigua and Barbuda 2020-04-10           2                  194.020   \n",
       "Benin               2020-03-18           0                    0.082   \n",
       "Timor               2020-04-02           0                    0.758   \n",
       "Guernsey            2020-03-26           0                      NaN   \n",
       "\n",
       "owid                            new_cases_per_million  \\\n",
       "location            date                                \n",
       "Iraq                2020-04-04                  0.000   \n",
       "Antigua and Barbuda 2020-04-10                 40.846   \n",
       "Benin               2020-03-18                  0.000   \n",
       "Timor               2020-04-02                  0.000   \n",
       "Guernsey            2020-03-26                    NaN   \n",
       "\n",
       "owid                            total_deaths_per_million  \\\n",
       "location            date                                   \n",
       "Iraq                2020-04-04                     1.343   \n",
       "Antigua and Barbuda 2020-04-10                    20.423   \n",
       "Benin               2020-03-18                     0.000   \n",
       "Timor               2020-04-02                     0.000   \n",
       "Guernsey            2020-03-26                       NaN   \n",
       "\n",
       "owid                            new_deaths_per_million  total_tests  \\\n",
       "location            date                                              \n",
       "Iraq                2020-04-04                   0.000          NaN   \n",
       "Antigua and Barbuda 2020-04-10                  20.423          NaN   \n",
       "Benin               2020-03-18                   0.000          NaN   \n",
       "Timor               2020-04-02                   0.000          NaN   \n",
       "Guernsey            2020-03-26                     NaN          NaN   \n",
       "\n",
       "owid                            new_tests  total_tests_per_thousand  \\\n",
       "location            date                                              \n",
       "Iraq                2020-04-04        NaN                       NaN   \n",
       "Antigua and Barbuda 2020-04-10        NaN                       NaN   \n",
       "Benin               2020-03-18        NaN                       NaN   \n",
       "Timor               2020-04-02        NaN                       NaN   \n",
       "Guernsey            2020-03-26        NaN                       NaN   \n",
       "\n",
       "owid                            new_tests_per_thousand tests_units  \n",
       "location            date                                            \n",
       "Iraq                2020-04-04                     NaN         NaN  \n",
       "Antigua and Barbuda 2020-04-10                     NaN         NaN  \n",
       "Benin               2020-03-18                     NaN         NaN  \n",
       "Timor               2020-04-02                     NaN         NaN  \n",
       "Guernsey            2020-03-26                     NaN         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owid_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OxCGRT government response data\n",
    "<a id='oxcgrt'></a>\n",
    "[Return to table of contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the data using their API (for whatever reason this data set is different from the manual download)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual importation of data (for whatever reason this data set is different from pulling using API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxcgrt_df = column_or_index_string_reformat(pd.read_csv('./OxCGRT_response_data/OxCGRT_20200504.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxcgrt_df.loc[:,'date'] = pd.to_datetime(oxcgrt_df.date,format='%Y%m%d').dt.normalize()\n",
    "oxcgrt_df = oxcgrt_df.set_index(['country_name', 'date']).sort_index()\n",
    "oxcgrt_df.index.names = ['location','date']\n",
    "oxcgrt_df.columns.names = ['oxcgrt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the data using their API (for whatever reason this data set is different from the manual download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_to_present_date = 'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/stringency/date-range/2020-01-02/' \\\n",
    "#                         + str(datetime.now().date())\n",
    "# response = requests.get(url_to_present_date)\n",
    "# response_json = response.json()\n",
    "# response_json_nested_dict = response_json['data']\n",
    "\n",
    "# response_api_df = pd.DataFrame.from_dict({(i,j): response_json_nested_dict[i][j] \n",
    "#                            for i in response_json_nested_dict.keys() \n",
    "#                            for j in response_json_nested_dict[i].keys()},\n",
    "#                        orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each computation requires its own unique slice, with a multiindex no less, I find it easiest\n",
    "to create a DataFrame whose values are pandas multislice elements using pandas IndexSlice objects. \n",
    "These values cannot be passed at once to the testing multiindex array, but it was designed to take advantage of the .apply method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing tracker data\n",
    "<a id='testtrack'></a>\n",
    "[Return to table of contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_track</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>tests_cumulative</th>\n",
       "      <th>penalty</th>\n",
       "      <th>population</th>\n",
       "      <th>per100k</th>\n",
       "      <th>testsPer100k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <th>2020-04-20</th>\n",
       "      <td>1054</td>\n",
       "      <td>54344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10423000</td>\n",
       "      <td>521.4</td>\n",
       "      <td>521.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burkina Faso</th>\n",
       "      <th>2020-04-15</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1.3</td>\n",
       "      <td>20903000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philippines</th>\n",
       "      <th>2020-04-18</th>\n",
       "      <td>11757</td>\n",
       "      <td>59928</td>\n",
       "      <td>1.3</td>\n",
       "      <td>109581000</td>\n",
       "      <td>54.7</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kenya</th>\n",
       "      <th>2020-04-21</th>\n",
       "      <td>545</td>\n",
       "      <td>13784</td>\n",
       "      <td>1.3</td>\n",
       "      <td>53771000</td>\n",
       "      <td>25.6</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sri Lanka</th>\n",
       "      <th>2020-05-03</th>\n",
       "      <td>0</td>\n",
       "      <td>2082</td>\n",
       "      <td>1.3</td>\n",
       "      <td>21413000</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "test_track               new_tests  tests_cumulative  penalty  population  \\\n",
       "location     date                                                           \n",
       "Greece       2020-04-20       1054             54344      1.0    10423000   \n",
       "Burkina Faso 2020-04-15          0                99      1.3    20903000   \n",
       "Philippines  2020-04-18      11757             59928      1.3   109581000   \n",
       "Kenya        2020-04-21        545             13784      1.3    53771000   \n",
       "Sri Lanka    2020-05-03          0              2082      1.3    21413000   \n",
       "\n",
       "test_track               per100k  testsPer100k  \n",
       "location     date                               \n",
       "Greece       2020-04-20    521.4         521.4  \n",
       "Burkina Faso 2020-04-15      0.5           0.5  \n",
       "Philippines  2020-04-18     54.7          54.7  \n",
       "Kenya        2020-04-21     25.6          25.6  \n",
       "Sri Lanka    2020-05-03      9.7           9.7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtrack_df = pd.read_csv('./TestTracker_data/Tests_20200504.csv')\n",
    "testtrack_df.loc[:, 'date'] = pd.to_datetime(testtrack_df.loc[:, 'date']).dt.normalize()\n",
    "# testtrack_df.loc[:, 'date'] = pd.to_datetime(testtrack_df.loc[:, 'date'], format='%Y-%m-%d', errors='coerce')\n",
    "testtrack_df = testtrack_df.set_index(['country','date']).sort_index()\n",
    "testtrack_df.index.names = ['location','date']\n",
    "testtrack_df.columns.names = ['test_track']\n",
    "unused_columns = ['ind', 'jhu_ID.x', 'source', 'X.x', 'X.y', 'alpha2', 'alpha3',\n",
    "                  'numeric', 'latitude', 'longitude', 'jhu_ID.y', 'notes']\n",
    "\n",
    "testtrack_df = testtrack_df.drop(columns=unused_columns)\n",
    "testtrack_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delphi-epidata\n",
    "<a id='delphi'></a>\n",
    "[Return to table of contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_source\tname of upstream data source \n",
    "(e.g., fb-survey, google-survey, ght, quidel, doctor-visits)\tstring\n",
    "\n",
    "signal\tname of signal derived from upstream data (see notes below)\tstring\n",
    "\n",
    "time_type\ttemporal resolution of the signal (e.g., day, week)\tstring\n",
    "\n",
    "geo_type\tspatial resolution of the signal (e.g., county, hrr, msa, dma, state)\tstring\n",
    "\n",
    "time_values\ttime unit (e.g., date) over which underlying events happened\tlist of time values (e.g., 20200401)\n",
    "\n",
    "geo_value\tunique code for each location, depending on geo_type (county -> FIPS 6-4 code, HRR -> HRR number, MSA -> CBSA code,\n",
    "DMA -> DMA code, state -> two-letter state code), or * for all\tstring\n",
    "\n",
    "As of this writing, data sources have the following signals:\n",
    "\n",
    "fb-survey signal values include raw_cli, raw_ili, raw_wcli, raw_wili, and also four additional named with raw_* replaced by smoothed_* (e.g. smoothed_cli, etc).\n",
    "google-survey signal values include raw_cli and smoothed_cli.\n",
    "ght signal values include raw_search and smoothed_search.\n",
    "quidel signal values include smoothed_pct_negative and smoothed_tests_per_device.\n",
    "doctor-visits signal values include smoothed_cli.\n",
    "\n",
    "Delphi API data :\n",
    "doctor visits : 20200201-20200429 (as of 20200503)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data regularization: making things uniform <a id='uniformity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection of countries in all DataFrames\n",
    "<a id='country'></a>\n",
    "[Return to table of contents](#toc)\n",
    "\n",
    "The data that will be used exists in the DataFrames : \n",
    "\n",
    "    csse_global_daily_reports_df\n",
    "    csse_global_timeseries_df\n",
    "    csse_us_timeseries_df\n",
    "    ihme_df\n",
    "    owid_df\n",
    "    oxcgrt_df\n",
    "    testtrack_df\n",
    "    \n",
    "The index (locations) were not reformatted by default; do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_track</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>tests_cumulative</th>\n",
       "      <th>penalty</th>\n",
       "      <th>population</th>\n",
       "      <th>per100k</th>\n",
       "      <th>testsPer100k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Afghanistan</th>\n",
       "      <th>2020-03-03</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38928000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-04</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38928000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-05</th>\n",
       "      <td>22</td>\n",
       "      <td>81</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38928000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-06</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38928000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-07</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38928000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Zimbabwe</th>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>1247</td>\n",
       "      <td>7642</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14863000</td>\n",
       "      <td>51.4</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>672</td>\n",
       "      <td>8314</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14863000</td>\n",
       "      <td>55.9</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>977</td>\n",
       "      <td>9291</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14863000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-02</th>\n",
       "      <td>0</td>\n",
       "      <td>9291</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14863000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-03</th>\n",
       "      <td>0</td>\n",
       "      <td>9291</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14863000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6736 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "test_track              new_tests  tests_cumulative  penalty  population  \\\n",
       "location    date                                                           \n",
       "Afghanistan 2020-03-03         59                59      1.3    38928000   \n",
       "            2020-03-04          0                59      1.3    38928000   \n",
       "            2020-03-05         22                81      1.3    38928000   \n",
       "            2020-03-06          0                81      1.3    38928000   \n",
       "            2020-03-07          3                84      1.3    38928000   \n",
       "...                           ...               ...      ...         ...   \n",
       "Zimbabwe    2020-04-29       1247              7642      1.3    14863000   \n",
       "            2020-04-30        672              8314      1.3    14863000   \n",
       "            2020-05-01        977              9291      1.3    14863000   \n",
       "            2020-05-02          0              9291      1.3    14863000   \n",
       "            2020-05-03          0              9291      1.3    14863000   \n",
       "\n",
       "test_track              per100k  testsPer100k  \n",
       "location    date                               \n",
       "Afghanistan 2020-03-03      0.2           0.2  \n",
       "            2020-03-04      0.2           0.2  \n",
       "            2020-03-05      0.2           0.2  \n",
       "            2020-03-06      0.2           0.2  \n",
       "            2020-03-07      0.2           0.2  \n",
       "...                         ...           ...  \n",
       "Zimbabwe    2020-04-29     51.4          51.4  \n",
       "            2020-04-30     55.9          55.9  \n",
       "            2020-05-01     62.5          62.5  \n",
       "            2020-05-02     62.5          62.5  \n",
       "            2020-05-03     62.5          62.5  \n",
       "\n",
       "[6736 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtrack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [csse_global_daily_reports_df,\n",
    "    csse_global_timeseries_df,\n",
    "    csse_us_timeseries_df,\n",
    "    ihme_df,\n",
    "    owid_df,\n",
    "    oxcgrt_df,\n",
    "    testtrack_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = all_data[:2] + all_data[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(all_data):\n",
    "    all_data[i] = regularize_country_names(column_or_index_string_reformat(df, index=True, columns=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(global_data):\n",
    "    global_data[i] = regularize_country_names(column_or_index_string_reformat(df, index=True, columns=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2019-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "country_intersection = global_data[0].index.levels[0]\n",
    "dates_union =  global_data[0].index.levels[1].unique()\n",
    "for i in range(len(global_data)-1):\n",
    "    country_intersection = country_intersection.intersection(global_data[i+1].index.levels[0])\n",
    "    dates_union = dates_union.union(global_data[i+1].index.levels[1].unique())\n",
    "    print(dates_union.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_intersected = [intersect_country_index(df, country_intersection) for df in global_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense, because of the intersections between data; to us the u.s. time series and ihme data together but not with\n",
    "the global data. The hospital data is very useful and so it may be important to look specifically at the small number of countries it contains. Regardless; by using only the global data we can keep 110 countries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pruned response data has 122 countries and the testing data has 206, the intersection : 94.\n",
    "These 94 countries still account for 6.6 billion people, notable missing entries are: Ethiopia, Iran. Congo, United Kingdom,\n",
    "dropped because they had missing values in governement response data; i.e. they did not take all considered actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization of time series dates\n",
    "<a id='time'></a>\n",
    "[Return to table of contents](#toc)\n",
    "\n",
    "Want to have all time dependent data defined on the same time ranges for convenience;\n",
    "this involves two steps. 1. Initialize the new dates, 2. deal with the missing values. \n",
    "Because there are already a good amount of missing values, this second step is saved until later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With identical countries and dates (identical MultiIndex) the list of DataFrames can easier be concatenated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "<a id='missingval'></a>\n",
    "[Return to table of contents](#toc)\n",
    "\n",
    "Redefining the time series range for most countries introduces a large number of missing values. To account for this, I will be replacing missing values in categorical variables with the value 'Missing' and I will be backfilling with a linear interpolant for numerical variables, so that the time series (and actions to be performed later) will be well defined. \n",
    "\n",
    "Next, I need to create a strategy for how to account for missing test values (i.e. when there are cases but no tests, presumably this is either a lack of reporting or the \"confirmed\" cases are via diagnosis rather than explicit testing).\n",
    "\n",
    "There are two \"types\" of missing test values: those from errors in reporting and those from confirmation of cases via diagnosis. I distinguish between these two types via the following: errors in reporting occur when there are gaps in the testing data after the date of the first known test. The second type occurs when there are known or confirmed cases but no testing data yet exists. To account for the first type I will use forward filling, as to not overestimate \n",
    "\n",
    "\n",
    "The second part of the weighting process is by the testing numbers, as the number of cases will go up if you\n",
    "test more.\n",
    "\n",
    "Import the new testing data (much better), but still use the old dataset because it has cases normalized by population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This redefines the time series for all variables as from December 31st 2019 to the day with most recent data\n",
    "normalized_global_data = [resample_dates(df, dates_union) for df in global_data_intersected]\n",
    "# To keep track of which data came from where, make the columns multi level with the first level labelling the dataset.\n",
    "data = pd.concat([make_multilevel_columns(df) for df in normalized_global_data], axis=1)\n",
    "\n",
    "#OxCGRT's \"flag\" columns (which indicate a target or general response) are numerical but I will cast them as categorical\n",
    "#so that they are not affected by the upcoming numerical feature manipulations. \n",
    "flag_columns =  data.columns.levels[1][data.columns.levels[1].str.contains('flag')]\n",
    "multiindex_for_flag_columns = pd.MultiIndex.from_product([['oxcgrt'], flag_columns], names=['dataset', 'features'])\n",
    "data.loc[:, multiindex_for_flag_columns] = data.loc[:, multiindex_for_flag_columns].fillna(value=-1.).astype('category')\n",
    "\n",
    "data_numerical = data.copy().select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated = data_numerical.groupby(level=0).apply(lambda x : x.interpolate(limit_direction='backward'))\n",
    "interpolate_flagged = flag_nan_differences(data_numerical, interpolated, '_interpolated')\n",
    "\n",
    "forwardfill = interpolated.groupby(level=0).fillna(method='ffill')\n",
    "forwardfill_flagged = flag_nan_differences(interpolated, forwardfill, 'ffill')\n",
    "\n",
    "\n",
    "\n",
    "#.fillna(value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backfill with interpolation, forward fill the remainder; NaNs may remain if there are only missing values\n",
    "# in their group. Therefore, still need to replace the remainder with something. Because so many of the features\n",
    "# utilize 0, I'm going to fill the remainder of missing values with -1 because nowhere do negative values appear. \n",
    "data.loc[data_numerical.index, data_numerical.columns] = data_numerical.groupby(level=0).apply(\n",
    "    lambda x : x.interpolate(limit_direction='backward')).groupby(level=0).fillna(method='ffill').fillna(value=-1)\n",
    "\n",
    "# still_missing_values = data.loc[:, pd.IndexSlice['test_track',:]].isna().sum()#.loc[pd.IndexSlice[:, #.index.levels[1]\n",
    "throw_out_these = still_missing_values.index[still_missing_values > 0]\n",
    "# data = data.drop(columns=)\n",
    "# These features do not seem worthwhile\n",
    "data = data.drop(columns=[('owid','iso_code'),\n",
    "                         ('oxcgrt','m1_wildcard'), ('oxcgrt','country_code')]\n",
    "                          + throw_out_these.tolist())\n",
    "# only remaining missing values are not numerical\n",
    "data.loc[:, ('owid', 'tests_units')] = data.loc[:, ('owid', 'tests_units')].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">csse_global_daily_reports</th>\n",
       "      <th colspan=\"3\" halign=\"left\">csse_global_timeseries</th>\n",
       "      <th colspan=\"3\" halign=\"left\">owid</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">oxcgrt</th>\n",
       "      <th colspan=\"6\" halign=\"left\">test_track</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>active</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>global_confirmed</th>\n",
       "      <th>global_deaths</th>\n",
       "      <th>global_recovered</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>...</th>\n",
       "      <th>stringency_index</th>\n",
       "      <th>stringency_index_for_display</th>\n",
       "      <th>legacy_stringency_index</th>\n",
       "      <th>legacy_stringency_index_for_display</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>tests_cumulative</th>\n",
       "      <th>penalty</th>\n",
       "      <th>population</th>\n",
       "      <th>per100k</th>\n",
       "      <th>testsPer100k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ireland</th>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4938000.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>36.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cuba</th>\n",
       "      <th>2020-03-14</th>\n",
       "      <td>4.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.29</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>11327000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saudi Arabia</th>\n",
       "      <th>2020-03-05</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.29</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>34814000.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cameroon</th>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>1705.00</td>\n",
       "      <td>842.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.88</td>\n",
       "      <td>63.88</td>\n",
       "      <td>68.57</td>\n",
       "      <td>68.57</td>\n",
       "      <td>9254.0</td>\n",
       "      <td>9254.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>26546000.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <th>2020-03-13</th>\n",
       "      <td>4970.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3681.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2876.000000</td>\n",
       "      <td>595.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.86</td>\n",
       "      <td>42.86</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15018.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>65274000.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>16755.00</td>\n",
       "      <td>14184.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>17567.0</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>14385.000000</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.35</td>\n",
       "      <td>47.35</td>\n",
       "      <td>58.10</td>\n",
       "      <td>58.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10099000.0</td>\n",
       "      <td>935.7</td>\n",
       "      <td>935.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <th>2020-03-10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.89</td>\n",
       "      <td>13.89</td>\n",
       "      <td>17.14</td>\n",
       "      <td>17.14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14863000.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.82</td>\n",
       "      <td>21.82</td>\n",
       "      <td>25.71</td>\n",
       "      <td>25.71</td>\n",
       "      <td>586.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>65274000.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazakhstan</th>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>2289.00</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2482.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.88</td>\n",
       "      <td>74.88</td>\n",
       "      <td>75.71</td>\n",
       "      <td>75.71</td>\n",
       "      <td>11013.0</td>\n",
       "      <td>164505.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>18777000.0</td>\n",
       "      <td>876.1</td>\n",
       "      <td>876.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>15529.00</td>\n",
       "      <td>5009.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>9086.0</td>\n",
       "      <td>16752.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>11423.0</td>\n",
       "      <td>8261.000000</td>\n",
       "      <td>764.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.38</td>\n",
       "      <td>68.38</td>\n",
       "      <td>85.95</td>\n",
       "      <td>85.95</td>\n",
       "      <td>14671.0</td>\n",
       "      <td>77005.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>128933000.0</td>\n",
       "      <td>59.7</td>\n",
       "      <td>59.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                 csse_global_daily_reports                             \\\n",
       "features                                confirmed   active  deaths recovered   \n",
       "location     date                                                              \n",
       "Ireland      2020-01-08                      1.00      0.0     0.0       0.0   \n",
       "Cuba         2020-03-14                      4.25      0.0     0.0       0.0   \n",
       "Saudi Arabia 2020-03-05                      5.00      0.0     0.0       0.0   \n",
       "Cameroon     2020-04-28                   1705.00    842.0    58.0     805.0   \n",
       "France       2020-03-13                   4970.00      0.0   103.0      16.0   \n",
       "Sweden       2020-04-24                  16755.00  14184.0  2021.0     550.0   \n",
       "Zimbabwe     2020-03-10                      1.00      0.0     0.0       0.0   \n",
       "France       2020-02-29                    100.00      0.0     2.0      12.0   \n",
       "Kazakhstan   2020-04-24                   2289.00   1709.0    20.0     560.0   \n",
       "Mexico       2020-04-28                  15529.00   5009.0  1434.0    9086.0   \n",
       "\n",
       "dataset                 csse_global_timeseries                                 \\\n",
       "features                      global_confirmed global_deaths global_recovered   \n",
       "location     date                                                               \n",
       "Ireland      2020-01-08                    0.0           0.0              0.0   \n",
       "Cuba         2020-03-14                    4.0           0.0              0.0   \n",
       "Saudi Arabia 2020-03-05                    5.0           0.0              0.0   \n",
       "Cameroon     2020-04-28                 1705.0          58.0            915.0   \n",
       "France       2020-03-13                 3681.0          79.0             12.0   \n",
       "Sweden       2020-04-24                17567.0        2152.0           1005.0   \n",
       "Zimbabwe     2020-03-10                    0.0           0.0              0.0   \n",
       "France       2020-02-29                  100.0           2.0             12.0   \n",
       "Kazakhstan   2020-04-24                 2482.0          25.0            604.0   \n",
       "Mexico       2020-04-28                16752.0        1569.0          11423.0   \n",
       "\n",
       "dataset                          owid                         ...  \\\n",
       "features                  total_cases new_cases total_deaths  ...   \n",
       "location     date                                             ...   \n",
       "Ireland      2020-01-08      0.000000       0.0          0.0  ...   \n",
       "Cuba         2020-03-14      4.000000       1.0          0.0  ...   \n",
       "Saudi Arabia 2020-03-05      3.666667       3.0          0.0  ...   \n",
       "Cameroon     2020-04-28   1016.000000       0.0         42.0  ...   \n",
       "France       2020-03-13   2876.000000     595.0         61.0  ...   \n",
       "Sweden       2020-04-24  14385.000000     563.0       1540.0  ...   \n",
       "Zimbabwe     2020-03-10      1.000000       1.0          0.0  ...   \n",
       "France       2020-02-29     57.000000      19.0          2.0  ...   \n",
       "Kazakhstan   2020-04-24   1735.000000      81.0         19.0  ...   \n",
       "Mexico       2020-04-28   8261.000000     764.0        686.0  ...   \n",
       "\n",
       "dataset                           oxcgrt                               \\\n",
       "features                stringency_index stringency_index_for_display   \n",
       "location     date                                                       \n",
       "Ireland      2020-01-08             0.00                         0.00   \n",
       "Cuba         2020-03-14            11.11                        11.11   \n",
       "Saudi Arabia 2020-03-05            11.11                        11.11   \n",
       "Cameroon     2020-04-28            63.88                        63.88   \n",
       "France       2020-03-13            42.86                        42.86   \n",
       "Sweden       2020-04-24            47.35                        47.35   \n",
       "Zimbabwe     2020-03-10            13.89                        13.89   \n",
       "France       2020-02-29            21.82                        21.82   \n",
       "Kazakhstan   2020-04-24            74.88                        74.88   \n",
       "Mexico       2020-04-28            68.38                        68.38   \n",
       "\n",
       "dataset                                          \\\n",
       "features                legacy_stringency_index   \n",
       "location     date                                 \n",
       "Ireland      2020-01-08                    0.00   \n",
       "Cuba         2020-03-14                   14.29   \n",
       "Saudi Arabia 2020-03-05                   14.29   \n",
       "Cameroon     2020-04-28                   68.57   \n",
       "France       2020-03-13                   45.00   \n",
       "Sweden       2020-04-24                   58.10   \n",
       "Zimbabwe     2020-03-10                   17.14   \n",
       "France       2020-02-29                   25.71   \n",
       "Kazakhstan   2020-04-24                   75.71   \n",
       "Mexico       2020-04-28                   85.95   \n",
       "\n",
       "dataset                                                     test_track  \\\n",
       "features                legacy_stringency_index_for_display  new_tests   \n",
       "location     date                                                        \n",
       "Ireland      2020-01-08                                0.00     1784.0   \n",
       "Cuba         2020-03-14                               14.29      893.0   \n",
       "Saudi Arabia 2020-03-05                               14.29     3500.0   \n",
       "Cameroon     2020-04-28                               68.57     9254.0   \n",
       "France       2020-03-13                               45.00        0.0   \n",
       "Sweden       2020-04-24                               58.10        0.0   \n",
       "Zimbabwe     2020-03-10                               17.14       15.0   \n",
       "France       2020-02-29                               25.71      586.0   \n",
       "Kazakhstan   2020-04-24                               75.71    11013.0   \n",
       "Mexico       2020-04-28                               85.95    14671.0   \n",
       "\n",
       "dataset                                                                \\\n",
       "features                tests_cumulative penalty   population per100k   \n",
       "location     date                                                       \n",
       "Ireland      2020-01-08           1784.0     0.8    4938000.0    36.1   \n",
       "Cuba         2020-03-14            893.0     1.3   11327000.0     7.9   \n",
       "Saudi Arabia 2020-03-05           3500.0     1.3   34814000.0    10.1   \n",
       "Cameroon     2020-04-28           9254.0     1.3   26546000.0    34.9   \n",
       "France       2020-03-13          15018.0     0.9   65274000.0    23.0   \n",
       "Sweden       2020-04-24          94500.0     0.6   10099000.0   935.7   \n",
       "Zimbabwe     2020-03-10             15.0     1.3   14863000.0     0.1   \n",
       "France       2020-02-29           1902.0     0.9   65274000.0     2.9   \n",
       "Kazakhstan   2020-04-24         164505.0     0.9   18777000.0   876.1   \n",
       "Mexico       2020-04-28          77005.0     1.3  128933000.0    59.7   \n",
       "\n",
       "dataset                               \n",
       "features                testsPer100k  \n",
       "location     date                     \n",
       "Ireland      2020-01-08         36.1  \n",
       "Cuba         2020-03-14          7.9  \n",
       "Saudi Arabia 2020-03-05         10.1  \n",
       "Cameroon     2020-04-28         34.9  \n",
       "France       2020-03-13         23.0  \n",
       "Sweden       2020-04-24        935.7  \n",
       "Zimbabwe     2020-03-10          0.1  \n",
       "France       2020-02-29          2.9  \n",
       "Kazakhstan   2020-04-24        876.1  \n",
       "Mexico       2020-04-28         59.7  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat of the above calculations for United States only data.\n",
    "\n",
    "<font color='red'>\n",
    "unfinished as of now\n",
    "</font>\n",
    "\n",
    "The United States' data merits separate investigation 1. because of the case number 2. because the IHME dataset is only really\n",
    "properly defined for the statewide description of the U.S. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csse_us_timeseries</th>\n",
       "      <th>US_confirmed</th>\n",
       "      <th>US_deaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>545</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>559</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>566</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-02</th>\n",
       "      <td>579</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-03</th>\n",
       "      <td>586</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "csse_us_timeseries   US_confirmed  US_deaths\n",
       "location date                               \n",
       "Alabama  2020-01-22             0          0\n",
       "         2020-01-23             0          0\n",
       "         2020-01-24             0          0\n",
       "         2020-01-25             0          0\n",
       "         2020-01-26             0          0\n",
       "...                           ...        ...\n",
       "Wyoming  2020-04-29           545          7\n",
       "         2020-04-30           559          7\n",
       "         2020-05-01           566          7\n",
       "         2020-05-02           579          7\n",
       "         2020-05-03           586          7\n",
       "\n",
       "[5974 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csse_us_timeseries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>allbed_mean</th>\n",
       "      <th>allbed_lower</th>\n",
       "      <th>allbed_upper</th>\n",
       "      <th>icubed_mean</th>\n",
       "      <th>icubed_lower</th>\n",
       "      <th>icubed_upper</th>\n",
       "      <th>inv_ven_mean</th>\n",
       "      <th>inv_ven_lower</th>\n",
       "      <th>inv_ven_upper</th>\n",
       "      <th>...</th>\n",
       "      <th>new_icu_upper</th>\n",
       "      <th>totdea_mean</th>\n",
       "      <th>totdea_lower</th>\n",
       "      <th>totdea_upper</th>\n",
       "      <th>bedover_mean</th>\n",
       "      <th>bedover_lower</th>\n",
       "      <th>bedover_upper</th>\n",
       "      <th>icuover_mean</th>\n",
       "      <th>icuover_lower</th>\n",
       "      <th>icuover_upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Abruzzo</th>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-01</th>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-02</th>\n",
       "      <td>213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-03</th>\n",
       "      <td>214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-04</th>\n",
       "      <td>215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30530 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      v1  allbed_mean  allbed_lower  allbed_upper  \\\n",
       "location date                                                       \n",
       "Abruzzo  2020-01-03    1          0.0           0.0           0.0   \n",
       "         2020-01-04    2          0.0           0.0           0.0   \n",
       "         2020-01-05    3          0.0           0.0           0.0   \n",
       "         2020-01-06    4          0.0           0.0           0.0   \n",
       "         2020-01-07    5          0.0           0.0           0.0   \n",
       "...                  ...          ...           ...           ...   \n",
       "Wyoming  2020-07-31  211          0.0           0.0           0.0   \n",
       "         2020-08-01  212          0.0           0.0           0.0   \n",
       "         2020-08-02  213          0.0           0.0           0.0   \n",
       "         2020-08-03  214          0.0           0.0           0.0   \n",
       "         2020-08-04  215          0.0           0.0           0.0   \n",
       "\n",
       "                     icubed_mean  icubed_lower  icubed_upper  inv_ven_mean  \\\n",
       "location date                                                                \n",
       "Abruzzo  2020-01-03          0.0           0.0           0.0           0.0   \n",
       "         2020-01-04          0.0           0.0           0.0           0.0   \n",
       "         2020-01-05          0.0           0.0           0.0           0.0   \n",
       "         2020-01-06          0.0           0.0           0.0           0.0   \n",
       "         2020-01-07          0.0           0.0           0.0           0.0   \n",
       "...                          ...           ...           ...           ...   \n",
       "Wyoming  2020-07-31          0.0           0.0           0.0           0.0   \n",
       "         2020-08-01          0.0           0.0           0.0           0.0   \n",
       "         2020-08-02          0.0           0.0           0.0           0.0   \n",
       "         2020-08-03          0.0           0.0           0.0           0.0   \n",
       "         2020-08-04          0.0           0.0           0.0           0.0   \n",
       "\n",
       "                     inv_ven_lower  inv_ven_upper  ...  new_icu_upper  \\\n",
       "location date                                      ...                  \n",
       "Abruzzo  2020-01-03            0.0            0.0  ...            0.0   \n",
       "         2020-01-04            0.0            0.0  ...            0.0   \n",
       "         2020-01-05            0.0            0.0  ...            0.0   \n",
       "         2020-01-06            0.0            0.0  ...            0.0   \n",
       "         2020-01-07            0.0            0.0  ...            0.0   \n",
       "...                            ...            ...  ...            ...   \n",
       "Wyoming  2020-07-31            0.0            0.0  ...            0.0   \n",
       "         2020-08-01            0.0            0.0  ...            0.0   \n",
       "         2020-08-02            0.0            0.0  ...            0.0   \n",
       "         2020-08-03            0.0            0.0  ...            0.0   \n",
       "         2020-08-04            0.0            0.0  ...            0.0   \n",
       "\n",
       "                     totdea_mean  totdea_lower  totdea_upper  bedover_mean  \\\n",
       "location date                                                                \n",
       "Abruzzo  2020-01-03         0.00           0.0         0.000           0.0   \n",
       "         2020-01-04         0.00           0.0         0.000           0.0   \n",
       "         2020-01-05         0.00           0.0         0.000           0.0   \n",
       "         2020-01-06         0.00           0.0         0.000           0.0   \n",
       "         2020-01-07         0.00           0.0         0.000           0.0   \n",
       "...                          ...           ...           ...           ...   \n",
       "Wyoming  2020-07-31        34.22           0.0       231.025           0.0   \n",
       "         2020-08-01        34.22           0.0       231.025           0.0   \n",
       "         2020-08-02        34.22           0.0       231.025           0.0   \n",
       "         2020-08-03        34.22           0.0       231.025           0.0   \n",
       "         2020-08-04        34.22           0.0       231.025           0.0   \n",
       "\n",
       "                     bedover_lower  bedover_upper  icuover_mean  \\\n",
       "location date                                                     \n",
       "Abruzzo  2020-01-03            0.0            0.0           0.0   \n",
       "         2020-01-04            0.0            0.0           0.0   \n",
       "         2020-01-05            0.0            0.0           0.0   \n",
       "         2020-01-06            0.0            0.0           0.0   \n",
       "         2020-01-07            0.0            0.0           0.0   \n",
       "...                            ...            ...           ...   \n",
       "Wyoming  2020-07-31            0.0            0.0           0.0   \n",
       "         2020-08-01            0.0            0.0           0.0   \n",
       "         2020-08-02            0.0            0.0           0.0   \n",
       "         2020-08-03            0.0            0.0           0.0   \n",
       "         2020-08-04            0.0            0.0           0.0   \n",
       "\n",
       "                     icuover_lower  icuover_upper  \n",
       "location date                                      \n",
       "Abruzzo  2020-01-03            0.0            0.0  \n",
       "         2020-01-04            0.0            0.0  \n",
       "         2020-01-05            0.0            0.0  \n",
       "         2020-01-06            0.0            0.0  \n",
       "         2020-01-07            0.0            0.0  \n",
       "...                            ...            ...  \n",
       "Wyoming  2020-07-31            0.0            0.0  \n",
       "         2020-08-01            0.0            0.0  \n",
       "         2020-08-02            0.0            0.0  \n",
       "         2020-08-03            0.0            0.0  \n",
       "         2020-08-04            0.0            0.0  \n",
       "\n",
       "[30530 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihme_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_data = [\n",
    "    csse_us_timeseries_df,\n",
    "    ihme_df,\n",
    "    owid_df,\n",
    "    oxcgrt_df,\n",
    "    testtrack_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
