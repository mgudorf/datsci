{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, plot_precision_recall_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, Binarizer, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.metrics import average_precision_score, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA, SparsePCA \n",
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capital loss prevention : loan outcome prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_feature_transformer(X, num_features, cat_features, date_features, num_transformer=StandardScaler()):\n",
    "    ''' Transform features using a column transformer. \n",
    "    \n",
    "    A DataFrame which takes mixed \"Missing\" and datetime values, separates out the \"Missing\"\n",
    "    and then performs two operations. First, the 'Missing' column is one-hot encoded, second,\n",
    "    the datetime variables are binned and encoded using KBinsDiscretizer, using a uniform bin\n",
    "    width strategy. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    X : DataFrame (n_samples, n_features)\n",
    "         \n",
    "        Dataframe which contains training data. \n",
    "\n",
    "    num_features : list, Pandas index\n",
    "    \n",
    "        List of Pandas Index of the name of columns that contain numerical features.\n",
    "         \n",
    "\n",
    "    cat_features : list, Pandas index\n",
    "    \n",
    "        List of Pandas Index of the name of columns that contain categorical features.\n",
    "         \n",
    "    date_features : list, Pandas index\n",
    "    \n",
    "        List of Pandas Index of the name of columns that contain categorical features.\n",
    "         \n",
    "        Dataframe which contains datetime features and value \"Missing\" which indicates missing values.\n",
    "\n",
    "    num_transformer : scikit-learn Transformer\n",
    "         \n",
    "        scikit-learn scaler such as QuantileTransformer(), MinMaxScaler(), etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    col_transformer : ColumnTransformer instance\n",
    "    \n",
    "         Transformer that can be used to rescale and encode data. \n",
    "            \n",
    "    '''\n",
    "    \n",
    "    transformer_list = []\n",
    "    if num_transformer is not None:\n",
    "        transformer_list += [('num', num_transformer, num_features)] \n",
    "\n",
    "    if cat_features is not None:        \n",
    "        #uniq_categories = [list(np.sort(X[col].unique()))+['Missing','Unknown'] for col in cat_features]\n",
    "        uniq_categories = [list(np.sort(X[col].unique())) for col in cat_features]\n",
    "        # Previously dropped first category, this is more strategic.\n",
    "        least_populated_categories = [X[col].value_counts().idxmin() for col in cat_features]\n",
    "        cat_transformer = OneHotEncoder(categories=uniq_categories, drop=least_populated_categories)\n",
    "        transformer_list += [('cat', cat_transformer, cat_features)] \n",
    "        \n",
    "    if date_features is not None:             \n",
    "        transformer_list += [('my_kbd', 'passthrough', date_features)] \n",
    "\n",
    "    col_transformer = ColumnTransformer(transformers=transformer_list)\n",
    "\n",
    "    return col_transformer\n",
    "\n",
    "\n",
    "# Function that combines different classification metrics to avoid repeated large blocks of code.\n",
    "# Produces the confusion matrix, classification report (precision, recall, f1-score,..)\n",
    "# ROC-AUC and ROC curve\n",
    "# Precision-recall curve\n",
    "\n",
    "def my_score(clf, X_test, y_test):\n",
    "    ''' Predict using trained scikit-learn estimator and compute the explained variance score.  \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_test : ndarray or DataFrame (n_samples, n_features)\n",
    "             Feature data to test. n_features represents the number of features\n",
    "             present in the data used to train the estimator clf\n",
    "\n",
    "    y_test : ndarray (n_samples, )\n",
    "             Target data to test. \n",
    "\n",
    "\n",
    "    clf : scikit-learn estimator which has been fit to data with same number of columns as X_test\n",
    "\n",
    "    '''\n",
    "    y_predict_proba= clf.predict_proba(X_test)[:,1]\n",
    "    return roc_auc_score(y_test, y_predict_proba)\n",
    "\n",
    "\n",
    "def classifier_analysis(clf, xt, yt):\n",
    "    ''' Predict and measure quality of model with a variety of metrics.   \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    xt : ndarray or DataFrame (n_samples, n_features)\n",
    "             Feature data to test. n_features represents the number of features\n",
    "             present in the data used to train the estimator clf\n",
    "\n",
    "    yt : ndarray (n_samples, )\n",
    "             Target data to test. \n",
    "\n",
    "\n",
    "    clf : scikit-learn estimator which has been fit to data with same number of columns as X_test\n",
    "\n",
    "    '''\n",
    "    y_predict = clf.predict(xt)\n",
    "    y_predict_proba= clf.predict_proba(xt)[:,1]\n",
    "\n",
    "    cm = confusion_matrix(yt, y_predict, labels=[0,1])#,dtype=float)\n",
    "    # negative guesses\n",
    "#     cm[:, 0] = cm[:, 0] / (len(yt) - yt.sum())\n",
    "#     cm[:, 1] = cm[:, 1] / yt.sum()\n",
    "    print('tn, fp, fn, tp', cm.ravel())\n",
    "    _ = ConfusionMatrixDisplay(cm / (yt.size), [0,1]).plot()\n",
    "    \n",
    "    print(classification_report(yt, y_predict))\n",
    "\n",
    "    roc_auc = roc_auc_score(yt, y_predict_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(yt, y_predict_proba)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=(clf.__class__.__name__ + '(area = %0.2f)' % roc_auc))\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    average_precision = average_precision_score(yt, y_predict_proba)\n",
    "    precision, recall, thresholds = precision_recall_curve(yt, y_predict_proba)\n",
    "    disp = plot_precision_recall_curve(clf, xt, yt)\n",
    "    disp.ax_.set_ylim([0.0, 1.0])\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "\n",
    "def scale_features(col_transformer_, X_train, X_test):\n",
    "    _ = col_transformer_.fit(X_train)\n",
    "    X_train = col_transformer_.transform(X_train)\n",
    "    X_test = col_transformer_.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_(estimator, X_traintest, y_traintest, train, test):\n",
    "    num_features = X_traintest.select_dtypes(exclude=['object','category']).columns\n",
    "    cat_features = X_traintest.select_dtypes(include=['object','category']).columns\n",
    "    date_features = None\n",
    "    \n",
    "    X_train, X_test = X_traintest.loc[train,:], X_traintest.loc[test,:]\n",
    "    y_train, y_test = y_traintest.loc[train].values.ravel(), y_traintest.loc[test].values.ravel()\n",
    "    \n",
    "    col_transformer_ = my_feature_transformer(X, num_features, cat_features, date_features, num_transformer=StandardScaler())\n",
    "    X_train, X_test  = scale_features(col_transformer_, X_train, X_test)\n",
    "    \n",
    "    _ = estimator.fit(X_train, y_train)    \n",
    "    return (estimator, X_test, y_test)\n",
    "\n",
    "def param_grid_iterable(params):\n",
    "    keys = sorted(params)\n",
    "    combinations = list(itertools.product(*(params[key] if type(params[key]) in [list, dict, np.ndarray] else [params[key]]\n",
    "                                            for key in keys)))\n",
    "    cvsorted = [dict(zip(len(c)*keys, c)) for c in combinations]\n",
    "    return cvsorted\n",
    "\n",
    "def my_cross_validate(estimator, X_traintest, y_traintest, train_test_iterable, param_grid, n_jobs=-2):\n",
    "    mean_scores = []\n",
    "    # cv_params needs to make sense for the estimator given\n",
    "    param_grid_list = param_grid_iterable(param_grid)\n",
    "    for params_ in param_grid_list:\n",
    "        with Parallel(n_jobs=n_jobs, max_nbytes=None) as parallel:\n",
    "            fitted_models_and_test_splits = parallel(delayed(fit_model_)(estimator(**params_), \n",
    "                                                          X_traintest, y_traintest, train, test)\n",
    "                                  for (train, test) in train_test_iterable)\n",
    "            \n",
    "        with Parallel(n_jobs=n_jobs, max_nbytes=None) as parallel:\n",
    "            fitted_models_and_test_splits = parallel(delayed(fit_model_)(estimator(**params_), \n",
    "                                                          X_traintest, y_traintest, train, test)\n",
    "                                  for (train, test) in train_test_iterable)\n",
    "            # Get averages (explained variance) score for this model\n",
    "            scores = parallel(delayed(my_score)(model_, xt, yt) for (model_, xt, yt) in fitted_models_and_test_splits) \n",
    "            mean_scores += [np.mean(list(scores))]\n",
    "            \n",
    "    \n",
    "    best_params_ = param_grid_list[np.argmax(np.array(mean_scores))]\n",
    "    return estimator(**best_params_) \n",
    "\n",
    "\n",
    "# Convert date-like + 'Missing' valued features to one-hot encoded columns; uses KBins on the years of the date-like, which \n",
    "# bins then one-hot encodes, while also one-hot encoding 'Missing' separately. \n",
    "def encode_dates_and_missing(df):\n",
    "    for i, seriesname in enumerate(df.columns):\n",
    "        series = df[seriesname]\n",
    "        series_missing = pd.get_dummies(series[series=='Missing'])\n",
    "        series_notmissing = series[series!='Missing']\n",
    "        notmiss_index = series_notmissing.index\n",
    "        \n",
    "        kbd = KBinsDiscretizer(n_bins=5, strategy='uniform')\n",
    "        series_dt = pd.to_datetime(series_notmissing).dt.year\n",
    "        encoded_series = kbd.fit_transform(series_dt.values.reshape(-1,1))\n",
    "        encoded_series = pd.DataFrame(kbd.fit_transform(series_dt.values.reshape(-1,1)).toarray(),index=notmiss_index).astype(int)\n",
    "        least_populated_feature = np.array([encoded_series[col].sum() for col in encoded_series.columns]).argmin()\n",
    "        encoded_series = encoded_series.drop(columns=encoded_series.columns[least_populated_feature])\n",
    "        encoded_series.columns = [seriesname+'_'+str(col) for col in encoded_series.columns]\n",
    "        if i == 0: \n",
    "            encoded_df = encoded_series\n",
    "        else:\n",
    "            encoded_df = pd.concat((encoded_df,encoded_series),axis=1)\n",
    "            \n",
    "    return encoded_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to take into consideration the time dependence element of this problem. The original goal is to create a predictive model that attempts to determine whether or not to issue a loan based on the learning what factors are likely to lead to a charged-off (defaulted) loan. Before we can begin there are a number of considerations that need to be performed first before the actually modeling process can begin. The necessary actions that must be taken are\n",
    "\n",
    "    1. Accounting for the time dependent nature of this problem.\n",
    "    2. Handling heterogeneous data types and preprocessing\n",
    "    4. Deciding on the model to be used, both in terms of hyperparameters and algorithms\n",
    "    5. Accounting for any unexpected results.\n",
    "    6. Analysis of the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data that has been prepared for this problem.\n",
    "loan_data = pd.read_csv('../data/classification_loan_data_ind.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loan outcome prediction portion of this project, only the loans which have both matured are considered.\n",
    "Additionally, in this subset of loans there are a number of outcomes but by far the most highly populated are loans which have been fully paid or charged off. This can be formulated as a binary classification problem: the loans that are charged-off\n",
    "will be denoted as \"successes\" or by the integer 1. Likewise, loans which have been fully paid off will be denoted as \"failure\"\n",
    "by assigning these the integer 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time-dependency\n",
    "The first main hurdle that we need to overcome is the time dependent nature of the problem. If not handled carefully, we could accidentally perform what is known as \"data snooping\", which is the contamination of the model by inclusion of information from\n",
    "the future. The two main effects that this time dependency has are\n",
    " \n",
    "- Multiple time dependent variables\n",
    "- Time ordered cross validation folds\n",
    "\n",
    "To account for the first of these issues, all variables that are recorded at times more recent than the issuance date\n",
    "of the loan are removed. The features which are removed all involve measurements in the recent past or present such as \"in the past twelve months\". Some of the features are ambiguous and so we lean on the side of caution by removing these features as well. By including only loans which have matured, the correct description that these models produce is **predict whether a loan will default by the maturity date**. The maturity date depends on the term of the loan; it might be wise to separate the loans by term but currently this is not done.\n",
    "\n",
    "To handle the second of these bullet points, the cross validation process as well as the folds will be customly made, instead\n",
    "of using scikit-learn's TimeSeriesSplit() for instance. This is to be as confident as possible that there is no data snooping. Additionally, there are some considerations regarding encoding and preprocessing that are best handled by a custom cross-validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will be deprecated after newest data cleaning run. \n",
    "issued_datetime = pd.to_datetime(loan_data.issue_d, format='%b-%Y').sort_values()\n",
    "loan_data = loan_data.loc[issued_datetime.sort_values().index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the cross validation folds, now need to create procedure which correctly preprocesses them before testing. Training component of folds are cumulative over time; always want to use as much information as possible.\n",
    "\n",
    "Create a \"hold-out\" set of data that will used for final predictions and analysis after all cross-validation and\n",
    "model learning has been accomplished. The loan issuance dates are aggregated by month, but from the metadata we know that the data is reported *quarterly*. Using this as motivation, the hold-out data will be the most recent quarter. Because the number of loans has grown over time, this one quarter represents nearly $1 / 7$ of all loan data of loans that have either been fully paid or charged off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data goes from second quarter of 2007 to fourth quarter of 2015; the number of samples are skewed toawrds later dates;\n",
    "# The data is reported quarterly; this should be represented in the cross validation/model selection process.\n",
    "pind = pd.PeriodIndex(issued_datetime, freq='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KBins needs numerical variables; use year.quarter (number.decimal). This transformation is not applied to the training data; it's just used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forget quarters, use month and year\n",
    "numerical_dt = 12*(pind.year-pind.year.min()) + pind.month\n",
    "\n",
    "nb=6\n",
    "kbd = KBinsDiscretizer(n_bins=nb)\n",
    "bin_masks = kbd.fit_transform(numerical_dt.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76780., 87727., 64957., 88374., 95477., 85483.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bin_masks, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Heterogeneous data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking there are two different data types in the feature data, numerical (float) and categorical (object, could be\n",
    "cast as string). The categorical variables will be encoded and represented by binary numerical columns. Practically speaking it gets more detailed; some of the categorical variables have many categories, of\n",
    "the order of a thousand. Let's have a look to see how we should proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade                    7\n",
       "sub_grade               35\n",
       "emp_length              12\n",
       "home_ownership           6\n",
       "issue_d                 41\n",
       "purpose                 14\n",
       "zip_code               907\n",
       "addr_state              51\n",
       "term                     2\n",
       "earliest_cr_line       676\n",
       "initial_list_status      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.select_dtypes(include='object').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most diverse categorical variables will be handled in one of two ways: we shall argue that they are\n",
    "either unnecessary or reduce the number of categories via binning.\n",
    "The following are the choices made for these variables: originally the choice was made to remove all but the first two digits\n",
    "of the zip_code (there are only three recorded). This in fact lowers the resolution to a point where the state of residence is more precise; therefore, I believe that the zip_code can be dropped as it isn't informative. For the categorical variables which may be cast as datetime variables, **['earliest credit_line', 'issue_d']** the number of categories will be reduces by application of a binning strategy. The binning for the issuance date is naturally handled when the cross-validation folds are\n",
    "being produced, as this is the determining time dependent quantity. More specifically, we drop the issuance date from the calculation because based on the folds, the training and testing data will never intersect by definition; which I believe implies that the model will not know what to do. For the earliest_credit_line dates it is less obvious as how to proceed. The earliest credit line is thought of to be a proxy for age groups. Depending on the context, demographic age groups can be quite large in terms of the age spread. Therefore, I believe that only creating a few bins for this variable is\n",
    "sufficient. Applying the same argument comparing zip_code and addr_state, I remove the 'grade' of the loan in favor of keeping the subgrade. The grades take the values such as 'A', 'B', 'C' while the sub-grade is more specific 'A1', 'A2', ... 'E4', 'E5'.\n",
    "Therefore before the modeling process the following steps shall be taken:\n",
    "\n",
    "    1. Remove target variable from feature data\n",
    "    2. Remove more coarse categorical variables\n",
    "    3. Encode datetime-like categorical variables with KBinsDiscretizer (OneHotEncoding strategy).\n",
    "    4. Encode remaining categorical variables with OneHotEncoder (scitkit-learn)\n",
    "    \n",
    "Note: To avoid colinearity in the one-hot encoding process, the category with the lowest frequency is dropped (for each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target variable\n",
    "y = loan_data.loan_status.astype(int)\n",
    "# Dump everything with high correlations\n",
    "X = loan_data.drop(columns=['loan_status', 'zip_code', 'issue_d', 'earliest_cr_line', 'grade'])#,'funded_amnt','installment'])\n",
    "num_features = X.select_dtypes(include='number').columns\n",
    "cat_features = X.select_dtypes(include=['object','category']).columns\n",
    "date_features = ['earliest_cr_line']\n",
    "encoded_dates = encode_dates_and_missing(loan_data.loc[:, date_features])\n",
    "date_features = encoded_dates.columns\n",
    "X = pd.concat((X, encoded_dates),axis=1)\n",
    "X = X.reset_index(drop=True)\n",
    "y.index = X.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn wants iterable containing (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.array([np.array(X.index[\n",
    "    np.array(np.sum(bin_masks[:, :i+1],axis=1), dtype=bool)].tolist())\n",
    "                          for i in range(bin_masks.shape[1]-2)])\n",
    "test_indices = np.array([np.array(X.index[\n",
    "    np.array(bin_masks[:,i+1], dtype=bool)].tolist())\n",
    "                         for i in range(bin_masks.shape[1]-2)])\n",
    "\n",
    "train_test_iterable = list(zip(train_indices,test_indices))\n",
    "\n",
    "traintest_indices = X.index[np.array(np.sum(bin_masks[:,:-1],axis=1), dtype=bool)] \n",
    "holdout_indices = X.index[np.array(bin_masks[:, -1], dtype=bool)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformer = my_feature_transformer(X, num_features, cat_features, date_features, num_transformer=StandardScaler())\n",
    "X_traintest, X_holdout = X.loc[traintest_indices, :], X.loc[holdout_indices, :]\n",
    "y_traintest, y_holdout = y.loc[traintest_indices], y.loc[holdout_indices]\n",
    "\n",
    "X_traintest = X_traintest.reset_index(drop=True)\n",
    "X_holdout = X_holdout.reset_index(drop=True)\n",
    "\n",
    "_ = col_transformer.fit(X_traintest)\n",
    "X_traintest_transform = col_transformer.transform(X_traintest)\n",
    "X_holdout_transform = col_transformer.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model selection\n",
    "First, perform preliminary tests to\n",
    "develop an intuition as what to include in the cross-validation process. To\n",
    "do so, the data needs to be processed and transformed. There are a number of choices for the\n",
    "method with which to scale the numerical data. The tests are performed by using the entirety\n",
    "of the training data (named traintest because the testing folds come from this subset) to fit\n",
    "the model. The model is then tested using this data as well as a set of \"holdout\" data which\n",
    "the model does not know about. The holdout data, by virtue of the cross-validation folds,\n",
    "corresponds to the most recent loan data. \n",
    "\n",
    "The name for the data variables might be confusing so, to be explicit:\n",
    "\n",
    "\"traintest\" is the data such that for each cross validation fold, traintest is split into a training set\n",
    "and a testing set. After the model selection via cross-validation the \"traintest\" set becomes the\n",
    "final training set.\n",
    "\n",
    "\"holdout\" is the data completely unknown to the model which is only tested after absolutely everything is\n",
    "put into place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Quick test of collinearity via correlation matrix plot\n",
    "plt.matshow(pd.DataFrame(X_traintest_transform.toarray()).corr(), cmap='viridis')\n",
    "_ = plt.colorbar()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the modeling process, first I would like to get an idea with what I am working with by fitting the models without parameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "_ = logistic_regression.fit(X_traintest_transform, y_traintest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression evaluation on training set')\n",
    "_ = classifier_analysis(logistic_regression, X_traintest_transform, y_traintest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression evaluation on testing set')\n",
    "logreg_roc_auc_test = classifier_analysis(logistic_regression, X_holdout_transform, y_holdout.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_initial = RandomForestClassifier()\n",
    "_ = random_forest_initial.fit(X_traintest_transform, y_traintest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest evaluation on training set')\n",
    "_ = classifier_analysis(random_forest_initial, X_traintest_transform, y_traintest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Random Forest evaluation on testing set')\n",
    "random_forest_initial_roc_auc = classifier_analysis(random_forest_initial, X_holdout_transform, y_holdout.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For me there are two main takeaways from these tests. Firstly, the class weights need to be balanced to represent the frequency at which defaults occur (approximately 1/7 of the total samples).  \n",
    "\n",
    "The main goal is to reduce capital loss not maximize profits. Therefore, we value prediction of when a loan will be charged off more than fully paid. We can account for this by changing the class weights in the classification process. This model will reject loans that would have been fully paid in order to avoid loans that will become charged off. In other words, the goal is to maximize the number of true positives, where \"positive\" in this case is equivalent to a loan being charged off.\n",
    "It's clear that the class weights need to be balanced because otherwise the models are modeling the null information rate.\n",
    "Therefore, for everything that proceeds I shall weight the binary classes by their inverse frequency.\n",
    "The choices for the hyper-parameters aren't obvious so the cross-validation process attempts to cast a broad (but coarse) net\n",
    "on the hyper-parameter space.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5, 10, 25]\n",
    "max_depth = [3, 9, 27]\n",
    "min_samples_split = [2, 20, 200]\n",
    "min_samples_leaf =  [2, 20, 200]\n",
    "max_samples = [None, 1000, 0.1]\n",
    "class_weight = ['balanced']\n",
    "\n",
    "random_forest_parameter_grid = {'n_estimators':n_estimators, \n",
    "                                'max_depth':max_depth,\n",
    "                                'min_samples_split':min_samples_split,\n",
    "                                'min_samples_leaf':min_samples_leaf,\n",
    "                                'class_weight':class_weight,\n",
    "                                   'max_samples':max_samples}                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the custom, parallelized (using joblib) cross-validation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model = my_cross_validate(RandomForestClassifier, X_traintest, y_traintest,\n",
    "                                             train_test_iterable, random_forest_parameter_grid, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = best_random_forest_model.fit(X_traintest_transform, y_traintest.values)\n",
    "random_forest_roc_auc = classifier_analysis(best_random_forest_model, X_holdout_transform, y_holdout.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = ['balanced']\n",
    "C = [0.25, 1, 4]\n",
    "max_iter = [250]\n",
    "tol = [0.1, 0.01, 0.0001]\n",
    "logistic_parameter_grid = { 'class_weight':class_weight,\n",
    "                           'max_iter': max_iter,\n",
    "                           'C':C,\n",
    "                          'tol'= tol\n",
    "                          'penalty'=pens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logistic_regression_model = my_cross_validate(LogisticRegression, X_traintest, \n",
    "                                             y_traintest, train_test_iterable, logistic_parameter_grid, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_logistic_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = best_logistic_regression_model.fit(X_traintest_transform, y_traintest.values)\n",
    "logistic_regression_roc_auc = classifier_analysis(best_logistic_regression_model, X_holdout_transform, y_holdout.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the logistic regression and random forest classification models seem to perform equally well. It has decent performance in regards to the main goal which is attempting to identify true positives. Originally the goal was to offer a recommendation for whether or not to provide the loan. Because there are\n",
    "so many false positives, however, I do not believe that this is sufficiently accurate to determine whether or not to provide\n",
    "loans, as it would reject far too many applicants. Therefore the best that this model can do is to flag accounts which\n",
    "are at risk of defaulting. This is still a proactive measure but it would only be correct around 25% of the time. \n",
    "\n",
    "The surface level comparison is that the logistic regression predicts the \"true\" label more often than the random forest classification. As a result, there is a higher prevalance of true and false positives. This is evidenced by the increase in\n",
    "both recall and precision of the logistic regression.\n",
    "\n",
    "For a recommendation I believe more work needs to be done to see why so many false positives are predicted. But if I were forced to choose between the two current models, I think if I was minimized the amount of lost capital, I need to have more recall on the \"1\" label because this represents a defaulted loan. In other words, use the Logistic Regression, which produces more false positives to reduce the number of potentially defaulting loans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
